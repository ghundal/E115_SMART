chunk_id,document,class,page,chunk_text,chunk_length,chunk_method
0d9bb6bc-23ae-4d9d-945d-4ff3dd22d88b,Neural_Networks.pdf,CSCI_80,0,"Neural Networks  AI neural networks are inspired by neuroscience. In the brain, neurons are cells that are connected to each other, forming networks. Each neuron is capable of both receiving and sending electrical signals. Once the electrical input that a neuron receives crosses some threshold, the neuron activates, thus sending its electrical signal forward.  1. Artificial Neural Network/ ANN An Artificial Neural Network is a mathematical model for learning inspired by biological neural networks. Artificial neural networks model mathematical functions that map inputs to outputs based on the structure and parameters of the network. In artificial neural networks, the structure of the network is shaped through training on data. This allows for leaning the network’s parameters based on data.  When implemented in AI, the parallel of each neuron is a unit that’s connected to other units",894,recursive
d1610b05-135d-4a91-9a9c-21b177461091,Neural_Networks.pdf,CSCI_80,0,". This allows for leaning the network’s parameters based on data.  When implemented in AI, the parallel of each neuron is a unit that’s connected to other units. For example, like in the last lecture, the AI might map two inputs, x₁, and x₂, to whether it is going to rain today or not. Last lecture, we suggested the following form for this hypothesis function: h(x₁, x₂) = w₀ + w₁x₁ + w₂x₂, where w₁ and w₂ are weights that modify the inputs, and w₀ is a constant, also called bias, modifying the value of the whole expression.   2. Activation Functions To use the hypothesis function to decide whether it rains or not, we need to create some sort of threshold based on the value it produces. h(x₁, x₂) = g(w₀ + w₁x₁ + w₂x₂) g = activation function  i. Step Function One way to do this is with a step function, which gives 0 before a certain threshold is reached and 1 after the threshold is reached.",902,recursive
ac8df068-3a7c-4779-b346-21ca67371bd7,Neural_Networks.pdf,CSCI_80,0,"ii. Logistic Function Another way to go about this is with a logistic function, which gives as output any real number from 0 to 1, thus expressing graded confidence in its judgment.",181,recursive
2b1b102b-8ce1-41ee-9cfe-9415b2ba774b,Neural_Networks.pdf,CSCI_80,1,"iii. Rectified Linear Unit Another possible function is Rectified Linear Unit (ReLU), which allows the output to be any positive value. If the value is negative, ReLU sets it to 0.  
  Whichever function we choose to use, we learned last lecture that the inputs are modified by weights in addition to the bias, and the sum of those is passed to an activation function. This stays true for simple neural networks. Check the gaussian linear unit, sigmoid, tanh.  3. Neural Network Structure A neural network can be thought of as a representation of the idea above, where a function sums up inputs to produce an output.",616,recursive
a683382a-9986-430f-9b79-2fb23ccdf48a,Neural_Networks.pdf,CSCI_80,2,"The two white units on the left are the input and the unit on the right is an output. The inputs are connected to the output by a weighted edge. To make a decision, the output unit multiplies the inputs by their weights in addition to the bias (w₀), and the uses function g to determine the output.  i. Neural Network of Or Function  For example, an Or logical connective can be represented as a function f with the following truth table:  x y f(x, y) 0 0 0 0 1 1 1 0 1 1 1 1  We can visualize this function as a neural network. x₁ is one input unit, and x₂ is another input unit. They are connected to the output unit by an edge with a weight of 1. The output unit then uses function g(-1 + 1x₁ + 2x₂) with a threshold of 0 to output either 0 or 1 (false or true).",765,recursive
334e418c-70ac-4554-a25b-3a6bb1fb8833,Neural_Networks.pdf,CSCI_80,3,"For example, in the case where x₁ = x₂ = 0, the sum is (-1). This is below the threshold, so the function g will output 0. However, if either or both of x₁ or x₂ are equal to 1, then the sum of all inputs will be either 0 or 1. Both are at or above the threshold, so the function will output 1.  ii. Neural Network of And Function A similar process can be repeated with the And function (where the bias will be (-2)). Moreover, inputs and outputs don’t have to be distinct. A similar process can be used to take humidity and air pressure as input, and produce the probability of rain as output. Or, in a different example, inputs can be money spent on advertising and the month when it was spent to get the output of expected revenue from sales. This can be extended to any number of inputs by multiplying each input x₁ … xₙ by weight w₁ … wₙ, summing up the resulting values and adding a bias w₀.  4",900,recursive
49d9b42c-ba87-4fdd-ab46-7ef7b3adc3bc,Neural_Networks.pdf,CSCI_80,3,". This can be extended to any number of inputs by multiplying each input x₁ … xₙ by weight w₁ … wₙ, summing up the resulting values and adding a bias w₀.  4. Gradient Descent Gradient descent is an algorithm for minimizing loss when training neural networks. As was mentioned earlier, a neural network is capable of inferring knowledge about the structure of the network itself from the data. Whereas, so far, we defined the different weights, neural networks allow us to compute these weights based on the training data. To do this, we use the gradient descent algorithm, which works the following way:  - Start with a random choice of weights. This is our naive starting place, where we don’t know how much we should weight each input.  - Repeat: • Calculate the gradient based on all data points that will lead to decreasing loss. Ultimately, the gradient is a vector (a sequence of numbers). • Update weights according to the gradient",938,recursive
ca4f1482-2e8d-4cc5-abfa-1093f190c981,Neural_Networks.pdf,CSCI_80,3,". Ultimately, the gradient is a vector (a sequence of numbers). • Update weights according to the gradient.  The problem with this kind of algorithm is that it requires to calculate the gradient based on all data points, which is computationally costly. There are multiple ways to minimize this cost.   i. Stochastic Gradient Descent the gradient is calculated based on one point chosen at random. This kind of gradient can be quite inaccurate, but it is much faster since it is calculated based on just one data point.  ii. Mini-Batch Gradient Descent algorithm which computes the gradient based on a few points/one small batch selected at random, thus finding a compromise between computation cost and accuracy. As often is the case, none of these solutions is perfect, and different solutions might be employed in different situations.  Using gradient descent, it is possible to find answers to many problems",911,recursive
6eec38d2-d0a0-4af3-9719-e766ed607500,Neural_Networks.pdf,CSCI_80,3,". As often is the case, none of these solutions is perfect, and different solutions might be employed in different situations.  Using gradient descent, it is possible to find answers to many problems. For example, we might want to know more than “will it rain today?” We can use some inputs to generate probabilities for different kinds of weather, and then just choose the weather that is most probable.  This can be done with any number of inputs and outputs, where each input is connected to each output and where the outputs represent decisions that we can make. Note that in this kind of",592,recursive
66ede3ab-9721-4c18-b889-b9074be7f783,Neural_Networks.pdf,CSCI_80,4,"neural networks the outputs are not connected. This means that each output and its associated weights from all the inputs can be seen as an individual neural network and thus can be trained separately from the rest of the outputs.  
  The general formula is: (num input units + 1) x (num output units) Where the + 1 accounts for the biases. This gives us the total number of learnable parameters for a simple, fully connected network.  So far, our neural networks relied on perceptron output units. These are units that are only capable of learning a linear decision boundary, using a straight line to separate data. That is, based on a linear equation, the perceptron could classify an input to be one type or another (e.g. left picture). However, often, data are not linearly separable (e.g. right picture). In this case, we turn to multilayer neural networks to model data non-linearly.",889,recursive
1faae362-204a-415d-9b37-1df34b44c147,Neural_Networks.pdf,CSCI_80,4,"5. Multilayer Neural Networks A multilayer neural network is an artificial neural network with an input layer, an output layer, and at least one hidden layer. While we provide inputs and outputs to train the model, we, the humans, don’t provide any values to the units inside the hidden layers. Each unit in the first hidden layer receives a weighted value from each of the units in the input layer, performs some action on it, and outputs a value. Each of these values is weighted and further propagated to the next layer, repeating the process until the output layer is reached. Through hidden layers, it is possible to model non-linear data.",644,recursive
25e1d7d5-4027-4171-83a6-5a129b66aff4,Neural_Networks.pdf,CSCI_80,5,"Hidden layers in neural networks help the model learn more complex relationships and patterns in the data. Here are some key reasons we use hidden layers:  - They allow the neural network to learn nonlinear relationships. Without hidden layers, a neural network can only learn linear relationships between input and output. Hidden layers enable modeling nonlinear patterns.  - They enable learning more abstract features and concepts. Early layers might learn simple features, while deeper layers can combine these to learn more complex, abstract features.   - They allow the model to generalize better. More hidden layers allow the model to better fit the training data without overfitting and capture more complex patterns.  - They provide a progression from input to output features. The layers connect the original input features to the final outputs through gradual transformations.  - They increase modeling capacity and expressiveness",941,recursive
2742dddb-5a33-43df-bffa-2f28b3a8f63a,Neural_Networks.pdf,CSCI_80,5,". The layers connect the original input features to the final outputs through gradual transformations.  - They increase modeling capacity and expressiveness. More layers and neurons increase the complexity of patterns the model can learn.  So in summary, adding one or more hidden layers enables the neural network to learn more complex relationships and patterns from the data than would be possible with just input and output layers. This helps the model achieve better performance.",484,recursive
8236094a-4d37-4708-8416-5a3a0133a25c,Neural_Networks.pdf,CSCI_80,5,"6. Backpropagation Backpropagation is the main algorithm used for training neural networks with hidden layers. It does so by starting with the errors in the output units, calculating the gradient descent for the weights of the previous layer, and repeating the process until the input layer is reached. In pseudocode, we can describe the algorithm as follows:  - Start with a random choice of weights. - Repeat: • Calculate error for output layer",446,recursive
28e38d19-3d0d-4719-8434-163d86d3d7ec,Neural_Networks.pdf,CSCI_80,6,"• For each layer, starting with output layer and moving inwards towards earliest hidden layer: Ø Propagate error back one layer. In other words, the current layer that’s being considered sends the errors to the preceding layer. Ø Update weights.  This can be extended to any number of hidden layers, creating deep neural networks, which are neural networks that have more than one hidden layer.  Backpropagation is a key algorithm that solves the problem of training multi-layer neural networks effectively. Here are some of the main problems backpropagation helps address:  - Credit assignment: Backpropagation provides an efficient way to calculate the contribution of each weight in the network to the overall error. This helps determine how much to adjust each weight during training.  - Computing error gradients: The backpropagation algorithm provides a way to calculate the gradient of the error with respect to the weights in a multi-layer network",955,recursive
ad4d58a7-a5cb-4959-b233-236da782048a,Neural_Networks.pdf,CSCI_80,6,".  - Computing error gradients: The backpropagation algorithm provides a way to calculate the gradient of the error with respect to the weights in a multi-layer network. These gradients indicate how to update the weights to reduce the error.  - Vanishing/exploding gradients: Backpropagation mitigates vanishing and exploding gradients by allowing direct and efficient calculation of error gradients for deeper layers in the network.  - Efficient training: Backpropagation allows multi-layer neural nets to be trained efficiently without needing to manually specify rules for each layer. It automates the weight adjustment process.  - Scalability: The algorithm scales well to large networks with many layers, enabling development of deep neural networks.  In essence, backpropagation solves the credit assignment problem for multi-layer networks. By providing an efficient way to calculate error gradients across all layers, it enables effective and automated training of deep neural networks",993,recursive
2411e973-6c43-4e3b-ad21-6b44127baa96,Neural_Networks.pdf,CSCI_80,6,". By providing an efficient way to calculate error gradients across all layers, it enables effective and automated training of deep neural networks. Without backpropagation, training networks with more than a few layers would be computationally intractable.  7. Overfitting/Dropout Overfitting is the danger of modeling the training data too closely, thus failing to generalize to new data. One way to combat overfitting is by dropout. In this technique, we temporarily remove units that we select at random during the learning phase. This way, we try to prevent over-reliance on any one unit in the network. Throughout training, the neural network will assume different forms, each time dropping some other units and then using them again:  Note that after the training is finished, the whole neural network will be used again.  Dropout is a regularization technique that helps reduce overfitting in neural networks. Here are some key problems that dropout helps address:",972,recursive
2a45d7a5-db60-486e-8d0e-0733ec2d9c8c,Neural_Networks.pdf,CSCI_80,7,"- Overfitting: Dropout prevents overfitting by randomly dropping out (setting to zero) a proportion of node activations during training. This forces the network to be redundant and prevents units from co-adapting too much.  - Complex co-adaptations: By dropping out nodes, it breaks up complex co-adaptations of nodes on the training data. This makes the model more robust and drives it to learn more distributed representations.  - Overly confident predictions: By randomly dropping nodes, it adds noise to the model's predictions during training. This reduces overconfidence and improves generalization.   - Exploding/vanishing gradients: Dropout can mitigate exploding and vanishing gradients, allowing models to be trained for longer and with more layers.  - Effective model averaging: Dropout can be seen as training a large ensemble of smaller networks. This acts to average predictions and improve generalization, similar to model ensembling",948,recursive
af885fda-9479-4271-9ed9-8a74b7982171,Neural_Networks.pdf,CSCI_80,7,".  - Effective model averaging: Dropout can be seen as training a large ensemble of smaller networks. This acts to average predictions and improve generalization, similar to model ensembling.  In summary, by randomly dropping nodes during training, dropout helps prevent overfitting, enabling the neural network model to better generalize to new data. It discourages reliance on any one node and instead improves distributed representations.  8. TensorFlow Like often is the case in python, multiple libraries already have an implementation for neural networks using the backpropagation algorithm, and TensorFlow is one such library. You are welcome to experiment with TensorFlow neural networks in this web application, which lets you define different properties of the network and run it, visualizing the output. We will now turn to an example of how we can use TensorFlow to perform the task we discussed last lecture: distinguishing counterfeit notes from genuine notes",973,recursive
34532081-6726-4287-b7be-691aa6a5dc65,Neural_Networks.pdf,CSCI_80,7,". We will now turn to an example of how we can use TensorFlow to perform the task we discussed last lecture: distinguishing counterfeit notes from genuine notes. Banknotes.py  import csv import tensorflow as tf from sklearn.model_selection import train_test_split We import TensorFlow and call it tf (to make the code shorter).  # Read data in from file with open(""banknotes.csv"") as f:     reader = csv.reader(f)     next(reader)      data = []     for row in reader:         data.append({             ""evidence"": [float(cell) for cell in row[:4]],             ""label"": 1 if row[4] == ""0"" else 0",596,recursive
5f04377f-711d-4864-862a-7319c796bef6,Neural_Networks.pdf,CSCI_80,8,"})  # Separate data into training and testing groups evidence = [row[""evidence""] for row in data] labels = [row[""label""] for row in data] X_training, X_testing, y_training, y_testing = train_test_split(     evidence, labels, test_size=0.4 ) We provide the CSV data to the model. Our work is often required in making the data fit the format that the library requires. The difficult part of actually coding the model is already implemented for us.  # Create a neural network model = tf.keras.models.Sequential() Keras is an api that different machine learning algorithms access. A sequential model is one where layers follow each other (like the ones we have seen so far).  # Add a hidden layer with 8 units, with ReLU activation model.add(tf.keras.layers.Dense(8, input_shape=(4,), activation=""relu"")) A dense layer is one where each node in the current layer is connected to all the nodes from the previous layer",912,recursive
677ddc3b-3ad7-488c-b798-c76548d317d1,Neural_Networks.pdf,CSCI_80,8,". In generating our hidden layers we create 8 dense layers, each having 4 input neurons, using the ReLU activation function mentioned above.  # Add output layer with 1 unit, with sigmoid activation model.add(tf.keras.layers.Dense(1, activation=""sigmoid"")) In our output layer, we want to create one dense layer that uses a sigmoid activation function, an activation function where the output is a value between 0 and 1.  # Train neural network model.compile(     optimizer=""adam"",     loss=""binary_crossentropy"",     metrics=[""accuracy""] ) model.fit(X_training, y_training, epochs=20)  # Evaluate how well model performs model.evaluate(X_testing, y_testing, verbose=2) Finally, we compile the model, specifying which algorithm should optimize it, what type of loss function we use, and how we want to measure its success (in our case, we are interested in the accuracy of the output)",883,recursive
1a7f9bef-a69a-4854-8652-6e63ba8ffcb4,Neural_Networks.pdf,CSCI_80,8,". Finally, we fit the model on the training data with 20 repetitions (epochs), and then evaluate it on the testing data.  9. Computer Vision Computer vision encompasses the different computational methods for analyzing and understanding digital images, and it is often achieved using neural networks. For example,",313,recursive
e02e583b-d72f-445f-8af2-30b63ba8f398,Neural_Networks.pdf,CSCI_80,9,"computer vision is used when social media employs face recognition to automatically tag people in pictures. Other examples are handwriting recognition and self-driving cars.  Images consist of pixels, and pixels are represented by three values that range from 0 to 255, one for red, one for green, and one for blue. These values are often referred to with the acronym RGB. We can use this to create a neural network where each color value in each pixel is an input, where we have some hidden layers, and the output is some number of units that tell us what it is that was shown in the image. However, there are a few drawbacks to this approach. First, by breaking down the image into pixels and the values of their colors, we can’t use the structure of the image as an aid. That is, as humans, if we see a part of a face we know to expect to see the rest of the face, and this quickens computation. We want to be able to use a similar advantage in our neural networks",967,recursive
9cc5c8d2-7bda-498c-b388-80064c6354d4,Neural_Networks.pdf,CSCI_80,9,". That is, as humans, if we see a part of a face we know to expect to see the rest of the face, and this quickens computation. We want to be able to use a similar advantage in our neural networks. Second, the sheer number of inputs is very big, which means that we will have to calculate a lot of weights.  10. Image Convolution Image convolution is applying a filter that adds each pixel value of an image to its neighbors, weighted according to a kernel matrix. Doing so alters the image and can help the neural network process it.  Let’s consider the following example:",572,recursive
89d49d52-1520-4b5f-8b2f-16311493ff8a,Neural_Networks.pdf,CSCI_80,9,"The kernel is the blue matrix, and the image is the big matrix on the left. The resulting filtered image is the small matrix on the bottom right. To filter the image with the kernel, we start with the pixel with the value 20 in the top-left of the image (coordinates 1,1). Then, we will multiply all the values around it by the corresponding value in the kernel and sum them up (10*0 + 20*(-1) + 30*0 + 10*(-1) + 20*5 + 30*(-1) + 20*0 + 30*(-1) + 40*0), producing the value 10. Then we will do the same for the pixel on the right (30), the pixel below the first one (30), and the pixel to the right of this one (40). This produces a filtered image with the values we see on the bottom right.",691,recursive
d59b4469-7f6a-4c08-965e-8b0db5204e0e,Neural_Networks.pdf,CSCI_80,10,"i. Edge Detection Kernel  Different kernels can achieve different tasks. For edge detection, the following kernel is often used:",128,recursive
6d9ca480-4aa4-4285-920f-4f82591ff057,Neural_Networks.pdf,CSCI_80,10,"The idea here is that when the pixel is similar to all its neighbors, they should cancel each other, giving a value of 0. Therefore, the more similar the pixels, the darker the part of the image, and the more different they are the lighter it is. Applying this kernel to an image (left) results in an image with pronounced edges (right):  ii. Edge Detection/Filter  Let’s consider an implementation of image convolution. We are using the PIL library (stands for Python Imaging Library) that can do most of the hard work for us.  import math import sys  from PIL import Image, ImageFilter  # Ensure correct usage if len(sys.argv) != 2:     sys.exit(""Usage: python filter.py filename"")  # Open image image = Image.open(sys.argv[1]).convert(""RGB"")  # Filter image according to edge detection kernel filtered = image.filter(ImageFilter.Kernel(     size=(3, 3),     kernel=[-1, -1, -1, -1, 8, -1, -1, -1, -1],     scale=1 ))  # Show resulting image filtered.show()",959,recursive
173a9920-898e-49fb-8010-da60b9b1c454,Neural_Networks.pdf,CSCI_80,11,"iii. Max-Pooling Still, processing the image in a neural network is computationally expensive due to the number of pixels that serve as input to the neural network. Another way to go about this is Pooling, where the size of the input is reduced by sampling from regions in the input. Pixels that are next to each other belong to the same area in the image, which means that they are likely to be similar. Therefore, we can take one pixel to represent a whole area. One way of doing this is with Max-Pooling, where the selected pixel is the one with the highest value of all others in the same region. For example, if we divide the left square (below) into four 2X2 squares, by max-pooling from this input, we get the small square on the right.",743,recursive
e8d35ce9-187a-4eb4-b5ad-16c46c859bd1,Neural_Networks.pdf,CSCI_80,11,"11. Convolutional Neural Networks/CNN A convolutional neural network is a neural network that uses convolution, usually for analyzing images. It starts by applying filters that can help distill some features of the image using different kernels. These filters can be improved in the same way as other weights in the neural network, by adjusting their kernels based on the error of the output. Then, the resulting images are pooled, after which the pixels are fed to a traditional neural network as inputs (a process called flattening).  Convolutional Neural Network",565,recursive
13dc3f1e-2127-4070-9c89-8d1a83c2ddba,Neural_Networks.pdf,CSCI_80,12,"The convolution and pooling steps can be repeated multiple times to extract additional features and reduce the size of the input to the neural network. One of the benefits of these processes is that, by convoluting and pooling, the neural network becomes less sensitive to variation. That is, if the same picture is taken from slightly different angles, the input for convolutional neural network will be similar, whereas, without convolution and pooling, the input from each image would be vastly different.  In code, a convolutional neural network doesn’t differ by much from a traditional neural network. TensorFlow offers datasets to test our models on. We will be using MNIST, which contains pictures of black and white handwritten digits. We will train our convolutional neural network to recognize digits",811,recursive
206aea6c-0264-4391-ad5a-bb40e28455b6,Neural_Networks.pdf,CSCI_80,12,". We will be using MNIST, which contains pictures of black and white handwritten digits. We will train our convolutional neural network to recognize digits. Handwriting.py  import sys import tensorflow as tf  # Use MNIST handwriting dataset mnist = tf.keras.datasets.mnist  # Prepare data for training (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train, x_test = x_train / 255.0, x_test / 255.0 y_train = tf.keras.utils.to_categorical(y_train) y_test = tf.keras.utils.to_categorical(y_test) x_train = x_train.reshape(     x_train.shape[0], x_train.shape[1], x_train.shape[2], 1 ) x_test = x_test.reshape(     x_test.shape[0], x_test.shape[1], x_test.shape[2], 1 )  # Create a convolutional neural network model = tf.keras.models.Sequential([      # Convolutional layer",782,recursive
3f013d7c-1586-454b-93ef-084fb6315ff4,Neural_Networks.pdf,CSCI_80,12,". Learn 32 filters using a 3x3 kernel     tf.keras.layers.Conv2D(         32, (3, 3), activation=""relu"", input_shape=(28, 28, 1)     ),      # Max-pooling layer, using 2x2 pool size     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),      # Flatten units     tf.keras.layers.Flatten(),      # Add a hidden layer with dropout     tf.keras.layers.Dense(128, activation=""relu""),",375,recursive
4c01e7b2-9754-4b1e-b16a-e2043145397a,Neural_Networks.pdf,CSCI_80,13,"tf.keras.layers.Dropout(0.5),      # Add an output layer with output units for all 10 digits     tf.keras.layers.Dense(10, activation=""softmax"") ])  # Train neural network model.compile(     optimizer=""adam"",     loss=""categorical_crossentropy"",     metrics=[""accuracy""] ) model.fit(x_train, y_train, epochs=10)  # Evaluate neural network performance model.evaluate(x_test,  y_test, verbose=2) Since the model takes time to train, we can save the already trained model to use it later.  # Save model to file if len(sys.argv) == 2:     filename = sys.argv[1]     model.save(filename)     print(f""Model saved to {filename}."")  Now, if we run a program that receives hand-drawn digits as input, it will be able to classify and output the digit using the model. For an implementation of such a program, refer to recognition.py in the source code for this lecture.  12. Recurrent Neural Networks  i",893,recursive
eaf6ebff-7a9a-42be-aee9-b3904c56b391,Neural_Networks.pdf,CSCI_80,13,". For an implementation of such a program, refer to recognition.py in the source code for this lecture.  12. Recurrent Neural Networks  i. Feed-Forward Neural Networks Feed-Forward Neural Networks are the type of neural networks that we have discussed so far, where input data is provided to the network, which eventually produces some output. A diagram of how feed-forward neural networks work can be seen below. This has a fixed number of inputs and a fixed number of outputs. This has limitations in the use of the model.  Feed-Forward Neural Networks Diagram",562,recursive
394f09cd-57c9-44b3-97dd-fc33496450d6,Neural_Networks.pdf,CSCI_80,13,"ii. Recurrent Neural Networks As opposed to that, Recurrent Neural Networks consist of a non-linear structure, where the network uses its own output as input. For example, Microsoft’s captionbot is capable of describing the content of an image with words in a sentence. This is different from classification",307,recursive
b69c7fde-c76f-4ec3-86ca-9ca0aa4404ca,Neural_Networks.pdf,CSCI_80,14,"in that the output can be of varying length based on the properties of the image. While feed-forward neural networks are incapable of varying the number of outputs, recurrent neural networks are capable to do that due to their structure. In the captioning task, a network would process the input to produce an output, and then continue processing from that point on, producing another output, and repeating as much as necessary.  Recurrent Neural Network 
  Recurrent neural networks are helpful in cases where the network deals with sequences and not a single individual object. Above, the neural network needed to produce a sequence of words. However, the same principle can be applied to analyzing video files, which consist of a sequence of images, or in translation tasks, where a sequence of inputs (words in the source language) is processed to produce a sequence of outputs (words in the target language).  Long Short Memory Network LSMS",945,recursive
f856ad63-7dc8-4d4c-a8aa-6fef700e2311,lecture2.pdf,CSCI_80,0,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
262b5b0a-fac2-433b-9437-b9830950a780,lecture2.pdf,CSCI_80,1,Uncertainty,11,recursive
2bd83ab0-bd03-4681-9de0-c36b63d99905,lecture2.pdf,CSCI_80,5,Probability,11,recursive
df541ef8-cf58-4c56-a943-9d963051038c,lecture2.pdf,CSCI_80,6,"P(ω)
Possible Worlds",20,recursive
6eebd39e-24d2-4755-a210-a6cf4c2fd1af,lecture2.pdf,CSCI_80,7,P(ω),4,recursive
6dee0072-b7be-4239-94ff-5b8dd57810f4,lecture2.pdf,CSCI_80,8,0 ≤ P(ω) ≤ 1,12,recursive
2d94b4f5-0a70-4c53-b37f-75cf934919ed,lecture2.pdf,CSCI_80,9,0 ≤ P(ω) = 1∑ω∈Ω,16,recursive
d76d516a-4dde-4043-a1ee-80459ecea3c0,lecture2.pdf,CSCI_80,10,"1
6
1
6
1
6
1
6
1
6
1
6",23,recursive
07827024-6fcc-44c0-b8c1-496d9fa7d5b8,lecture2.pdf,CSCI_80,11,"P(        ) = 1/61
6",20,recursive
2310cd99-9321-4aa1-8640-e80146e47f7a,lecture2.pdf,CSCI_80,14,"2
3
4
5
6
7
3
4
5
6
7
8
4
5
6
7
8
9
5
6
7
8
9
10
6
7
8
9
10
11
7
8
9
10
11
12",77,recursive
e06d3657-950a-4506-86f0-f6f0759c0efb,lecture2.pdf,CSCI_80,15,"2
3
4
5
6
7
3
4
5
6
7
8
4
5
6
7
8
9
5
6
7
8
9
10
6
7
8
9
10
11
7
8
9
10
11
12",77,recursive
3fd03997-5fa0-42cd-8ce2-af87f748cee4,lecture2.pdf,CSCI_80,16,"2
3
4
5
6
7
3
4
5
6
7
8
4
5
6
7
8
9
5
6
7
8
9
10
6
7
8
9
10
11
7
8
9
10
11
12",77,recursive
906cb8cb-7d6a-40f2-8eb2-4d3d32b0dc6f,lecture2.pdf,CSCI_80,17,"P(sum to 7) =
P(sum to 12) = 1
36
6
36 = 1
6",44,recursive
068aa616-c568-4466-aa35-47927f6880e0,lecture2.pdf,CSCI_80,18,"unconditional probability
degree of belief in a proposition 
in the absence of any other evidence",97,recursive
338c0b96-39e5-4524-adba-3c8156202c7e,lecture2.pdf,CSCI_80,19,"conditional probability
degree of belief in a proposition 
given some evidence that has already 
been revealed",110,recursive
326f467e-aba6-4889-bc74-c1f6dec6b39a,lecture2.pdf,CSCI_80,20,"conditional probability
P(a | b)",32,recursive
6aa0e4ef-a432-451c-a5b5-6a5a1a32b957,lecture2.pdf,CSCI_80,21,P(rain today | rain yesterday),30,recursive
8b800d96-8409-4fff-a956-fc9d78704598,lecture2.pdf,CSCI_80,22,P(route change | traffic conditions),36,recursive
336cde31-fb44-4edb-8156-83f9b5d5a7fc,lecture2.pdf,CSCI_80,23,P(disease | test results),25,recursive
aa8b2529-c854-40b8-981f-47a328b15ae4,lecture2.pdf,CSCI_80,24,"P(a| b) = P(a ∧ b)
P(b)",23,recursive
a87a4fbd-732f-461a-8d07-8054885a7aec,lecture2.pdf,CSCI_80,25,P(sum 12 |    ),15,recursive
da6a456b-69a0-41dc-97ca-d4ee7a22e7e0,lecture2.pdf,CSCI_80,27,"= 1
6P(    )",12,recursive
7756ddda-199b-4940-94d4-48f49fa09a67,lecture2.pdf,CSCI_80,28,"= 1
6P(    )
= 1
36P(sum 12)
= 1
6P(sum 12 |    )",49,recursive
7656b483-8432-4019-b157-5a4e04324906,lecture2.pdf,CSCI_80,29,"P(a| b) = P(a ∧ b)
P(b)
P(a ∧ b) = P(b)P(a| b)
P(a ∧ b) = P(a)P(b| a)",69,recursive
ad59aeaf-f5a6-46fd-b983-77e841b9370e,lecture2.pdf,CSCI_80,30,"random variable
a variable in probability theory with a 
domain of possible values it can take on",97,recursive
f6612890-1851-480b-b1a2-6f2cee5fc4e3,lecture2.pdf,CSCI_80,31,"random variable
Roll 
{1, 2, 3, 4, 5, 6}",40,recursive
1bb1da86-a383-45f3-9e38-feac5c317d30,lecture2.pdf,CSCI_80,32,"random variable
Weather 
{sun, cloud, rain, wind, snow}",55,recursive
eca02cad-b0de-468f-bfbc-3578badf5829,lecture2.pdf,CSCI_80,33,"random variable
Traffic 
{none, light, heavy}",45,recursive
d0f9176c-218b-4724-ac70-fbdcd1dde63b,lecture2.pdf,CSCI_80,34,"random variable
Flight 
{on time, delayed, cancelled}",53,recursive
8a83d291-cf99-4f3e-b066-e2aa6bdf9cf1,lecture2.pdf,CSCI_80,35,"probability distribution
P(Flight = on time) = 0.6 
P(Flight = delayed) = 0.3 
P(Flight = cancelled) = 0.1",106,recursive
97ae4fdd-ed65-4a9b-893b-41a1d1bf9690,lecture2.pdf,CSCI_80,36,"probability distribution
P(Flight) = ⟨0.6, 0.3, 0.1⟩",52,recursive
f449c1d9-84db-43fb-b066-6a3ff8489b47,lecture2.pdf,CSCI_80,37,"independence
the knowledge that one event occurs does 
not affect the probability of the other event",100,recursive
8d6cce6d-1ca3-4922-b070-a29ec14da1d9,lecture2.pdf,CSCI_80,38,"independence
P(a ∧ b) = P(a)P(b| a)",35,recursive
b7c69802-d15a-4710-8194-4901a66bb5d6,lecture2.pdf,CSCI_80,39,"independence
P(a ∧ b) = P(a)P(b)",32,recursive
a6f76583-6cf5-48cd-baac-ccd65f735428,lecture2.pdf,CSCI_80,40,"independence
P(        ) = P(    )P(    )
= 1
6 ⋅ 1
6 = 1
36",60,recursive
71bdbc37-5695-42d5-88e1-3400a4d57c24,lecture2.pdf,CSCI_80,41,"independence
P(        ) ≠ P(    )P(    )
= 1
6 ⋅ 1
6 = 1
36",60,recursive
d7acf4b4-ce9e-4f29-9af5-3f4aefa1e6a9,lecture2.pdf,CSCI_80,42,"independence
P(        ) ≠ P(    )P(     |    )
= 1
6 ⋅ 0 = 0",61,recursive
6f420016-feee-4872-ba44-bf475a65546d,lecture2.pdf,CSCI_80,43,Bayes' Rule,11,recursive
17b71882-a656-4280-9c9c-490fe86c03d4,lecture2.pdf,CSCI_80,44,"P(a ∧ b) = P(b) P(a| b)
P(a ∧ b) = P(a) P(b| a)",47,recursive
5903a09f-11b6-4768-8162-19d7ec03009e,lecture2.pdf,CSCI_80,45,= P(b) P(a| b)P(a) P(b| a),26,recursive
c6d2ef28-7f8b-40b1-acbd-cf393330a996,lecture2.pdf,CSCI_80,46,"= P(b) P(a| b)
P(a)
P(b| a)
Bayes' Rule",39,recursive
089c4a6c-b4fb-464e-b496-c35d7c4b81e3,lecture2.pdf,CSCI_80,47,"= P(b)P(a| b)
P(a)
P(b| a)
Bayes' Rule",38,recursive
14f01a28-631c-4d5d-bad9-2cc01290ae41,lecture2.pdf,CSCI_80,48,"PMAM
Given clouds in the morning, 
what's the probability of rain in the afternoon?
• 80% of rainy afternoons start with cloudy 
  mornings. 
• 40% of days have cloudy mornings. 
• 10% of days have rainy afternoons.",215,recursive
d6e19270-9132-4857-8216-5f76fd8fea47,lecture2.pdf,CSCI_80,49,"P(rain| clouds) = P(clouds| rain)P(rain)
P(clouds)
= (.8)(.1)
.4
= 0.2",70,recursive
02f15d17-4aa0-47cd-bd66-4950c12d6746,lecture2.pdf,CSCI_80,50,"P(cloudy morning | rainy afternoon)
Knowing
we can calculate
P(rainy afternoon | cloudy morning)",96,recursive
e51fc10a-64c2-4cc5-829e-20934e83c30f,lecture2.pdf,CSCI_80,51,"P(visible effect | unknown cause)
Knowing
we can calculate
P(unknown cause | visible effect)",92,recursive
f12a19e8-6c94-45d9-ab1e-5f5d8734d45c,lecture2.pdf,CSCI_80,52,"P(medical test result | disease)
Knowing
we can calculate
P(disease | medical test result)",90,recursive
2874686f-9e20-40fc-9411-27f3b3a272bb,lecture2.pdf,CSCI_80,53,"P(blurry text | counterfeit bill)
Knowing
we can calculate
P(counterfeit bill | blurry text)",92,recursive
60b46f2b-6fcf-45f6-837c-9eae973a86b0,lecture2.pdf,CSCI_80,54,Joint Probability,17,recursive
e5878e35-3ef9-4469-bf13-f5756e1ec665,lecture2.pdf,CSCI_80,55,"C = cloud C = ¬cloud
0.4 0.6
AM
R = rain R = ¬rain
C = cloud 0.08 0.32
C = ¬cloud 0.02 0.58
PM
R = rain R = ¬rain
0.1 0.9
AM
PM",127,recursive
454d0fbf-7a67-45f7-abb8-cce6ada10082,lecture2.pdf,CSCI_80,56,"P(C | rain)
R = rain R = ¬rain
C = cloud 0.08 0.32
C = ¬cloud 0.02 0.58
P(C | rain) = P(C, rain)
P(rain) = αP(C, rain)
= α⟨0.08, 0.02⟩ = ⟨0.8, 0.2⟩",147,recursive
26b092af-3c2a-4576-a1de-b95cd0387aaa,lecture2.pdf,CSCI_80,57,Probability Rules,17,recursive
0acf82da-bb2c-40b1-bd44-ee8b58e4693e,lecture2.pdf,CSCI_80,58,"P(¬ a) = 1 − P(a)
Negation",26,recursive
21e933d6-078d-4657-82a7-39d23e14846b,lecture2.pdf,CSCI_80,59,"P(a ∨ b) = P(a) + P(b) − P(a ∧ b)
Inclusion-Exclusion",53,recursive
4dce5f0e-1b09-4dab-8016-ac4b32fc79c6,lecture2.pdf,CSCI_80,60,"P(a) = P(a, b) + P(a, ¬ b)
Marginalization",42,recursive
8ef75dc8-28a5-43f3-af64-07a0ba4ccf89,lecture2.pdf,CSCI_80,61,"P(X = xi) = ∑j
P(X = xi, Y = yj)
Marginalization",48,recursive
75c4cc42-da05-4469-9c51-5995b9cd3d0a,lecture2.pdf,CSCI_80,62,"Marginalization
R = rain R = ¬rain
C = cloud 0.08 0.32
C = ¬cloud 0.02 0.58
P(C = cloud)
= P(C = cloud, R = rain) + P(C = cloud, R = ¬ rain)
= 0.08 + 0.32
= 0.40",161,recursive
739d153a-c80c-4898-98d1-e8a4b8a3ac11,lecture2.pdf,CSCI_80,63,"P(a) = P(a| b)P(b) + P(a| ¬ b)P(¬ b)
Conditioning",49,recursive
167ae867-8bb0-4725-82e3-226cc9c39372,lecture2.pdf,CSCI_80,64,"P(X = xi) = ∑j
P(X = xi | Y = yj)P(Y = yj)
Conditioning",55,recursive
14171ee1-7788-4b3e-b5e4-e5e873d7d3fc,lecture2.pdf,CSCI_80,65,Bayesian Networks,17,recursive
8b457ee8-ab82-474b-a0ec-2af192fc4056,lecture2.pdf,CSCI_80,66,"Bayesian network
data structure that represents the 
dependencies among random variables",88,recursive
47aa881c-6d56-4940-b2ab-03425615b59c,lecture2.pdf,CSCI_80,67,"Bayesian network
• directed graph 
• each node represents a random variable 
• arrow from X to Y means X is a parent of Y 
• each node X has probability distribution 
P(X | Parents(X))",184,recursive
83198f39-ca94-40fb-a01e-865cf76673a4,lecture2.pdf,CSCI_80,68,"Appointment 
{attend, miss}
Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}",103,recursive
dc9c9b91-9cc7-41dc-8cf3-e161a61f0d58,lecture2.pdf,CSCI_80,69,"Rain 
{none, light, heavy}
none light heavy
0.7 0.2 0.1",55,recursive
1e8f9641-107d-4edc-a2e3-ff1fa9833ebd,lecture2.pdf,CSCI_80,70,"Maintenance 
{yes, no}
Rain 
{none, light, heavy}
R yes no
none 0.4 0.6
light 0.2 0.8
heavy 0.1 0.9",99,recursive
68d84700-af18-4cf6-9490-50a21cdd3ef6,lecture2.pdf,CSCI_80,71,"Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}
R M on time delayed
none yes 0.8 0.2
none no 0.9 0.1
light yes 0.6 0.4
light no 0.7 0.3
heavy yes 0.4 0.6
heavy no 0.5 0.5",198,recursive
f85c3759-ef82-4eae-b3c5-f7e17bf69916,lecture2.pdf,CSCI_80,72,"Appointment 
{attend, miss}
Train 
{on time, delayed}
Maintenance 
{yes, no}
T attend miss
on time 0.9 0.1
delayed 0.6 0.4",122,recursive
36a10337-7157-4c9a-81be-a7f2355ce156,lecture2.pdf,CSCI_80,73,"Appointment 
{attend, miss}
Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}",103,recursive
40848761-a528-415b-a7ec-dcce76d0f7a3,lecture2.pdf,CSCI_80,74,"Appointment 
{attend, miss}
Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}
P(light)
P(light)
Computing Joint Probabilities",151,recursive
0edb1703-03d0-4434-99c7-e89b08bb57e9,lecture2.pdf,CSCI_80,75,"Appointment 
{attend, miss}
Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}
P(light, no)
P(light) P(no | light)
Computing Joint Probabilities",169,recursive
d633b4de-fdea-41bf-8c51-c675b19bbbbd,lecture2.pdf,CSCI_80,76,"Appointment 
{attend, miss}
Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}
P(light, no, delayed)
P(light) P(no | light) P(delayed | light, no)
Computing Joint Probabilities",201,recursive
a5c72d97-8caa-4407-9ed1-b4e2f450ff6f,lecture2.pdf,CSCI_80,77,"Appointment 
{attend, miss}
Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}
P(light, no, delayed, miss)
P(light) P(no | light) P(delayed | light, no) P(miss | delayed)
Computing Joint Probabilities",225,recursive
c85a24db-defe-4363-98e5-376821d6976d,lecture2.pdf,CSCI_80,78,Inference,9,recursive
fee8f30f-00be-4e4c-8a50-9f9bd8011597,lecture2.pdf,CSCI_80,79,"Inference
•Query X: variable for which to compute distribution 
•Evidence variables E: observed variables for event e 
•Hidden variables Y: non-evidence, non-query variable. 
•Goal: Calculate P(X | e)",200,recursive
3e905ebe-a926-4ad0-9127-334f0751196e,lecture2.pdf,CSCI_80,80,"Appointment 
{attend, miss}
Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}
P(Appointment | light, no)
 = α P(Appointment, light, no)
 = α [P(Appointment, light, no, on time) 
    + P(Appointment, light, no, delayed)]",245,recursive
0804e31b-b051-4cc4-a1a5-2d527f62cdf3,lecture2.pdf,CSCI_80,81,"∑
Inference by Enumeration
P(X | e) = α P(X, e) = α  
y
 P(X, e, y)
X is the query variable. 
e is the evidence. 
y ranges over values of hidden variables. 
α normalizes the result.",181,recursive
b3ce44f5-615a-4b71-b6bd-43b7a78c8ac7,lecture2.pdf,CSCI_80,82,Approximate Inference,21,recursive
ba987870-38ba-4c46-98c6-60a4c89124b9,lecture2.pdf,CSCI_80,83,Sampling,8,recursive
c1fd2d20-6380-429d-b355-4fb033eda8cd,lecture2.pdf,CSCI_80,84,"Appointment 
{attend, miss}
Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}",103,recursive
98568bea-2368-42cc-912f-e91556acf549,lecture2.pdf,CSCI_80,85,"Rain 
{none, light, heavy}
none light heavy
0.7 0.2 0.1
R = none",64,recursive
3e07d677-109c-4094-9f5b-69b91ebd1b62,lecture2.pdf,CSCI_80,86,"Maintenance 
{yes, no}
Rain 
{none, light, heavy}
R yes no
none 0.4 0.6
light 0.2 0.8
heavy 0.1 0.9
R = none
M = yes",116,recursive
2c4bf1dd-ccb3-4704-b97b-b75bc3e7ef0f,lecture2.pdf,CSCI_80,87,"Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}
R M on time delayed
none yes 0.8 0.2
none no 0.9 0.1
light yes 0.6 0.4
light no 0.7 0.3
heavy yes 0.4 0.6
heavy no 0.5 0.5
R = none
M = yes
T = on time",227,recursive
3cb5fbd2-4a58-4539-be3c-33267f33e887,lecture2.pdf,CSCI_80,88,"Appointment 
{attend, miss}
Train 
{on time, delayed}
Maintenance 
{yes, no}
T attend miss
on time 0.9 0.1
delayed 0.6 0.4
R = none
M = yes
T = on time
A = attend",162,recursive
ba2ac111-a05f-45bb-a121-9b53ce903183,lecture2.pdf,CSCI_80,89,"R = none
M = yes
T = on time
A = attend",39,recursive
6fd5248a-7952-4ebb-8c78-c26ada2ed95b,lecture2.pdf,CSCI_80,90,"R = none
M = yes
T = on time
A = attend
R = none
M = no
T = on time
A = attend
R = light
M = yes
T = delayed
A = attend
R = light
M = no
T = on time
A = miss
R = none
M = yes
T = on time
A = attend
R = none
M = yes
T = on time
A = attend
R = heavy
M = no
T = delayed
A = miss
R = light
M = no
T = on time
A = attend",315,recursive
5a87e85a-0a86-4364-8f61-d78abdbd37b3,lecture2.pdf,CSCI_80,91,P(Train = on time) ?,20,recursive
e301b6b6-bbfa-490f-97c2-2f1fca591d60,lecture2.pdf,CSCI_80,92,"R = none
M = yes
T = on time
A = attend
R = none
M = no
T = on time
A = attend
R = light
M = yes
T = delayed
A = attend
R = light
M = no
T = on time
A = miss
R = none
M = yes
T = on time
A = attend
R = none
M = yes
T = on time
A = attend
R = heavy
M = no
T = delayed
A = miss
R = light
M = no
T = on time
A = attend",315,recursive
9b2757f5-d9e5-4818-a0d4-5322b8afa69d,lecture2.pdf,CSCI_80,93,"R = none
M = yes
T = on time
A = attend
R = none
M = no
T = on time
A = attend
R = light
M = yes
T = delayed
A = attend
R = light
M = no
T = on time
A = miss
R = none
M = yes
T = on time
A = attend
R = none
M = yes
T = on time
A = attend
R = heavy
M = no
T = delayed
A = miss
R = light
M = no
T = on time
A = attend",315,recursive
4d744e5c-9590-4ad8-b20a-cc786941dddf,lecture2.pdf,CSCI_80,94,P(Rain = light | Train = on time) ?,35,recursive
6003f230-c459-4160-ae78-5597d565df96,lecture2.pdf,CSCI_80,95,"R = none
M = yes
T = on time
A = attend
R = none
M = no
T = on time
A = attend
R = light
M = yes
T = delayed
A = attend
R = light
M = no
T = on time
A = miss
R = none
M = yes
T = on time
A = attend
R = none
M = yes
T = on time
A = attend
R = heavy
M = no
T = delayed
A = miss
R = light
M = no
T = on time
A = attend",315,recursive
fc2d976d-b116-4850-8fb2-3c1dbdc25f54,lecture2.pdf,CSCI_80,96,"R = none
M = yes
T = on time
A = attend
R = none
M = no
T = on time
A = attend
R = light
M = yes
T = delayed
A = attend
R = light
M = no
T = on time
A = miss
R = none
M = yes
T = on time
A = attend
R = none
M = yes
T = on time
A = attend
R = heavy
M = no
T = delayed
A = miss
R = light
M = no
T = on time
A = attend",315,recursive
41cb84cc-5463-403a-b0d5-fcac0d1b750b,lecture2.pdf,CSCI_80,97,"R = none
M = yes
T = on time
A = attend
R = none
M = no
T = on time
A = attend
R = light
M = yes
T = delayed
A = attend
R = light
M = no
T = on time
A = miss
R = none
M = yes
T = on time
A = attend
R = none
M = yes
T = on time
A = attend
R = heavy
M = no
T = delayed
A = miss
R = light
M = no
T = on time
A = attend",315,recursive
1b48208d-634e-4716-b3e1-457a64ff37be,lecture2.pdf,CSCI_80,98,Rejection Sampling,18,recursive
8bb16fb9-268a-45db-936e-ee6f1d9b83dc,lecture2.pdf,CSCI_80,99,Likelihood Weighting,20,recursive
557060c8-841a-42e2-8bec-eb49cebe6fd7,lecture2.pdf,CSCI_80,100,"Likelihood Weighting
•Start by fixing the values for evidence variables. 
•Sample the non-evidence variables using conditional 
probabilities in the Bayesian Network. 
•Weight each sample by its likelihood: the probability 
of all of the evidence.",247,recursive
64ec46bf-3401-4abc-bd7b-cda0162688d2,lecture2.pdf,CSCI_80,101,P(Rain = light | Train = on time) ?,35,recursive
11aa5890-5126-4b33-ac2f-ce9ade181057,lecture2.pdf,CSCI_80,102,"Appointment 
{attend, miss}
Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}",103,recursive
449fad66-e6f6-4235-a586-eaad0b1edf39,lecture2.pdf,CSCI_80,103,"Rain 
{none, light, heavy}
none light heavy
0.7 0.2 0.1
T = on time
R = light",77,recursive
f6c82ed6-16e1-486c-99d8-5f40d01a7989,lecture2.pdf,CSCI_80,104,"Maintenance 
{yes, no}
Rain 
{none, light, heavy}
R yes no
none 0.4 0.6
light 0.2 0.8
heavy 0.1 0.9
T = on time
R = lightR = light
M = yes",138,recursive
87ec382d-ef4b-43e2-935f-de9dd8b4ffa5,lecture2.pdf,CSCI_80,105,"Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}
R M on time delayed
none yes 0.8 0.2
none no 0.9 0.1
light yes 0.6 0.4
light no 0.7 0.3
heavy yes 0.4 0.6
heavy no 0.5 0.5
T = on time
R = lightR = light
M = yes",237,recursive
fbf2e16b-ce34-4ad0-abfe-46b3ed91aa80,lecture2.pdf,CSCI_80,106,"Appointment 
{attend, miss}
Train 
{on time, delayed}
Maintenance 
{yes, no}
T attend miss
on time 0.9 0.1
delayed 0.6 0.4
T = on time
R = lightR = light
M = yes
R = light
M = yes
A = attend",190,recursive
6a7eed3a-ccbd-474c-afa7-bb653509f9bb,lecture2.pdf,CSCI_80,107,"Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}
R M on time delayed
none yes 0.8 0.2
none no 0.9 0.1
light yes 0.6 0.4
light no 0.7 0.3
heavy yes 0.4 0.6
heavy no 0.5 0.5
T = on time
R = lightR = light
M = yes
R = light
M = yes
A = attend",266,recursive
2baac1c7-ea91-4b31-b399-1f4c6cad8ac9,lecture2.pdf,CSCI_80,108,"Train 
{on time, delayed}
Maintenance 
{yes, no}
Rain 
{none, light, heavy}
R M on time delayed
none yes 0.8 0.2
none no 0.9 0.1
light yes 0.6 0.4
light no 0.7 0.3
heavy yes 0.4 0.6
heavy no 0.5 0.5
T = on time
R = lightR = light
M = yes
R = light
M = yes
A = attend",266,recursive
0ad69d5a-b3c9-4a54-82a8-8a3e78d41c1c,lecture2.pdf,CSCI_80,109,Uncertainty over Time,21,recursive
3559c346-f19c-4dee-9170-4b05693791b0,lecture2.pdf,CSCI_80,110,Xt: Weather at time t,21,recursive
244990e7-d432-4f88-a60f-09ec78a63dd7,lecture2.pdf,CSCI_80,111,"Markov assumption
the assumption that the current state 
depends on only a finite fixed number of 
previous states",114,recursive
fe5c8a19-1220-4fe5-be44-756033d7a9f3,lecture2.pdf,CSCI_80,112,Markov Chain,12,recursive
58ec8168-a0d6-40bf-bafe-65a8cdc6a695,lecture2.pdf,CSCI_80,113,"Markov chain
a sequence of random variables where the 
distribution of each variable follows the 
Markov assumption",115,recursive
c70ac1d5-a4f1-49f0-8932-834e72037760,lecture2.pdf,CSCI_80,114,"0.8 0.2
0.3 0.7
Today (Xt)
Tomorrow (Xt+1)
Transition Model",59,recursive
2631b8d8-806b-4e68-bfb7-337eb00c77e0,lecture2.pdf,CSCI_80,115,X0 X1 X2 X3 X4,14,recursive
042672b9-86e1-4b11-a825-b75ac61de398,lecture2.pdf,CSCI_80,116,Sensor Models,13,recursive
2946f49d-2f18-4aa2-931c-9052e1dcb7c8,lecture2.pdf,CSCI_80,117,"Hidden State Observation
robot's position robot's sensor data
words spoken audio waveforms
user engagement website or app analytics
weather umbrella",148,recursive
dddd4a56-83d2-41ea-87b0-df1ca200a636,lecture2.pdf,CSCI_80,118,Hidden Markov Models,20,recursive
bbbfb7f9-ab1c-46c1-8187-88a028bc0995,lecture2.pdf,CSCI_80,119,"Hidden Markov Model
a Markov model for a system with hidden 
states that generate some observed event",101,recursive
e4bee15f-0d2e-4c22-aacc-63af05a2a8b4,lecture2.pdf,CSCI_80,120,"0.2 0.8
0.9 0.1
State (Xt)
Observation (Et)
Sensor Model",56,recursive
6974e80c-de0e-4ae7-ad2b-bfbc4485b5ee,lecture2.pdf,CSCI_80,121,"sensor Markov assumption
the assumption that the evidence variable 
depends only the corresponding state",104,recursive
fe6aff39-39bb-4087-aa31-60a9d8a4eeff,lecture2.pdf,CSCI_80,122,"X0 X1 X2 X3 X4
E0 E1 E2 E3 E4",29,recursive
8714d49a-25cf-4202-b9f6-89caae2e9fda,lecture2.pdf,CSCI_80,123,"Task Definition
filtering given observations from start until now, 
calculate distribution for current state
prediction given observations from start until now, 
calculate distribution for a future state
smoothing given observations from start until now, 
calculate distribution for past state
most likely 
explanation
given observations from start until now, 
calculate most likely sequence of states",401,recursive
c445faa0-894c-4bdb-8a51-a88997c9eefe,lecture2.pdf,CSCI_80,124,Uncertainty,11,recursive
9280866f-05b8-4ad9-af46-ef8cb923412c,lecture2.pdf,CSCI_80,125,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
6c10d267-c29e-42ae-9418-c13085014fa6,lecture6.pdf,CSCI_80,0,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
7cdaecdb-7962-48bc-bd41-f7c4b92ee483,lecture6.pdf,CSCI_80,1,Language,8,recursive
d04cf1b5-ddf4-436e-830d-d93f61e6e41b,lecture6.pdf,CSCI_80,2,Natural Language Processing,27,recursive
f3e46d9e-17f8-42c4-9617-7875a6f215c3,lecture6.pdf,CSCI_80,3,"Natural Language Processing
•automatic summarization 
•information extraction 
•machine translation 
•question answering 
•text classification 
•...",148,recursive
5fec587b-e265-442b-9099-60a496794f70,lecture6.pdf,CSCI_80,4,Syntax,6,recursive
dedb66a4-195d-4617-b108-c4fee3e4a40f,lecture6.pdf,CSCI_80,5,"""Just before nine o'clock Sherlock 
Holmes stepped briskly into the room.""",74,recursive
d3c7e013-3dfc-4f02-b809-362fe3ffeb3d,lecture6.pdf,CSCI_80,6,"""Just before Sherlock Holmes nine 
o'clock stepped briskly the room.""",69,recursive
66767c25-abb7-4c2a-8c94-cb98af7eb334,lecture6.pdf,CSCI_80,7,"""I saw the man on the mountain 
 with a telescope.""",51,recursive
ae9b7fcf-218c-45ed-bde2-a0ba55c989f7,lecture6.pdf,CSCI_80,8,Semantics,9,recursive
dfd1debb-d549-4df8-8dca-1b9a613be8a2,lecture6.pdf,CSCI_80,9,"""Just before nine o'clock Sherlock  
 Holmes stepped briskly into the room.""",76,recursive
ab653fe3-f4f4-4d07-963b-86cc7a83b6ee,lecture6.pdf,CSCI_80,10,"""A few minutes before nine, Sherlock  
 Holmes walked quickly into the room.""",77,recursive
4dcddfc4-78e9-4250-a0f6-55fe056a8979,lecture6.pdf,CSCI_80,11,"""Colorless green ideas sleep furiously.""",40,recursive
4359d319-40d8-485d-a0b1-93f433c6d35c,lecture6.pdf,CSCI_80,12,Natural Language Processing,27,recursive
93ff67d6-46ce-4618-875c-046a4461a270,lecture6.pdf,CSCI_80,13,"formal grammar
a system of rules for generating sentences 
in a language",72,recursive
d66c191b-1e66-4499-be0b-8302ead73d3e,lecture6.pdf,CSCI_80,14,Context-Free Grammar,20,recursive
dc22c597-f238-4474-91e3-17a0d2858fb0,lecture6.pdf,CSCI_80,15,"N
she
V
saw
V D
the
N
city",26,recursive
7eddf0c8-0cd2-4098-ab34-73fd1ef83270,lecture6.pdf,CSCI_80,16,"N
she
V
saw
V D
the
N
city",26,recursive
c49330b8-b07d-4457-85a9-bebe970faa77,lecture6.pdf,CSCI_80,17,"N → she | city | car | Harry | ...
D → the | a | an | ...
V → saw | ate | walked | ...
P → to | on | over | ...
ADJ → blue | busy | old | ...",141,recursive
5db76d78-bf50-47bc-bf14-9f9231021678,lecture6.pdf,CSCI_80,18,NP → N | D N,12,recursive
44e3edda-efaa-4234-aa05-8ca408b622bd,lecture6.pdf,CSCI_80,19,"NP → N | D N N
she
NP",21,recursive
3efc392b-d541-4cb6-934d-6433ee529db8,lecture6.pdf,CSCI_80,20,"NP → N | D N D
the
N
city
NP",28,recursive
4d536583-8b12-47a0-99ec-1632a83f96f4,lecture6.pdf,CSCI_80,21,VP → V | V NP,13,recursive
eb248f67-5843-4434-b51e-91723033b111,lecture6.pdf,CSCI_80,22,"V
walked
VP
VP → V | V NP",25,recursive
d64f84cc-d136-4580-8928-5877c16ee4f0,lecture6.pdf,CSCI_80,23,"D
the
N
city
NPV
saw
V
VP
VP → V | V NP",39,recursive
535f45f0-142c-489b-b95d-4cafb09e4818,lecture6.pdf,CSCI_80,24,S → NP VP,9,recursive
fe7427be-6832-4594-a64b-a941709b5150,lecture6.pdf,CSCI_80,25,"S → NP VP
D
the
N
city
NPV
saw
V
VPNP
she
S
N",45,recursive
d6dfa6f3-7f7f-48e5-a55b-d2f64c8395ab,lecture6.pdf,CSCI_80,26,nltk,4,recursive
a09b029c-b949-49e1-aa4f-989f3eb198c7,lecture6.pdf,CSCI_80,27,"n-gram
a contiguous sequence of n items 
from a sample of text",62,recursive
af57b9a8-c6c6-4cb1-bab9-9350900ba934,lecture6.pdf,CSCI_80,28,"""How often have I said to you that 
when you have eliminated the 
impossible whatever remains, 
however improbable, must be the 
truth?""",136,recursive
2e2d4944-5d8f-4b02-ab78-bdfb673f9231,lecture6.pdf,CSCI_80,29,"""How often have I said to you that 
when you have eliminated the 
impossible whatever remains, 
however improbable, must be the 
truth?""",136,recursive
01d5a08e-a34b-4101-88f8-c6451b5ccf51,lecture6.pdf,CSCI_80,30,"""How often have I said to you that 
when you have eliminated the 
impossible whatever remains, 
however improbable, must be the 
truth?""",136,recursive
1ad27ec2-1393-4c93-8d6d-b9b39080fda0,lecture6.pdf,CSCI_80,31,"""How often have I said to you that 
when you have eliminated the 
impossible whatever remains, 
however improbable, must be the 
truth?""",136,recursive
502fb6cc-3919-4172-b5f1-3350aa570fe5,lecture6.pdf,CSCI_80,32,"""How often have I said to you that 
when you have eliminated the 
impossible whatever remains, 
however improbable, must be the 
truth?""",136,recursive
a14b6419-67a6-4dc4-9518-e8aa66c79b82,lecture6.pdf,CSCI_80,33,"""How often have I said to you that 
when you have eliminated the 
impossible whatever remains, 
however improbable, must be the 
truth?""",136,recursive
1b1659aa-2a67-4000-b2d0-841f084d8282,lecture6.pdf,CSCI_80,34,"""How often have I said to you that 
when you have eliminated the 
impossible whatever remains, 
however improbable, must be the 
truth?""",136,recursive
a38c697a-c221-402c-9646-56a030ef6a6f,lecture6.pdf,CSCI_80,35,"tokenization
the task of splitting a sequence of 
characters into pieces (tokens)",81,recursive
e6f24311-7605-43cf-8461-4c7f6da95514,lecture6.pdf,CSCI_80,36,Markov Chains,13,recursive
ca577842-2ed8-4220-84e9-ad0922de2a87,lecture6.pdf,CSCI_80,38,Text Categorization,19,recursive
ea128019-4a50-440c-adf7-61df32438112,lecture6.pdf,CSCI_80,39,"Inbox
 Spam",11,recursive
eb426a19-30a4-43ff-816f-915799d4c8c0,lecture6.pdf,CSCI_80,40,"😀
 🙁",4,recursive
02ac9cf8-e6c6-42af-b323-ca6ec971e3f6,lecture6.pdf,CSCI_80,41,"""My grandson loved it! So much fun!""
""Product broke after a few days.""
""One of the best games I've played in a 
long time.""
""Kind of cheap and flimsy, not worth it.""",165,recursive
d6d2d70a-e582-4185-bea4-0d20a52736ca,lecture6.pdf,CSCI_80,42,"""My grandson loved it! So much fun!""
""Product broke after a few days.""
""One of the best games I've played in a 
long time.""
""Kind of cheap and flimsy, not worth it.""
😀
🙁
😀
🙁",173,recursive
e1e0bf11-f300-45a2-b4a9-6b6ae03d0f11,lecture6.pdf,CSCI_80,43,"""My grandson loved it! So much fun!""
""Product broke after a few days.""
""One of the best games I've played in a 
long time.""
""Kind of cheap and ﬂimsy, not worth it.""
😀
🙁
😀
🙁",172,recursive
9c18dc06-cdf8-4ef3-a65e-e392f9767c76,lecture6.pdf,CSCI_80,44,"bag-of-words model
model that represents text as an unordered 
collection of words",82,recursive
20ce1ecd-4b24-4010-b7e6-75f77982177a,lecture6.pdf,CSCI_80,45,Naive Bayes,11,recursive
2832ec66-ac6c-467f-bce8-4af6ba42203a,lecture6.pdf,CSCI_80,46,"Bayes' Rule
= P(b)P(a| b)
P(a)
P(b| a)",38,recursive
77a93f43-06de-4ab8-9751-d220f29a0908,lecture6.pdf,CSCI_80,47,"P(Positive)
P(Negative)",23,recursive
762c9606-b431-48d5-83c7-0a8e4ca73e22,lecture6.pdf,CSCI_80,48,"P(
😀)
P(
🙁)",11,recursive
9842bbf4-c7f9-4d47-b0b4-e962a81d8d1c,lecture6.pdf,CSCI_80,49,"""My grandson loved it!""",23,recursive
4daa3061-6ebc-49f1-97cc-859d1d0311b5,lecture6.pdf,CSCI_80,50,"P(
😀)",5,recursive
69034a77-75b0-44b2-a6b3-a145ecbe5b4b,lecture6.pdf,CSCI_80,51,"P(
😀 | ""my grandson loved it"")",30,recursive
ac73ec1a-2041-4687-968f-24cc3c94a338,lecture6.pdf,CSCI_80,52,"P(
😀 | ""my"", ""grandson"", ""loved"", ""it"")",39,recursive
d63fd8f8-9f8e-4b90-8f62-7b8486efdf14,lecture6.pdf,CSCI_80,53,"P(
😀 | ""my"", ""grandson"", ""loved"", ""it"")",39,recursive
eea564b4-3a22-426d-904e-a27123a1dac9,lecture6.pdf,CSCI_80,54,"P(
😀 | ""my"", ""grandson"", ""loved"", ""it"")
equal to
P(""my"", ""grandson"", ""loved"", ""it"" | 
😀)
P(""my"", ""grandson"", ""loved"", ""it"")
P(
😀)",129,recursive
cc6b1d39-633c-4842-bc53-f49cbaf9f3ac,lecture6.pdf,CSCI_80,55,"P(
😀 | ""my"", ""grandson"", ""loved"", ""it"")
proportional to
P(""my"", ""grandson"", ""loved"", ""it"" | 
😀)P(
😀)",100,recursive
1c7d7e43-3912-4ed4-9ebf-7372cb4bff66,lecture6.pdf,CSCI_80,56,"P(
😀 | ""my"", ""grandson"", ""loved"", ""it"")
proportional to
P(
😀, ""my"", ""grandson"", ""loved"", ""it"")",94,recursive
b940fb2a-d814-44c6-b550-325cf2a38f8d,lecture6.pdf,CSCI_80,57,"P(
😀 | ""my"", ""grandson"", ""loved"", ""it"")
naively proportional to
P(
😀)P(""my"" | 
😀)P(""grandson"" | 
😀) 
P(""loved"" | 
😀) P(""it"" | 
😀)",129,recursive
f78b1715-f625-4c32-a016-d2f9605e7554,lecture6.pdf,CSCI_80,58,"P(
😀) = number of positive samples
number of total samples",58,recursive
707f6ab1-969c-4b4a-bcda-b6583019cd65,lecture6.pdf,CSCI_80,59,"P(""loved"" | 
😀) =
number of positive samples with ""loved""
number of positive samples",84,recursive
ef6f5d8e-bcd9-4072-b8d8-9529449c411f,lecture6.pdf,CSCI_80,60,"P(
😀)P(""my"" | 
😀)P(""grandson"" | 
😀) 
P(""loved"" | 
😀) P(""it"" | 
😀)
😀
 🙁
my 0.30 0.20
grandson 0.01 0.02
loved 0.32 0.08
it 0.30 0.40
😀
 🙁
0.49 0.51",146,recursive
4dae87de-e62f-4df4-a2ac-c101f97d6ce7,lecture6.pdf,CSCI_80,61,"P(
😀)P(""my"" | 
😀)P(""grandson"" | 
😀) 
P(""loved"" | 
😀) P(""it"" | 
😀)
😀
 🙁
my 0.30 0.20
grandson 0.01 0.02
loved 0.32 0.08
it 0.30 0.40
😀
 🙁
0.49 0.51",146,recursive
db0f4acb-f8b0-4286-b979-6a9288c1cdcf,lecture6.pdf,CSCI_80,62,"P(
😀)P(""my"" | 
😀)P(""grandson"" | 
😀) 
P(""loved"" | 
😀) P(""it"" | 
😀)
😀
 🙁
my 0.30 0.20
grandson 0.01 0.02
loved 0.32 0.08
it 0.30 0.40
😀
 🙁
0.49 0.51
😀 0.00014112",159,recursive
f9304ff0-af16-455e-b549-2e25115ad9ad,lecture6.pdf,CSCI_80,63,"P(
😀)P(""my"" | 
😀)P(""grandson"" | 
😀) 
P(""loved"" | 
😀) P(""it"" | 
😀)
😀
 🙁
my 0.30 0.20
grandson 0.01 0.02
loved 0.32 0.08
it 0.30 0.40
😀
 🙁
0.49 0.51
😀 0.00014112",159,recursive
56cd6aa9-7c2c-4819-90cb-372c95584d20,lecture6.pdf,CSCI_80,64,"P(
🙁)P(""my"" | 
🙁)P(""grandson"" | 
🙁) 
P(""loved"" | 
🙁) P(""it"" | 
🙁)
😀
 🙁
my 0.30 0.20
grandson 0.01 0.02
loved 0.32 0.08
it 0.30 0.40
😀
 🙁
0.49 0.51
😀 0.00014112",159,recursive
b76819a5-de57-4a5f-bb1a-d92935161a8f,lecture6.pdf,CSCI_80,65,"P(
🙁)P(""my"" | 
🙁)P(""grandson"" | 
🙁) 
P(""loved"" | 
🙁) P(""it"" | 
🙁)
😀
 🙁
my 0.30 0.20
grandson 0.01 0.02
loved 0.32 0.08
it 0.30 0.40
😀
 🙁
0.49 0.51
😀 0.00014112",159,recursive
b1dd8200-58dd-4a44-8253-d924613fc06d,lecture6.pdf,CSCI_80,66,"P(
🙁)P(""my"" | 
🙁)P(""grandson"" | 
🙁) 
P(""loved"" | 
🙁) P(""it"" | 
🙁)
😀
 🙁
my 0.30 0.20
grandson 0.01 0.02
loved 0.32 0.08
it 0.30 0.40
😀
 🙁
0.49 0.51
😀 0.00014112
🙁 0.00006528",172,recursive
ad60fbfb-0fd7-4dae-9267-92036ea18e34,lecture6.pdf,CSCI_80,67,"P(
🙁)P(""my"" | 
🙁)P(""grandson"" | 
🙁) 
P(""loved"" | 
🙁) P(""it"" | 
🙁)
😀
 🙁
my 0.30 0.20
grandson 0.01 0.02
loved 0.32 0.08
it 0.30 0.40
😀
 🙁
0.49 0.51
😀 0.00014112
🙁 0.00006528",172,recursive
68698d60-4060-4aa7-a4d2-0645a2c2ebb0,lecture6.pdf,CSCI_80,68,"P(
🙁)P(""my"" | 
🙁)P(""grandson"" | 
🙁) 
P(""loved"" | 
🙁) P(""it"" | 
🙁)
😀
 🙁
my 0.30 0.20
grandson 0.01 0.02
loved 0.32 0.08
it 0.30 0.40
😀
 🙁
0.49 0.51
😀 0.6837
🙁 0.3163",164,recursive
820c7f36-5191-44f9-a6a4-71c553d4901b,lecture6.pdf,CSCI_80,69,"P(
🙁)P(""my"" | 
🙁)P(""grandson"" | 
🙁) 
P(""loved"" | 
🙁) P(""it"" | 
🙁)
😀
 🙁
my 0.30 0.20
grandson 0.01 0.02
loved 0.32 0.08
it 0.30 0.40
😀
 🙁
0.49 0.51",146,recursive
4307f883-48e7-48bf-a56e-0b9d4e8a91ee,lecture6.pdf,CSCI_80,70,"P(
🙁)P(""my"" | 
🙁)P(""grandson"" | 
🙁) 
P(""loved"" | 
🙁) P(""it"" | 
🙁)
😀
 🙁
my 0.30 0.20
grandson 0.00 0.02
loved 0.32 0.08
it 0.30 0.40
😀
 🙁
0.49 0.51",146,recursive
08dc6a8a-433e-4873-9288-896dce88f56f,lecture6.pdf,CSCI_80,71,"P(
🙁)P(""my"" | 
🙁)P(""grandson"" | 
🙁) 
P(""loved"" | 
🙁) P(""it"" | 
🙁)
😀
 🙁
my 0.30 0.20
grandson 0.00 0.02
loved 0.32 0.08
it 0.30 0.40
😀
 🙁
0.49 0.51
😀 0.00000000
🙁 0.00006528",172,recursive
acf1ab13-3f5c-4e75-b724-cf1f3454743c,lecture6.pdf,CSCI_80,72,"additive smoothing
adding a value α to each value in our 
distribution to smooth the data",89,recursive
90a079b9-7a64-4757-bfb5-f0bed9baa5ea,lecture6.pdf,CSCI_80,73,"Laplace smoothing
adding 1 to each value in our distribution: 
pretending we've seen each value one more 
time than we actually have",132,recursive
95617dcd-c7e5-4823-a85d-70eb156e0b03,lecture6.pdf,CSCI_80,74,Word Representation,19,recursive
38c8f2a4-12f8-4a7f-8372-b05b9a1a97f7,lecture6.pdf,CSCI_80,76,"""He wrote a book.""
he    [1, 0, 0, 0]
wrote [0, 1, 0, 0]
a     [0, 0, 1, 0]
book  [0, 0, 0, 1]",94,recursive
5a4bb29a-ae16-4264-923b-8174f7299f69,lecture6.pdf,CSCI_80,77,"one-hot representation
representation of meaning as a vector with 
a single 1, and with other values as 0",105,recursive
818969cb-772d-47d4-9623-939667c88f60,lecture6.pdf,CSCI_80,78,"""He wrote a book.""
he    [1, 0, 0, 0]
wrote [0, 1, 0, 0]
a     [0, 0, 1, 0]
book  [0, 0, 0, 1]",94,recursive
5ed7e427-1b29-41af-b86d-3c1f861c2c44,lecture6.pdf,CSCI_80,79,"""He wrote a book.""
he    [1, 0, 0, 0, 0, 0, 0, ...]
wrote [0, 1, 0, 0, 0, 0, 0, ...]
a     [0, 0, 1, 0, 0, 0, 0, ...]
book  [0, 0, 0, 1, 0, 0, 0, ...]",150,recursive
3a8ef55b-5dd8-480c-947e-15363bbf38ba,lecture6.pdf,CSCI_80,80,"""He wrote a book.""
""He authored a novel.""
wrote    [0, 1, 0, 0, 0, 0, 0, ...]
authored [0, 0, 0, 0, 1, 0, 0, ...]
book     [0, 0, 0, 1, 0, 0, 0, ...]
novel    [0, 0, 0, 0, 0, 0, 1, ...]",185,recursive
6a56cf13-cf0a-480b-93e2-64f17f648c9a,lecture6.pdf,CSCI_80,81,"distributed representation
representation of meaning distributed 
across multiple values",88,recursive
76050f25-13f9-4f58-9e25-1c33b5b10229,lecture6.pdf,CSCI_80,82,"""He wrote a book.""
he    [-0.34, -0.08, 0.02, -0.18, 0.22, ...]
wrote [-0.27, 0.40, 0.00, -0.65, -0.15, ...]
a     [-0.12, -0.25, 0.29, -0.09, 0.40, ...]
book  [-0.23, -0.16, -0.05, -0.57, 0.05, ...]",199,recursive
8f1087ae-a10b-406c-967b-798b67b2ce2c,lecture6.pdf,CSCI_80,83,"""You shall know a word 
 by the company it keeps.""
J. R. Firth, 1957",68,recursive
c3264542-d02e-40c5-a110-6573ed9ef0e9,lecture6.pdf,CSCI_80,84,for he ate,10,recursive
c538f7f2-cfc5-4a78-a7f1-a86b0845ac57,lecture6.pdf,CSCI_80,85,for breakfast he ate,20,recursive
93b304dc-d0ae-472d-be51-56ad01c12fde,lecture6.pdf,CSCI_80,86,for lunch he ate,16,recursive
477ed11c-4ebb-4464-8b9d-65c9eaacf82d,lecture6.pdf,CSCI_80,87,for dinner he ate,17,recursive
03fe345d-a11a-468d-882c-d4e1e3939f15,lecture6.pdf,CSCI_80,88,for he ate,10,recursive
224fec94-f7ba-4d1e-bd24-5e06debecd06,lecture6.pdf,CSCI_80,89,"word2vec
model for generating word vectors",42,recursive
075758a0-b4cf-48ee-b4f4-963e9e59c7c8,lecture6.pdf,CSCI_80,90,"breakfast
lunch
dinner
book
novel
memoir",40,recursive
413744b5-c895-4aa2-b665-d8586ee6245c,lecture6.pdf,CSCI_80,91,"breakfast
lunchdinner
book
novel
memoir",39,recursive
c68d1c9e-818e-4540-9471-54782f5a5c7b,lecture6.pdf,CSCI_80,92,"king - man
king
man
king - man
woman",36,recursive
4912c53c-e6cc-42d7-acfc-84009985e3ba,lecture6.pdf,CSCI_80,93,"king - man
king
man
king - man
woman
queen",42,recursive
e35d5e2a-ab04-4f72-ac43-9a8c7b59564e,lecture6.pdf,CSCI_80,94,Neural Networks,15,recursive
cfc04ed7-bbcb-4d69-8e78-494b3cbedf51,lecture6.pdf,CSCI_80,96,input network output,20,recursive
247452dd-328b-4c33-a6d9-b323a5a865db,lecture6.pdf,CSCI_80,97,word word,9,recursive
39f3be55-5bf5-44a5-87ac-4a9059ef12c7,lecture6.pdf,CSCI_80,98,English French,14,recursive
50c8fa1e-a609-4122-9862-dff77af0ade4,lecture6.pdf,CSCI_80,99,lamp lampe,10,recursive
4655bedc-d738-441d-a783-9d1725eafda8,lecture6.pdf,CSCI_80,100,"The only light in 
the room came 
from the lamp 
upon the table at 
which I had been 
reading.
La pièce n'était 
éclairée que par 
la lampe placée 
sur la table où je 
lisais.",175,recursive
7ac6359e-1c60-4900-abba-a32172df9353,lecture6.pdf,CSCI_80,101,"What is the 
capital of 
Massachusetts?
The capital 
is Boston.",63,recursive
d4646ed4-2a3b-4fa1-9b29-9d1af8e2a8e6,lecture6.pdf,CSCI_80,102,"hidden state
what
is
the
capital",32,recursive
a9899965-945c-42ad-992f-a6860b107c8e,lecture6.pdf,CSCI_80,103,"what
is
the
capital",19,recursive
3e3ec8d2-bd12-43e0-a134-161a3f62ddc6,lecture6.pdf,CSCI_80,104,"capital
of
Massachusetts
The<end>",33,recursive
986f1cec-6b3a-4c4e-ace3-b67ced2f2642,lecture6.pdf,CSCI_80,105,"capital
of
Massachusetts
The<end>",33,recursive
5c1188ea-3d48-431d-b96f-f40ffefff74c,lecture6.pdf,CSCI_80,106,"The<end>
capitalThe
iscapital
Bostonis",38,recursive
fdde943d-393b-4dd7-9038-ad175f83a4da,lecture6.pdf,CSCI_80,107,"The<end>
capitalThe
iscapital
Bostonis",38,recursive
39e84945-4815-4e88-ab5b-3af1d049537b,lecture6.pdf,CSCI_80,108,"capitalThe
iscapital
Bostonis
<end>Boston",41,recursive
adfb9497-da79-41bc-92c4-db0dfc54e7e9,lecture6.pdf,CSCI_80,109,"input sequence
output sequence 
<end>
<end>",43,recursive
c387024d-3757-41e5-a9b1-e6d7289c995c,lecture6.pdf,CSCI_80,110,"input sequence
output sequence 
<end>
<end>",43,recursive
713be3c8-0de1-4373-9719-cfa2fa6e2b4d,lecture6.pdf,CSCI_80,111,"input sequence
output sequence 
<end>
<end>",43,recursive
8c7337ca-fc83-4eec-9ea2-972a8e267bd8,lecture6.pdf,CSCI_80,112,"input sequence
output sequence 
<end>
<end>",43,recursive
4a88a76a-d6a8-479d-ba6c-57f978d73526,lecture6.pdf,CSCI_80,113,"input sequence
output sequence 
<end>
<end>",43,recursive
1b78b480-91af-4ab3-9e6d-a1a75a68d450,lecture6.pdf,CSCI_80,114,"input sequence
output sequence 
<end>
<end>",43,recursive
10a2b119-b237-40fb-ac89-3a229d6d89d1,lecture6.pdf,CSCI_80,115,Attention,9,recursive
998d21d1-6875-4f4b-8176-538bafe3a5e4,lecture6.pdf,CSCI_80,116,"what is the capital of Massachusetts
the capital is",51,recursive
ca7f12d0-d3a7-43a7-a248-936f5a77f957,lecture6.pdf,CSCI_80,117,"what is the capital of Massachusetts
the capital is",51,recursive
1aaea685-2518-4ee7-9fa0-f13399ed6dee,lecture6.pdf,CSCI_80,118,"what is the capital of Massachusetts
the capital is
0.620.280.04 0.030.02 0.01
××××××
+ + + + + =",97,recursive
e26d010a-5415-41bd-a03e-177682b01bb0,lecture6.pdf,CSCI_80,119,"what is the capital of Massachusetts
the capital is Boston
0.620.280.04 0.030.02 0.01
××××××
+ + + + + =",104,recursive
07e88fe3-aea9-4e77-91a8-d33d7cbdb56a,lecture6.pdf,CSCI_80,120,"input sequence
output sequence 
<end>
<end>",43,recursive
c112081f-b3c2-4b33-a8b8-a1956f719d62,lecture6.pdf,CSCI_80,121,"L'
agreement
The
on
the
European
Economic
Area
was
signed
in
August
1992
.
<end>
accord
sur
la
zone
économique
européenne
a
été
signé
en
août
1992
.
<end> Adapted from Bahdanau et al. 2015. 
Neural machine translation by jointly 
learning to align and translate",261,recursive
9a393bee-8a81-40f1-8da8-9308da95f61e,lecture6.pdf,CSCI_80,122,"input sequence
output sequence 
<end>
<end>",43,recursive
258dbccc-e216-401b-982b-27992365ed24,lecture6.pdf,CSCI_80,123,Transformers,12,recursive
285b12e3-a19e-4185-bae3-2b72fbef0934,lecture6.pdf,CSCI_80,124,input sequence,14,recursive
1da10d06-a6db-4ff3-b665-6f19081867cc,lecture6.pdf,CSCI_80,125,"Neural Network
Neural Network
Neural Network
Neural Network
input sequence",74,recursive
9b219b0c-2fff-4a7b-813f-9aab8cb3499a,lecture6.pdf,CSCI_80,126,"input 
word
encoded 
representation 
Neural Network",51,recursive
ce9d5d90-b82b-4387-b979-aae33fbc6d00,lecture6.pdf,CSCI_80,127,"input 
word
encoded 
representation 
Neural Network
positional 
encoding
+",74,recursive
20ecbb4c-dfc7-403d-aee5-51b98e03193b,lecture6.pdf,CSCI_80,128,"input 
word
encoded 
representation 
Neural Network
positional 
encoding
+ Self-Attention",89,recursive
48e409d1-ab71-499a-9138-f428c862a824,lecture6.pdf,CSCI_80,129,"input 
word
encoded 
representation 
Neural Network
positional 
encoding
+ Self-AttentionSelf-AttentionSelf-Attention",117,recursive
eec7407a-c8b3-4118-b239-329d9d7f3759,lecture6.pdf,CSCI_80,130,"input 
word
encoded 
representation 
Neural Network
positional 
encoding
+ Self-AttentionSelf-AttentionSelf-Attention
x N",121,recursive
f2ab344b-dbce-4d9d-9c6e-9d7927280bbf,lecture6.pdf,CSCI_80,131,"Neural Network+ Self-AttentionSelf-AttentionSelf-Attention
Neural Network+ Self-AttentionSelf-AttentionSelf-Attention
Neural Network+ Self-AttentionSelf-AttentionSelf-Attention
Neural Network+ Self-AttentionSelf-AttentionSelf-Attention",235,recursive
25b90cf5-d667-422b-9adf-f15cc3313944,lecture6.pdf,CSCI_80,132,"Neural Network+ Self-AttentionSelf-AttentionSelf-Attention
Neural Network+ Self-AttentionSelf-AttentionSelf-Attention
Neural Network+ Self-AttentionSelf-AttentionSelf-Attention
Neural Network+ Self-AttentionSelf-AttentionSelf-Attention
encoded representations",259,recursive
b3015050-42ae-48ff-8c90-5c4d29b86b13,lecture6.pdf,CSCI_80,133,"previous 
output 
word
next 
output 
word
positional 
encoding
+ Neural 
Network
Self-AttentionSelf-AttentionSelf-Attention
x N",127,recursive
36ba4d73-b808-46d3-bcd0-79fe3191b846,lecture6.pdf,CSCI_80,134,"previous 
output 
word
next 
output 
word
positional 
encoding
+ Neural 
Network
Self-AttentionSelf-AttentionSelf-Attention
AttentionAttentionAttention
encoded 
representations
x N",180,recursive
06227420-c793-4d18-b905-6c9ed70387d2,lecture6.pdf,CSCI_80,135,"encoded 
representation
input 
word
positional 
encoding
previous 
output 
word
next 
output 
word
positional 
encoding
+ Neural 
Network
Self-AttentionSelf-AttentionSelf-Attention
AttentionAttentionAttention
x N
Neural Network+ Self-AttentionSelf-AttentionSelf-Attention",271,recursive
2d9d4932-80fb-4626-9737-b4748cd91339,lecture6.pdf,CSCI_80,136,Language,8,recursive
ab4e12cb-9b9f-4afd-88aa-50f5e0ade50c,lecture6.pdf,CSCI_80,137,Artiﬁcial Intelligence,22,recursive
3781c3f7-d3ea-43a1-9df8-8dbee8c640be,lecture6.pdf,CSCI_80,138,"Search
O
X X
O X",16,recursive
aa969ffc-7549-4fb1-b94b-d9a3d6fa703a,lecture6.pdf,CSCI_80,139,"Knowledge
P → Q
Q
P",19,recursive
38c26032-4207-49bd-a6bf-0cfa085190c7,lecture6.pdf,CSCI_80,140,Uncertainty,11,recursive
bacd9563-f560-4238-b712-a3f890d058d7,lecture6.pdf,CSCI_80,141,Optimization,12,recursive
ee675b48-aa87-4017-b245-c1edf2b58821,lecture6.pdf,CSCI_80,142,"Learning
 Inbox
Spam",20,recursive
192fbd61-9f50-4653-aaed-ae0d6e4974e5,lecture6.pdf,CSCI_80,143,"Neural 
Networks",16,recursive
50671322-caab-4ceb-94e9-563bfd632cd6,lecture6.pdf,CSCI_80,144,"Language
NP
NP PP
ADJ N P N
artificial
intelligence
with
python",63,recursive
8973b55e-28fe-4f82-8bad-f766b57762bd,lecture6.pdf,CSCI_80,145,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
8ee3cb92-1c2f-453b-bbf3-f391edc955ea,Lecture_Notes6.pdf,CSCI_80,0,"Language So far in the course, we needed to shape tasks and data such that an AI will be able to process them. Today, we will look at how an AI can be constructed to process human language.  1. Natural Language Processing Natural Language Processing spans all tasks where the AI gets human language as input. The following are a few examples of such tasks:  a. automaBc summarizaBon, where the AI is given text as input, and it produces a summary of the text as output. b. informaBon extracBon, where the AI is given a corpus of text and the AI extracts data as output. c. language idenBﬁcaBon, where the AI is given text and returns the language of the text as output. d. machine translaBon, where the AI is given a text in the origin language, and it outputs the translaBon in the target language. e. named enBty recogniBon, where the AI is given text and it extracts the names of the enBBes in the text (for example, names of companies). f",942,recursive
d0cc3cd1-3355-46f1-ac92-5e60b98d0c31,Lecture_Notes6.pdf,CSCI_80,0,". e. named enBty recogniBon, where the AI is given text and it extracts the names of the enBBes in the text (for example, names of companies). f. speech recogniBon, where the AI is given speech, and it produces the same words in text. g. text classiﬁcaBon, where the AI is given text and it needs to classify it as some type of text. h. word sense disambiguaBon, where the AI needs to choose the right meaning of a word that has mulBple meanings (e.g. bank means both a ﬁnancial insBtuBon and the ground on the sides of a river).  2. Syntax and Seman9cs 2.1. Syntax Syntax is sentence structure. As naBve speakers of some human language, we don’t struggle with producing grammaBcal sentences and ﬂagging non-grammaBcal sentences as wrong. For example, the sentence “Just before nine o’clock Sherlock Holmes stepped briskly into the room” is grammaBcal, whereas the sentence “Just before Sherlock Holmes nine o’clock stepped briskly the room” is non-grammaBcal",959,recursive
49cf4906-0601-419a-bac8-479f09daeea2,Lecture_Notes6.pdf,CSCI_80,0,". Syntax can be grammaBcal and ambiguous at the same Bme, as in “I saw the man with the telescope.” Did I see (the man with the telescope) or did I see (the man), doing so by looking through the telescope? To be able to parse human speech and produce it, the AI needs to command syntax.  2.2. Seman-cs SemanBcs is the meaning of words or sentences. While the sentence “Just before nine o’clock Sherlock Holmes stepped briskly into the room” is syntacBcally diﬀerent from “Sherlock Holmes stepped briskly into the room just before nine o’clock,” their content is eﬀecBvely idenBcal. Similarly, although the sentence “A few minutes before nine, Sherlock Holmes walked quickly",673,recursive
a48685f5-7599-4cd1-b83e-ef83bfbdeb14,Lecture_Notes6.pdf,CSCI_80,1,"into the room” uses diﬀerent words from the previous sentences, it sBll carries a very similar meaning. Moreover, a sentence can be perfectly grammaBcal while being completely nonsensical, as in Chomsky’s example, “Colorless green ideas sleep furiously.” To be able to parse human speech and produce it, the AI needs to command semanBcs.  A sentence has terminals and non terminals.  Part of speech: noun, verb, adverb, adjecBves, determinants.  e.g. I will wear a red shirt if I go shopping later.  Verb phrase: verb + adv like tore yesterday. P: PreposiBon: I V: Verb : will | wear | go D: determinant: a Adj: AdjecBve: Red N: Noun : shirt C: ConjuncBon: if   A dv: Adverb : shopping | later   3. Context-Free Grammar/Formal Grammar Formal Grammar is a system of rules for generaBng sentences in a language. In Context-Free Grammar, the text is abstracted from its meaning to represent the structure of the sentence using formal grammar",938,recursive
e1da5d41-513c-4e9c-b853-664dd8fbffb1,Lecture_Notes6.pdf,CSCI_80,1,". In Context-Free Grammar, the text is abstracted from its meaning to represent the structure of the sentence using formal grammar. Let’s consider the following example sentence:  She saw the city. This is a simple grammaBcal sentence, and we would like to generate a syntax tree represenBng its structure.  We start by assigning each word its part of speech. She and city are nouns, which we will mark as N. Saw is a verb, which we will mark as V. The is a determiner, marking the following noun as deﬁnite or indeﬁnite, and we will mark it as D. Now, the above sentence can be rewri]en as  3.1. N V D N So far, we have abstracted each word from its semanBc meaning to its part of speech. However, words in a sentence are connected to each other, and to understand the sentence we must understand how they connect. A noun phrase (NP) is a group of words that connect to a noun. For example, the word she is a noun phrase in this sentence",938,recursive
460ade28-0155-4e0f-8e12-cc8b3d5b1c77,Lecture_Notes6.pdf,CSCI_80,1,". A noun phrase (NP) is a group of words that connect to a noun. For example, the word she is a noun phrase in this sentence. In addiBon, the words the city also form a noun phrase, consisBng of a determiner and a noun. A verb phrase (VP) is a group of words that connect to a verb. The word saw is a verb phrase in itself. However, the words saw the city also make a verb phrase. In this case, it is a verb phrase consisBng of a verb and a noun phrase, which in turn consists of a determiner and a noun. Finally, the whole sentence (S) can be represented as follows:",567,recursive
54725920-8b49-454e-9fd9-c67bc2512a00,Lecture_Notes6.pdf,CSCI_80,2,"3.2. Syntac-c Tree  Using formal grammar, the AI is able to represent the structure of sentences. In the grammar we have described, there are enough rules to represent the simple sentence above. To represent more complex sentences, we will have to add more rules to our formal grammar.  4. nltk As is o_en the case in Python, mulBple libraries have been wri]en to implement the idea above. nltk (Natural Language Toolkit) is one such library. To analyze the sentence from above, we will provide the algorithm with rules for the grammar:  import nltk  grammar = nltk.CFG.fromstring(""""""     S -> NP VP      NP -> D N | N     VP -> V | V NP      D -> ""the"" | ""a""     N -> ""she"" | ""city"" | ""car""     V -> ""saw"" | ""walked"" """""")  parser = nltk.ChartParser(grammar) Similar to what we did above, we deﬁne what possible components could be included in others. A sentence can include a noun phrase and a verb phrase, while the phrases themselves can",940,recursive
5b3ad24d-3351-4d83-8ee0-e457ec6e77f0,Lecture_Notes6.pdf,CSCI_80,3,"consist of other phrases, nouns, verbs, etc., and, ﬁnally, each part of speech spans some words in the language.  sentence = input(""Sentence: "").split() try:     for tree in parser.parse(sentence):         tree.pre]y_print()         tree.draw() except ValueError:     print(""No parse tree possible."") A_er giving the algorithm an input sentence split into a list of words, the funcBon prints the resulBng syntacBc tree (pre]y_print) and also generates a graphic representaBon (draw).  SyntacBc Trees  5. n-grams An n-gram is a sequence of n items from a sample of text. In a character n-gram, the items are characters, and in a word n-gram the items are words. A unigram, bigram, and trigram are sequences of one, two, and three items",734,recursive
a11259d8-e12d-430d-b346-488eedeb7c76,Lecture_Notes6.pdf,CSCI_80,3,". In a character n-gram, the items are characters, and in a word n-gram the items are words. A unigram, bigram, and trigram are sequences of one, two, and three items. In the following sentence, the ﬁrst three n-grams are “how o_en have,” “o_en have I,” and “have I said.”  “How o_en have I said to you that when you have eliminated the impossible whatever remains, however improbable, must be the truth?”  n-grams are useful for text processing. While the AI hasn’t necessarily seen the whole sentence before, it sure has seen parts of it, like “have I said.” Since some words occur together more o_en then others, it is possible to also predict the next word with some probability. For example, your smartphone suggests words to you based on a probability distribuBon derived from the last few words you typed. Thus, a helpful step in natural language processing is breaking the sentence into n-grams.  6. Tokeniza9on TokenizaBon is the task of splieng a sequence of characters into pieces (tokens)",1000,recursive
1664a915-3348-46b4-b69f-1fc2d06df473,Lecture_Notes6.pdf,CSCI_80,3,". Thus, a helpful step in natural language processing is breaking the sentence into n-grams.  6. Tokeniza9on TokenizaBon is the task of splieng a sequence of characters into pieces (tokens). Tokens can be words as well as sentences, in which case the task is called word tokenizaBon or sentence tokenizaBon. We need tokenizaBon to be able to look at n-grams, since those rely on sequences of tokens. We start by splieng the text into words based on the space character. While this is a good start, this method is imperfect because we end up with words with punctuaBon, such as “remains,”. So, for example, we can remove punctuaBon. However, then we face addiBonal challenges, such as words with apostrophes (e.g. “o’clock”) and hyphens (e.g. “pearl-grey). AddiBonally, some punctuaBon is important for sentence structure, like periods. However, we need to be able to tell apart between a period at the end of the word “Mr.” and a period in the end of the sentence",963,recursive
a9e1a361-4088-4c46-b6be-e793ad299e3c,Lecture_Notes6.pdf,CSCI_80,3,". However, we need to be able to tell apart between a period at the end of the word “Mr.” and a period in the end of the sentence. Dealing with these quesBons is the process of tokenizaBon. In the end, once we have our tokens, we can start looking at n-grams.",259,recursive
291e7aba-6904-4026-809f-dc8690355ce5,Lecture_Notes6.pdf,CSCI_80,4,"7. Markov Models As discussed in previous lectures, Markov models consist of nodes, the value of each of which has a probability distribuBon based on a ﬁnite number of previous nodes. Markov models can be used to generate text. To do so, we train the model on a text, and then establish probabiliBes for every n-th token in an n-gram based on the n words preceding it. For example, using trigrams, a_er the Markov model has two words, it can choose a third one from a probability distribuBon based on the ﬁrst two. Then, it can choose a fourth word from a probability distribuBon based on the second and third words. To see an implementaBon of such a model using nltk, refer to generator.py in the source code, where our model learns to generate Shakespeare-sounding sentences. Eventually, using Markov models, we are able to generate text that is o_en grammaBcal and sounding superﬁcially similar to human language output. However, these sentences lack actual meaning and purpose.  8",984,recursive
013ce967-8ffe-45da-9803-9aebb26845ab,Lecture_Notes6.pdf,CSCI_80,4,". However, these sentences lack actual meaning and purpose.  8. Bag-of-Words Model Bag-of-words is a model that represents text as an unordered collecBon of words. This model ignores syntax and considers only the meanings of the words in the sentence. This approach is helpful in some classiﬁcaBon tasks, such as senBment analysis (another classiﬁcaBon task would be disBnguishing regular email from spam email). SenBment analysis can be used, for instance, in product reviews, categorizing reviews as posiBve or negaBve. Consider the following sentences:  “My grandson loved it! So much fun!” “Product broke a_er a few days.” “One of the best games I’ve played in a long Bme.” “Kind of cheap and ﬂimsy, not worth it.” Based only on the words in each sentence and ignoring the grammar, we can see that sentences 1 and 3 are posiBve (“loved,” “fun,” “best”) and sentences 2 and 4 are negaBve (“broke,” “cheap,” “ﬂimsy”).  9",922,recursive
c0ef3154-68ce-4735-a8cc-25eca0f941ec,Lecture_Notes6.pdf,CSCI_80,4,".  9. Naive Bayes Naive Bayes is a technique that’s can be used in senBment analysis with the bag-of-words model. In senBment analysis, we are asking “What is the probability that the sentence is posiBve/negaBve given the words in the sentence.” Answering this quesBon requires compuBng condiBonal probability, and it is helpful to recall Bayes’ rule from lecture 2:  Bayes' Rule",379,recursive
0feb5cc4-1b5c-46cc-b052-28f2e5487af2,Lecture_Notes6.pdf,CSCI_80,5,"Now, we would like to use this formula to ﬁnd P(senBment | text), or, for example, P(posiBve | “my grandson loved it”). We start by tokenizing the input, such that we end up with P(posiBve | “my”, “grandson”, “loved”, “it”). Applying Bayes’ ruled directly, we get the following expression: P(“my”, “grandson”, “loved”, “it” | posiBve)*P(posiBve)/P(“my”, “grandson”, “loved”, “it”). This complicated expression will give us the precise answer to P(posiBve | “my”, “grandson”, “loved”, “it”).  However, we can simplify the expression if we are willing to get an answer that’s not equal, but proporBonal to P(posiBve | “my”, “grandson”, “loved”, “it”). Later on, knowing that the probability distribuBon needs to sum up to 1, we can normalize the resulBng value into an exact probability. This means that we can simplify the expression above to the numerator only: P(“my”, “grandson”, “loved”, “it” | posiBve)*P(posiBve)",917,recursive
2f0bc07f-6bb1-40f0-9769-4cc750c4269f,Lecture_Notes6.pdf,CSCI_80,5,". This means that we can simplify the expression above to the numerator only: P(“my”, “grandson”, “loved”, “it” | posiBve)*P(posiBve). Again, we can simplify this expression based on the knowledge that a condiBonal probability of a given b is proporBonal to the joint probability of a and b. Thus, we get the following expression for our probability: P(posiBve, “my”, “grandson”, “loved”, “it”)*P(posiBve). CalculaBng this joint probability, however, is complicated, because the probability of each word is condiBoned on the probabiliBes of the words preceding it. It requires us to compute P(posiBve)*P(“my” | posiBve)*P(“grandson” | posiBve, “my”)*P(loved | posiBve, “my”, “grandson”)*P(“it” | posiBve, “my”, “grandson”, “loved”).  Here is where we use Bayes’ rules naively: we assume that the probability of each word is independent from other words. This is not true, but despite this imprecision, Naive Bayes’ produces a good senBment esBmate",947,recursive
28f3425d-3994-4f2a-9f3b-7d37afcef8f1,Lecture_Notes6.pdf,CSCI_80,5,". This is not true, but despite this imprecision, Naive Bayes’ produces a good senBment esBmate. Using this assumpBon, we end up with the following probability: P(posiBve)*P(“my” | posiBve)*P(“grandson” | posiBve)*P(“loved” | posiBve)*P(“it” | posiBve), which is not that diﬃcult to calculate. P(posiBve) = the number of all posiBve samples divided by the number of total samples. P(“loved” | posiBve) is equal to the number of posiBve samples with the word “loved” divided by the number of posiBve samples. Let’s consider the example below, with smiling and frowning emojies subsBtuBng the words “posiBve” and “negaBve”:",621,recursive
9292a14f-b844-4ab1-a61f-fdeed01bc8cf,Lecture_Notes6.pdf,CSCI_80,6,"On the right we are seeing a table with the condiBonal probabiliBes of each word on the le_ occurring in a sentence given that the sentence is posiBve or negaBve. In the small table on the le_ we are seeing the probability of a posiBve or a negaBve sentence. On the bo]om le_ we are seeing the resulBng probabiliBes following the computaBon. At this point, they are in proporBon to each other, but they don’t tell us much in terms of probabiliBes. To get the probabiliBes, we need to normalize the values, arriving at P(posiBve) = 0.6837 and P(negaBve) = 0.3163. The strength of naive Bayes is that it is sensiBve to words that occur more o_en in one type of sentence than in the other. In our case, the word “loved” occurs much more o_en in posiBve sentences, which makes the whole sentence more likely to be posiBve than negaBve. To see an implementaBon of senBment assessment using Naive Bayes with the nltk library, refer to senBment.py.   9.1",947,recursive
58bf088d-a35d-4c3a-ad86-6f7e8119851c,Lecture_Notes6.pdf,CSCI_80,6,". To see an implementaBon of senBment assessment using Naive Bayes with the nltk library, refer to senBment.py.   9.1. Smoothing One problem that we can run into is that some words may never appear in a certain type of sentence. Suppose none of the posiBve sentences in our sample had the word “grandson.” Then, P(“grandson” | posiBve) = 0, and when compuBng the probability of the sentence being posiBve we will get 0. However, this is not the case in reality (not all sentences menBoning grandsons are negaBve). One way to go about this problem is with Addi$ve Smoothing, where we add a value α to each value in our distribuBon to smooth the data. This way, even if a certain value is 0, by adding α to it we won’t be mulBplying the whole probability for a posiBve or negaBve sentence by 0. A speciﬁc type of addiBve smoothing, Laplace Smoothing adds 1 to each value in our distribuBon, pretending that all values have been observed at least once.  10",953,recursive
da858714-1984-4c55-b575-da5464114b6e,Lecture_Notes6.pdf,CSCI_80,6,". A speciﬁc type of addiBve smoothing, Laplace Smoothing adds 1 to each value in our distribuBon, pretending that all values have been observed at least once.  10. Word Representa9on We want to represent word meanings in our AI. As we’ve seen before, it is convenient to provide input to the AI in the form of numbers.   10.1. One-Hot Representa-on, One way to go about this is by using One-Hot Representa$on, where each word is represented with a vector that consists of as many values as we have words. Except for a single value in the vector that is equal to 1, all other values are equal to 0. How we can diﬀerenBate words is by",632,recursive
b6c4aed4-f47d-433d-b47f-4b9af9d20501,Lecture_Notes6.pdf,CSCI_80,7,"which of the values is 1, ending up with a unique vector per word. For example, the sentence “He wrote a book” can be represented as four vectors:  [1, 0, 0, 0] (he) [0, 1, 0, 0] (wrote) [0, 0, 1, 0] (a) [0, 0, 0, 1] (book) However, while this representaBon works in a world with four words, if we want to represent words from a dicBonary, when we can have 50,000 words, we will end up with 50,000 vectors of length 50,000. This is incredibly ineﬃcient. Another problem in this kind of representaBon is that we are unable to represent similarity between words like “wrote” and “authored.”   10.2. Distributed Representa-on Instead, we turn to the idea of Distributed Representa$on, where meaning is distributed across mulBple values in a vector",744,recursive
7fd0e7b5-5921-4a3d-9d7f-ecdde43508be,Lecture_Notes6.pdf,CSCI_80,7,". Distributed Representa-on Instead, we turn to the idea of Distributed Representa$on, where meaning is distributed across mulBple values in a vector. With distributed representaBon, each vector has a limited number of values (much less than 50,000), taking the following form:  [-0.34, -0.08, 0.02, -0.18, …] (he) [-0.27, 0.40, 0.00, -0.65, …] (wrote) [-0.12, -0.25, 0.29, -0.09, …] (a) [-0.23, -0.16, -0.05, -0.57, …] (book) This allows us to generate unique values for each word while using smaller vectors. AddiBonally, now we are able to represent similarity between words by how diﬀerent the values in their vectors are.  “You shall know a word by the company it keeps” is an idea by J. R. Firth, an English linguist. Following this idea, we can come to deﬁne words by their adjacent words",795,recursive
82e5cda1-9d9d-48c1-bce4-d4c1ffeccf0f,Lecture_Notes6.pdf,CSCI_80,7,".  “You shall know a word by the company it keeps” is an idea by J. R. Firth, an English linguist. Following this idea, we can come to deﬁne words by their adjacent words. For example, there are limited words that we can use to complete the sentence “for ___ he ate.” These words are probably words like “breakfast,” “lunch,” and “dinner.” This brings us to the conclusion that by considering the environment in which a certain word tends to appear, we can infer the meaning of the word.  11. word2vec word2vec is an algorithm for generaBng distributed representaBons of words. It does so by Skip-Gram Architecture, which is a neural network architecture for predicBng context given a target word. In this architecture, the neural network has an input unit for every target word. A smaller, single hidden layer (e.g. 50 or 100 units, though this number is ﬂexible) will generate values that represent the distributed representaBons of words",940,recursive
8ab93dc8-4687-4c4f-97bc-f758b0633fb1,Lecture_Notes6.pdf,CSCI_80,7,". A smaller, single hidden layer (e.g. 50 or 100 units, though this number is ﬂexible) will generate values that represent the distributed representaBons of words. Every unit in this hidden layer is connected to every unit in the input layer. The output layer will generate words that are likely to appear in a similar context as the target words. Similar to what we saw in last lecture, this network needs to be trained with a training dataset using the backpropagaBon algorithm.",480,recursive
ccf880c2-1741-4f19-8a2a-d83f14a9bcd8,Lecture_Notes6.pdf,CSCI_80,8,"11.1. Skip-Gram Architecture  This neural network turns out to be quite powerful. In the end, of the process, every word ends up being just a vector, or a sequence of numbers",174,recursive
6b8ea156-3c01-44d7-be7a-43b4c28f4d46,Lecture_Notes6.pdf,CSCI_80,8,". For example,  book: [-0.226776 -0.155999 -0.048995 -0.569774 0.053220 0.124401 -0.091108 -0.606255 -0.114630 0.473384 0.061061 0.551323 -0.245151 -0.014248 -0.210003 0.316162 0.340426 0.232053 0.386477 -0.025104 -0.024492 0.342590 0.205586 -0.554390 -0.037832 -0.212766 -0.048781 -0.088652 0.042722 0.000270 0.356324 0.212374 -0.188433 0.196112 -0.223294 -0.014591 0.067874 -0.448922 -0.290960 -0.036474 -0.148416 0.448422 0.016454 0.071613 -0.078306 0.035400 0.330418 0.293890 0.202701 0.555509 0.447660 -0.361554 -0.266283 -0.134947 0.105315 0.131263 0.548085 -0.195238 0.062958 -0.011117 -0.226676 0.050336 -0.295650 -0.201271 0.014450 0.026845 0.403077 -0.221277 -0.236224 0.213415 -0.163396 -0.218948 -0.242459 -0.346984 0.282615 0.014165 -0.342011 0.370489 -0.372362 0.102479 0.547047 0.020831 -0.202521 -0.180814 0.035923 -0.296322 -0.062603 0.232734 0.191323 0.251916 0.150993 -0.024009 0.129037 -0.033097 0.029713 0.125488 -0.018356 -0.226277 0.437586 0.004913]  By themselves, these",994,recursive
0d37aa89-7266-448a-bda4-868744ed6c6e,Lecture_Notes6.pdf,CSCI_80,8,"-0.202521 -0.180814 0.035923 -0.296322 -0.062603 0.232734 0.191323 0.251916 0.150993 -0.024009 0.129037 -0.033097 0.029713 0.125488 -0.018356 -0.226277 0.437586 0.004913]  By themselves, these numbers don’t mean much",216,recursive
3829d2dd-9e37-4baf-9ae3-bbbb0e781bd6,Lecture_Notes6.pdf,CSCI_80,8,". But by ﬁnding which other words in the corpus have the most similar vectors, we can run a funcBon that will generate the words that are the most similar to the word book. In the case of this network it will be: book, books, essay, memoir, essays, novella, anthology, blurb, autobiography, audiobook. This is not bad for a computer! Through a bunch of numbers that don’t carry any speciﬁc meaning themselves, the AI is able to generate words that really are very similar to book not in le]ers or sounds, but in meaning! We can also compute the diﬀerence between words based on how diﬀerent their vectors are. For example, the diﬀerence between king and man is similar to the diﬀerence between queen and woman. That is, if we add the diﬀerence between king and man to the vector for woman, the closest word to the resulBng vector is queen! Similarly, if we add the diﬀerence between ramen and japan to america, we get burritos",926,recursive
c6ea66e2-3eaf-46ee-87e2-6dd7fe859d2a,Lecture_Notes6.pdf,CSCI_80,8,". By using neural networks and distributed representaBons for words, we get our AI to understand semanBc similariBes between words in the language, bringing us one step closer to AIs that can understand and produce human language.  12. Neural Networks Recall that a neural network takes some input, passes it to the network, and creates some output. By providing the network with training data, it can do more and more of an accurate job of translaBng the input into an output. Commonly, machine translaBon uses neural networks. In pracBce, when we are translaBng words, we want to translate a sentence or paragraph. Since a sentence is a ﬁxed size, we run into the problem of translaBng a sequence to another sequence where sizes are not ﬁxed. If you have ever had a conversaBon with an AI chatbot, it needs to understand a sequence of words and generate an appropriate sequence as output.",890,recursive
3a996050-434b-497f-a882-51e5f1d86aad,Lecture_Notes6.pdf,CSCI_80,9,"12.1. Recurrent neural networks Recurrent neural networks can re-run the neural network mulBple Bmes, keeping track of a state that holds all relevant informaBon. Input is taken into the network, creaBng a hidden state. Passing a second input into the encoder, along with the ﬁrst hidden state, produces a new hidden state. This process is repeated unBl an end token is passed. Then, a decoding state begins, creaBng hidden state a_er hidden state unBl we get the ﬁnal word and another end token. Some problems, however, arise. One problem in the encoder stage where all the informaBon from the input stage must be stored in one ﬁnal state. For large sequences, it’s very challenging to store all that informaBon into a single state value. It would be useful to somehow combine all the hidden states. Another problem is that some of the hidden states in the input sequence are more important than others. Could there be some way to know what states (or words) are more important than others?  13",995,recursive
316d6df9-263d-410f-8b6a-0176662949ae,Lecture_Notes6.pdf,CSCI_80,9,". Another problem is that some of the hidden states in the input sequence are more important than others. Could there be some way to know what states (or words) are more important than others?  13. ASen9on A]enBon refers to the neural network’s ability to decide what values are more important than others. In the sentence “What is the capital of Massachuse]s,” a]enBon allows the neural network to decide what values it will pay a]enBon to at each stage of generaBng the output sentence. Running such a calculaBon, the neural network will show that when generaBng the ﬁnal word of the answer, “capital” and “Massachuse]s” are the most important to pay a]enBon to. By taking the a]enBon score, mulBplying them by the hidden state values generated by the network, and adding them up, the neural network will create a ﬁnal context vector that the decoder can use to calculate the ﬁnal word",887,recursive
e57e766e-1170-47cf-a427-390fc40ca113,Lecture_Notes6.pdf,CSCI_80,9,". A challenge that arises in calculaBons such as these is that recurrent neural networks require sequenBal training of word a_er word. This takes a lot of Bme. With the growth of large language models, they take longer and longer to train. A desire for parallelism has steadily grown as larger and larger datasets need to be trained. Hence, a new architecture has been introduced.  14. Transformers Transformers is a new type of training architecture whereby each input word is passed through a neural network simultaneously. An input word goes into the neural network and is captured as an encoded representaBon. Because all words are fed into the neural network at the same Bme, word order could easily be lost. Accordingly, posiBon encoding is added to the inputs. The neural network, therefore, will use both the word and the posiBon of the word in the encoded representaBon. AddiBonally, a self-a]enBon step is added to help deﬁne the context of the word being inpu]ed",973,recursive
e4084b9e-da28-4f04-a421-1259676a126b,Lecture_Notes6.pdf,CSCI_80,9,". AddiBonally, a self-a]enBon step is added to help deﬁne the context of the word being inpu]ed. In fact, neural networks will o_en use mulBple self-a]enBon steps such that they can further understand the context. This process is repeated mulBple Bmes for each of the words in the sequence. What results are encoded representaBons that will be useful when it’s Bme to decode the informaBon.  In the decoding step, the previous output word and its posiBonal encoding are given to mulBple self-a]enBon steps and the neural network. AddiBonally, mulBple a]enBon steps are fed the encoded representaBon from the encoding process and provided to the neural network. Hence,",667,recursive
43f940e2-8665-4805-b526-c31c63b89d1a,Lecture_Notes6.pdf,CSCI_80,10,"words are able to pay a]enBon to each other. Further, parallel processing is possible, and the calculaBons are fast and accurate.",129,recursive
ae45e912-bd21-405b-a7ac-87ccdac7e65e,lecture0.pdf,CSCI_80,0,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
1273d701-a2c2-4c06-88c2-00852dfabd60,lecture0.pdf,CSCI_80,1,Artiﬁcial Intelligence,22,recursive
a76da381-b8d8-4b76-8770-a033aae4f70b,lecture0.pdf,CSCI_80,2,"Search
O
X X
O X",16,recursive
fe0518eb-7dba-4972-b8b3-1681e49bc391,lecture0.pdf,CSCI_80,3,"Knowledge
P → Q
Q
P",19,recursive
77e1fa83-ac72-4127-a54e-19f6bbff60cd,lecture0.pdf,CSCI_80,4,Uncertainty,11,recursive
e21055e3-cf64-4cb9-9aee-69739ca64b8e,lecture0.pdf,CSCI_80,5,Optimization,12,recursive
2bfefee4-c106-4d89-8710-02bb65302e66,lecture0.pdf,CSCI_80,6,"Learning
 Inbox
Spam",20,recursive
58a5bd51-eeff-419f-ae45-9e6cfcb17081,lecture0.pdf,CSCI_80,7,"Neural 
Networks",16,recursive
fb6eaeff-52a6-4461-b851-0737c3c8aa93,lecture0.pdf,CSCI_80,8,"Language
NP
NP PP
ADJ N P N
artificial
intelligence
with
python",63,recursive
0c3995df-9d97-46ce-a0c4-258dac93e6ed,lecture0.pdf,CSCI_80,9,Search,6,recursive
234e6150-823c-43cb-bbfd-9b700c8c77cd,lecture0.pdf,CSCI_80,10,"1 2 3 4
5 6 7 8
9 10 11 12
13 14 15",35,recursive
cac2dc97-008a-459b-a03b-04540e56b274,lecture0.pdf,CSCI_80,13,Search Problems,15,recursive
0505fb83-0efa-4f6e-95d3-8c6bd831c1be,lecture0.pdf,CSCI_80,14,"agent
entity that perceives its environment 
and acts upon that environment",75,recursive
b607a5e8-3902-4f46-922e-096cd5ab2747,lecture0.pdf,CSCI_80,15,"state
a configuration of the agent and 
its environment",55,recursive
fab62ddb-294a-4d52-8d7c-092bae68c426,lecture0.pdf,CSCI_80,16,"5 742
1 1138
12
10614
15139
4 2912
3 1478
10
1161
15135
10 3415
11 12113
14 759
286",83,recursive
57c89bc1-76cc-4868-ad22-19cfad0864cd,lecture0.pdf,CSCI_80,17,"initial state
the state in which the agent begins",49,recursive
454cf32e-d2c2-4b07-9a24-cf239ea06bc6,lecture0.pdf,CSCI_80,18,"initial state
 5 742
1 1138
12
10614
15139",42,recursive
1cf9b0a5-f812-4c56-99c0-8b51a4bb7381,lecture0.pdf,CSCI_80,19,"actions
choices that can be made in a state",43,recursive
b506a2d7-1f62-4a9a-9fc5-7aafee53dd75,lecture0.pdf,CSCI_80,20,"actions
ACTIONS(s) returns the set of actions that 
can be executed in state s",78,recursive
e8fdef7a-80a6-4c17-85f5-6f109b34ec48,lecture0.pdf,CSCI_80,21,"actions
1 2
3
4",15,recursive
3458b52b-e3cf-4606-b10e-9a6fd54963b1,lecture0.pdf,CSCI_80,22,"transition model
a description of what state results from 
performing any applicable action in any 
state",105,recursive
28056f96-6440-4170-b701-032ff367c02f,lecture0.pdf,CSCI_80,23,"transition model
RESULT(s, a) returns the state resulting from 
performing action a in state s",94,recursive
ca564030-7aeb-47db-928c-bddf35b65278,lecture0.pdf,CSCI_80,24,"RESULT(                             ,             ) = 
5 742
1 1138
1210614
15139
5 742
1 1138
1210614
15139
RESULT(                             ,             ) = 
5 742
1 1138
1210614
15139
5 742
1 1138
12
10614
15139",218,recursive
c6b4eea8-415f-48d0-bed7-dbb610cc1e4b,lecture0.pdf,CSCI_80,25,"transition model
RESULT(                             ,             ) = 
5 742
1 1138
1210614
15139
5 742
1 1138
12
10614
15139",126,recursive
e5bac303-b588-496c-b187-8f99f0c39696,lecture0.pdf,CSCI_80,26,"state space
the set of all states reachable from the 
initial state by any sequence of actions",94,recursive
57d9ac9b-ddff-4288-b3fc-864ec802e094,lecture0.pdf,CSCI_80,27,"2 4 5 7
8 3 1 11
14 6 10 12
9 13 15
2 4 5 7
8 3 1 11
14 6 10 12
9 13 15
2 4 5 7
8 3 1 11
14 6 10
129 13 15
2 4 5 7
8 3 1 11
14 6
10
12
9 13 15
2 4 5 7
8 3 1 11
14 6 10 12
9 13 15
2 4 5 7
8 3 1 11
14 6 10
129 13 15
2 4 5 7
8 3 1
1114 6 10
129 13 15",247,recursive
0f563a98-6880-45de-8d22-2d4b4fd5b600,lecture0.pdf,CSCI_80,29,"goal test
way to determine whether a given state 
is a goal state",65,recursive
148d3ae5-2dff-4798-811d-7cd380f82dd0,lecture0.pdf,CSCI_80,30,"path cost
numerical cost associated with a given path",53,recursive
176de0d9-1c8f-480e-9e21-4a4939524a02,lecture0.pdf,CSCI_80,31,"C D
H
M
I
E
J
K
A
B
F G
L",25,recursive
3ef78d2c-7f28-4b37-b4e2-ecbd341f7f0c,lecture0.pdf,CSCI_80,32,"C D
H
M
I
E
J
K
A
B
F G
L
2
1
3 2
2 1
4
2
34
3
5
6
24",53,recursive
da21e59c-1454-4648-b0f3-e36b28f1f4a5,lecture0.pdf,CSCI_80,33,"C D
H
M
I
E
J
K
A
B
F G
L
1
1
1 1
1 1
1
1
11
1
1
1
11",53,recursive
1035fd04-2bd7-4373-a106-a81f6e265d9e,lecture0.pdf,CSCI_80,34,"Search Problems
•initial state 
•actions 
•transition model 
•goal test 
•path cost function",92,recursive
4ea5076d-f753-4d58-b5c5-e80565560ec0,lecture0.pdf,CSCI_80,35,"solution
a sequence of actions that leads from the 
initial state to a goal state",81,recursive
4e3ccf2a-3cf5-4887-ad22-609cd18b85b2,lecture0.pdf,CSCI_80,36,"optimal solution
a solution that has the lowest path cost 
among all solutions",78,recursive
f01fd636-d6d0-428a-92d1-81cf53c511fb,lecture0.pdf,CSCI_80,37,"node
a data structure that keeps track of 
- a state 
- a parent (node that generated this node) 
- an action (action applied to parent to get node) 
- a path cost (from initial state to node)",192,recursive
29214366-9c90-4e18-806b-1dd73de7e110,lecture0.pdf,CSCI_80,38,"Approach
•Start with a frontier that contains the initial state. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Expand node, add resulting nodes to the frontier.",259,recursive
ba5d97f2-689a-4122-90cd-27204de6ef9c,lecture0.pdf,CSCI_80,39,"E
A
B
C D
F
Frontier
Find a path from A to E.
•Start with a frontier that contains the initial state. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Expand node, add resulting nodes to the frontier.
A",298,recursive
1eae5f68-fb51-415c-bde1-36cc5cfe9b80,lecture0.pdf,CSCI_80,40,"E
A
B
C D
F
Frontier
Find a path from A to E.
•Start with a frontier that contains the initial state. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Expand node, add resulting nodes to the frontier.
A",298,recursive
221d3298-ee04-4931-8a6b-0c64bdba8044,lecture0.pdf,CSCI_80,41,"E
A
B
C D
F
Frontier
Find a path from A to E.
•Start with a frontier that contains the initial state. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Expand node, add resulting nodes to the frontier.
B",298,recursive
ecdc0cd4-8d8d-4f81-aadb-a6f12fe70f8d,lecture0.pdf,CSCI_80,42,"E
A
B
C D
F
Frontier
Find a path from A to E.
•Start with a frontier that contains the initial state. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Expand node, add resulting nodes to the frontier.
B",298,recursive
4408c3a2-97e8-46fe-8c07-d8c105653bb6,lecture0.pdf,CSCI_80,43,"E
A
B
C D
F
Frontier
Find a path from A to E.
•Start with a frontier that contains the initial state. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Expand node, add resulting nodes to the frontier.
C D",300,recursive
e47bfaa1-3897-4c71-a74b-87d3c98639b7,lecture0.pdf,CSCI_80,44,"E
A
B
C D
F
Frontier
Find a path from A to E.
•Start with a frontier that contains the initial state. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Expand node, add resulting nodes to the frontier.
C D",300,recursive
00aaf326-4175-4951-b743-aec1e06cf893,lecture0.pdf,CSCI_80,45,"E
A
B
C D
F
Frontier
Find a path from A to E.
•Start with a frontier that contains the initial state. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Expand node, add resulting nodes to the frontier.
D
E",300,recursive
fa8f0167-e8e4-4ca9-b81d-fdd4ce27da30,lecture0.pdf,CSCI_80,46,"E
A
B
C D
F
Frontier
Find a path from A to E.
•Start with a frontier that contains the initial state. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Expand node, add resulting nodes to the frontier.
DE",299,recursive
8c6f9931-a992-4f22-b476-92379d748a67,lecture0.pdf,CSCI_80,47,"E
A
B
C D
F
Frontier
Find a path from A to E.
•Start with a frontier that contains the initial state. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Expand node, add resulting nodes to the frontier.
D",298,recursive
3cb364fc-ad38-4012-90c7-47f5b7935a83,lecture0.pdf,CSCI_80,48,"E
A
B
C D
F
Frontier
Find a path from A to E.
•Start with a frontier that contains the initial state. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Expand node, add resulting nodes to the frontier.
D",298,recursive
b1ae6418-12f3-48ec-a902-f547fca78043,lecture0.pdf,CSCI_80,49,What could go wrong?,20,recursive
e3136a86-88d5-4ff5-a32e-3ea4cca05fb7,lecture0.pdf,CSCI_80,50,"E
A
B
C D
F
Frontier
Find a path from A to E. A",47,recursive
7f834b0a-cc77-4462-8310-83fc78d7999a,lecture0.pdf,CSCI_80,51,"E
A
B
C D
F
Frontier
Find a path from A to E.
A",47,recursive
d25fa5f9-19c5-43c2-b42e-22203c406ea5,lecture0.pdf,CSCI_80,52,"E
A
B
C D
F
Frontier
Find a path from A to E.
B",47,recursive
4fbea418-a5c6-45de-9e84-aa8bac83750b,lecture0.pdf,CSCI_80,53,"E
A
B
C D
F
Frontier
Find a path from A to E.
B",47,recursive
c240e14a-3889-47fd-a697-4f7c71be6f20,lecture0.pdf,CSCI_80,54,"E
A
B
C D
F
Frontier
Find a path from A to E. A
C D",51,recursive
a233eaa4-1a7c-4245-8872-b3bfbb3161e8,lecture0.pdf,CSCI_80,55,"E
A
B
C D
F
Frontier
Find a path from A to E.
A C D",51,recursive
e8352817-38a0-441e-a3e2-6ed1cd2b7bda,lecture0.pdf,CSCI_80,56,"E
A
B
C D
F
Frontier
Find a path from A to E.
C D",49,recursive
a56a06bd-2a75-4a75-b68d-99ab5c0acf8e,lecture0.pdf,CSCI_80,57,"Revised Approach
•Start with a frontier that contains the initial state. 
•Start with an empty explored set. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Add the node to the explored set. 
•Expand node, add resulting nodes to the frontier if they 
aren't already in the frontier or the explored set.",399,recursive
38b7a541-1042-4f06-99ae-ff13e6dc48dd,lecture0.pdf,CSCI_80,58,"Revised Approach
•Start with a frontier that contains the initial state. 
•Start with an empty explored set. 
•Repeat: 
•If the frontier is empty, then no solution. 
•Remove a node from the frontier. 
•If node contains goal state, return the solution. 
•Add the node to the explored set. 
•Expand node, add resulting nodes to the frontier if they 
aren't already in the frontier or the explored set.",399,recursive
e60b14ce-5a58-45d5-9058-1437910a636e,lecture0.pdf,CSCI_80,59,"stack
last-in first-out data type",33,recursive
6b8e7d83-ef25-4340-b3c4-4ee2583d8ca6,lecture0.pdf,CSCI_80,60,"E
A
B
C D
F
Frontier
Find a path from A to E. A
Explored Set",60,recursive
06a00457-150d-49a3-8cfd-670bd7f92141,lecture0.pdf,CSCI_80,61,"E
A
B
C D
F
Frontier
Find a path from A to E.
A
Explored Set",60,recursive
8cf1be77-daa3-4fa3-84cc-1bd502bf1c1d,lecture0.pdf,CSCI_80,62,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
B
A",62,recursive
58b6695a-7651-40af-afd8-8f7dc6a94039,lecture0.pdf,CSCI_80,63,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
B
A",62,recursive
51be7a6f-7206-4322-aeb3-d61a63b22531,lecture0.pdf,CSCI_80,64,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
C D
BA",65,recursive
7c8769c5-9639-4fec-9764-c6c5c9d61346,lecture0.pdf,CSCI_80,65,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
C D
BA",65,recursive
afa9ad5b-4a1c-40cf-8723-18c6d6e18130,lecture0.pdf,CSCI_80,66,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
C
F
BA D",67,recursive
c8c9ca98-b650-4b2f-8ec0-28a8082923f5,lecture0.pdf,CSCI_80,67,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
C F
BA D",67,recursive
0a1c320c-fa61-4bd2-901d-644166161edf,lecture0.pdf,CSCI_80,68,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
C
BA D F",67,recursive
f17d0089-6d17-477b-b170-67d8a108a16b,lecture0.pdf,CSCI_80,69,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
E
BA D F C",69,recursive
e829bb89-57d6-4438-a890-ad1c9d91e5f6,lecture0.pdf,CSCI_80,70,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
E
BA D F C",69,recursive
fd6610fb-cef7-499f-b9d9-01b6965fc389,lecture0.pdf,CSCI_80,71,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
BA D F C",67,recursive
a97572d5-df11-4a59-b333-cd7af02d46ac,lecture0.pdf,CSCI_80,72,Depth-First Search,18,recursive
29bd00b3-dfa6-4184-b58d-b76533f1d731,lecture0.pdf,CSCI_80,73,"depth-ﬁrst search
search algorithm that always expands the 
deepest node in the frontier",88,recursive
e1569f4b-f76c-4e98-b04f-aea11c5f116b,lecture0.pdf,CSCI_80,74,Breadth-First Search,20,recursive
e77a5772-d7dd-4c39-a343-67bb94406935,lecture0.pdf,CSCI_80,75,"breadth-ﬁrst search
search algorithm that always expands the 
shallowest node in the frontier",93,recursive
816441c8-efde-4d63-9b14-78768dcb3022,lecture0.pdf,CSCI_80,76,"queue
first-in first-out data type",34,recursive
4860a720-c32e-4339-a0ea-d1ec367ff2e1,lecture0.pdf,CSCI_80,77,"E
A
B
C D
F
Frontier
Find a path from A to E. A
Explored Set",60,recursive
73db9f27-c22b-44a8-9ba4-fe4c61e97286,lecture0.pdf,CSCI_80,78,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
A",60,recursive
ff89f361-f1ab-471c-b7f4-d7f2bf589181,lecture0.pdf,CSCI_80,79,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
A
B",62,recursive
a48cbecb-78bc-46c8-9590-2020684977d6,lecture0.pdf,CSCI_80,80,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
A
B",62,recursive
76b8aecc-217f-48c6-992a-18ed7be4c471,lecture0.pdf,CSCI_80,81,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
A B
C D",66,recursive
016f36c7-ce6b-43ff-9f7c-89ec193cef8a,lecture0.pdf,CSCI_80,82,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
A B
C D",66,recursive
6f39a9a4-7891-4e76-bbd3-e19fbc7edbec,lecture0.pdf,CSCI_80,83,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
A B C
D
E",68,recursive
9d021f2d-c6ac-4d1c-9c5a-03537731b86a,lecture0.pdf,CSCI_80,84,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
A B C
D E",68,recursive
2bd15eb2-b704-4b8c-b4d8-16b21363bfbf,lecture0.pdf,CSCI_80,85,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
A B C D
E
F",70,recursive
69649f21-a4d9-4b3c-bf93-68c3e1f84da1,lecture0.pdf,CSCI_80,86,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
A B C D
E F",70,recursive
aff621d9-3123-4e93-a9e6-43763796f793,lecture0.pdf,CSCI_80,87,"E
A
B
C D
F
Frontier
Find a path from A to E.
Explored Set
A B C D
F",68,recursive
2357b355-3cb6-4ed4-af83-1de4cec0d7ff,lecture0.pdf,CSCI_80,88,"B
A
Depth-First Search",22,recursive
441ca474-7e47-445b-9c9f-61423336ac05,lecture0.pdf,CSCI_80,89,"B
A
Depth-First Search",22,recursive
392d1446-695d-4feb-a6e3-a2579e370c85,lecture0.pdf,CSCI_80,90,"B
A
Depth-First Search",22,recursive
5b3d6ed8-7932-436f-b6fa-7d5bc0666294,lecture0.pdf,CSCI_80,91,"B
A
Depth-First Search",22,recursive
7e290c93-1d7d-475f-88a0-6d469287e72b,lecture0.pdf,CSCI_80,92,"B
A
Depth-First Search",22,recursive
568f682c-b8d4-408b-9d1c-bed92e9787bb,lecture0.pdf,CSCI_80,93,"B
A
Depth-First Search",22,recursive
0644f14c-5c5c-4db4-a502-091b766a159d,lecture0.pdf,CSCI_80,94,"B
A
Depth-First Search",22,recursive
0503e1f6-1d23-4915-990a-1b515dbf484e,lecture0.pdf,CSCI_80,95,"B
A
Depth-First Search",22,recursive
8994ae1f-c8ba-4146-90fd-1b1b19e63ff1,lecture0.pdf,CSCI_80,96,"B
A
Depth-First Search",22,recursive
3bda6d72-6e99-447a-8c4d-6651016e13e6,lecture0.pdf,CSCI_80,97,"B
A
Depth-First Search",22,recursive
5034d7e0-8198-4343-b66c-84299f964960,lecture0.pdf,CSCI_80,98,"B
A
Depth-First Search",22,recursive
588b2d28-b43d-4309-a779-13a20234a2aa,lecture0.pdf,CSCI_80,99,"B
A
Depth-First Search",22,recursive
8e6cd0a2-07d0-426c-bb63-c59dd512fe39,lecture0.pdf,CSCI_80,100,"B
A
Depth-First Search",22,recursive
327e44d9-56a4-4388-ba0f-669c93925477,lecture0.pdf,CSCI_80,101,"B
A
Depth-First Search",22,recursive
491e3039-8eb0-43d3-8236-6e48653cb577,lecture0.pdf,CSCI_80,102,"B
A
Depth-First Search",22,recursive
8f88321f-a734-435f-ba4b-a4191ea80d27,lecture0.pdf,CSCI_80,103,"B
A
Depth-First Search",22,recursive
e9c4c425-f641-4cdd-a4f3-2916838f2351,lecture0.pdf,CSCI_80,104,"B
A
Depth-First Search",22,recursive
498f0d8b-9a67-4dc4-af2c-367cf4e6dd69,lecture0.pdf,CSCI_80,105,"B
A
Depth-First Search",22,recursive
b22b1ddf-dab4-4e13-be0c-f4757010d047,lecture0.pdf,CSCI_80,106,"B
A
Depth-First Search",22,recursive
74f417a9-2353-48a3-b96e-72d7c8ea02de,lecture0.pdf,CSCI_80,107,"B
A
Depth-First Search",22,recursive
07b1ffe6-2dfe-40b0-a69c-32de79e98a9f,lecture0.pdf,CSCI_80,108,"B
A
Depth-First Search",22,recursive
2333914c-ee6c-428c-a6c5-32fdecabffe0,lecture0.pdf,CSCI_80,109,"B
A
Depth-First Search",22,recursive
f35dce5c-27c6-4c92-a19a-bb03ffdeafef,lecture0.pdf,CSCI_80,110,"B
A
Depth-First Search",22,recursive
ae490823-d0d5-4ad0-957d-76c3fd11bfe8,lecture0.pdf,CSCI_80,111,"B
A
Depth-First Search",22,recursive
06e8df86-e0df-4e71-adab-15ce8ef0d2bc,lecture0.pdf,CSCI_80,112,"B
A
Depth-First Search",22,recursive
2f621e4c-1738-49ac-8e25-f5595c2fee92,lecture0.pdf,CSCI_80,113,"B
A
Depth-First Search",22,recursive
8c7e0616-1580-48f0-834b-60b2a9880e34,lecture0.pdf,CSCI_80,114,"B
A
Depth-First Search",22,recursive
880c7819-56a2-439f-bc2d-30c472d23e45,lecture0.pdf,CSCI_80,115,"B
A
Depth-First Search",22,recursive
603d3492-bec9-4b12-ad2a-37239e587487,lecture0.pdf,CSCI_80,116,"B
A
Depth-First Search",22,recursive
c3ecec29-df21-479d-9bcc-56a3a54f2c30,lecture0.pdf,CSCI_80,117,"B
A
Depth-First Search",22,recursive
191d3ec2-84c0-44b7-a758-9ea1d876b1c4,lecture0.pdf,CSCI_80,118,"B
A
Depth-First Search",22,recursive
c206652f-159f-4821-b8ea-d96f8b365649,lecture0.pdf,CSCI_80,119,"B
A
Depth-First Search",22,recursive
490114f4-77b3-4a78-a2fb-ee505a05aa3a,lecture0.pdf,CSCI_80,120,"B
A
Depth-First Search",22,recursive
a2a01832-656d-455e-8d52-b5a79f6b4e40,lecture0.pdf,CSCI_80,121,"B
A
Depth-First Search",22,recursive
b3c33b86-198e-4bb7-90f7-69ebad6de53a,lecture0.pdf,CSCI_80,122,"B
A
Depth-First Search",22,recursive
28c77b82-1e80-48af-b85a-73dce21b1277,lecture0.pdf,CSCI_80,123,"B
A
Depth-First Search",22,recursive
ead3d6f4-b9fa-478e-bc7b-080e522394e7,lecture0.pdf,CSCI_80,124,"B
A
Depth-First Search",22,recursive
ad74a257-9425-4cb9-b2c3-ec5097d34312,lecture0.pdf,CSCI_80,125,"B
A
Depth-First Search",22,recursive
8c713680-ee3b-450a-af62-9ecf8c85534b,lecture0.pdf,CSCI_80,126,"B
A
Depth-First Search",22,recursive
e69eac58-4d79-41fa-a1d5-31f7b4466d9f,lecture0.pdf,CSCI_80,127,"B
A
Depth-First Search",22,recursive
16e8ad0d-249f-4c4e-be02-38d0dd92da43,lecture0.pdf,CSCI_80,128,"B
A
Depth-First Search",22,recursive
080b407d-406c-47f0-999e-c4eb29fd9d04,lecture0.pdf,CSCI_80,129,"B
A
Depth-First Search",22,recursive
1f4e3ab5-2d42-4d35-ab59-f6402bb4b778,lecture0.pdf,CSCI_80,130,"B
A
Depth-First Search",22,recursive
390d1659-cc36-4193-a8f4-5218067efb29,lecture0.pdf,CSCI_80,131,"B
A
Depth-First Search",22,recursive
e3e7b830-2f35-41a2-8248-a759ff31b101,lecture0.pdf,CSCI_80,132,"B
A
Depth-First Search",22,recursive
6079fa2d-e00d-4143-a55f-0922a695fbaf,lecture0.pdf,CSCI_80,133,"B
A
Depth-First Search",22,recursive
007ee2b7-7d61-4596-81f9-d5a3f35eb690,lecture0.pdf,CSCI_80,134,"B
A
Depth-First Search",22,recursive
be56e16d-272d-4d95-8f45-179b7ef4d53d,lecture0.pdf,CSCI_80,135,"B
A
Depth-First Search",22,recursive
9dc876f1-aab0-4b5e-8ec8-15ff4b0c0341,lecture0.pdf,CSCI_80,136,"B
A
Breadth-First Search",24,recursive
f55cca2c-3254-4f38-8f70-2d4a29e4ea55,lecture0.pdf,CSCI_80,137,"B
A
Breadth-First Search",24,recursive
fd34dc97-58f1-40d0-97c4-35424e2d99e2,lecture0.pdf,CSCI_80,138,"B
A
Breadth-First Search",24,recursive
effd2ff3-4bd7-4851-b75f-438f4066d6da,lecture0.pdf,CSCI_80,139,"B
A
Breadth-First Search",24,recursive
d0ad8b9c-0121-42a5-b587-2ed93409992d,lecture0.pdf,CSCI_80,140,"B
A
Breadth-First Search",24,recursive
b3e1d085-8a91-4ed2-b2c5-81125860c3ca,lecture0.pdf,CSCI_80,141,"B
A
Breadth-First Search",24,recursive
99e25662-a6bb-4a18-bff6-7d6392baa276,lecture0.pdf,CSCI_80,142,"B
A
Breadth-First Search",24,recursive
e7a2e6d4-2acf-4ca7-8d63-aca19e973804,lecture0.pdf,CSCI_80,143,"B
A
Breadth-First Search",24,recursive
0cee6d15-8c38-46d6-af57-cd3dffbc84c1,lecture0.pdf,CSCI_80,144,"B
A
Breadth-First Search",24,recursive
31b65fb8-2e02-424c-81b2-41d282a65628,lecture0.pdf,CSCI_80,145,"B
A
Breadth-First Search",24,recursive
f569d387-c0c2-4158-8885-96d889423eba,lecture0.pdf,CSCI_80,146,"B
A
Breadth-First Search",24,recursive
bc37e8cf-92d9-4ab4-963d-de162809cf9e,lecture0.pdf,CSCI_80,147,"B
A
Breadth-First Search",24,recursive
3b969c65-0d5c-477c-8965-8d0afee17d8b,lecture0.pdf,CSCI_80,148,"B
A
Breadth-First Search",24,recursive
73bb6136-65b7-4738-8b9c-2050a620b865,lecture0.pdf,CSCI_80,149,"B
A
Breadth-First Search",24,recursive
9b8c210c-1652-4f3d-881b-0fcd3f3274d2,lecture0.pdf,CSCI_80,150,"B
A
Breadth-First Search",24,recursive
5708ed45-dd58-4755-b5ce-928f7a1e7c74,lecture0.pdf,CSCI_80,151,"B
A
Breadth-First Search",24,recursive
17617c95-12a6-4185-8a34-61f9c2a2de25,lecture0.pdf,CSCI_80,152,"B
A
Breadth-First Search",24,recursive
bbc8eef0-5f63-49c4-b0b2-13a6a5dfd156,lecture0.pdf,CSCI_80,153,"B
A
Breadth-First Search",24,recursive
d99bd03e-e001-4ebf-aa4e-19306b5b8e88,lecture0.pdf,CSCI_80,154,"B
A
Breadth-First Search",24,recursive
96720086-a266-451d-ade2-34324096de72,lecture0.pdf,CSCI_80,155,"B
A
Breadth-First Search",24,recursive
1c54bbd5-7319-4ecd-90d1-d156b697f007,lecture0.pdf,CSCI_80,156,"B
A
Breadth-First Search",24,recursive
a97e1907-2f17-4249-b91c-02fbbcbc96f6,lecture0.pdf,CSCI_80,157,"B
A
Breadth-First Search",24,recursive
85df4a7a-21c3-4fa3-b2df-d19f2ca59f07,lecture0.pdf,CSCI_80,158,"B
A
Breadth-First Search",24,recursive
88290006-7035-4758-b886-fe76c305e808,lecture0.pdf,CSCI_80,159,"B
A
Breadth-First Search",24,recursive
c42a56ca-b767-41f1-84af-8014bad55aa2,lecture0.pdf,CSCI_80,160,"B
A
Breadth-First Search",24,recursive
9aae3bf2-c10e-4dc6-8608-63f971f601a4,lecture0.pdf,CSCI_80,161,"B
A
Breadth-First Search",24,recursive
c529f1ed-2de7-4045-ae4a-6d7d3436aed8,lecture0.pdf,CSCI_80,162,"B
A
Breadth-First Search",24,recursive
c95de873-6a62-4a81-a3ca-096d0e016fe2,lecture0.pdf,CSCI_80,163,"B
A
Breadth-First Search",24,recursive
77d318e0-6c81-4710-b381-4ad146141877,lecture0.pdf,CSCI_80,164,"B
A
Breadth-First Search",24,recursive
ab6ea5fa-b4b9-4bc0-bdfb-caf384251680,lecture0.pdf,CSCI_80,165,"B
A
Breadth-First Search",24,recursive
0bfe27c0-8358-4353-8461-f504768ff15b,lecture0.pdf,CSCI_80,166,"B
A
Breadth-First Search",24,recursive
a58b7c53-b36c-4cfe-936a-60cf25b9ebea,lecture0.pdf,CSCI_80,167,"B
A
Breadth-First Search",24,recursive
b9be8cf7-d9bb-4220-ba24-accf6f538f12,lecture0.pdf,CSCI_80,168,"B
A
Breadth-First Search",24,recursive
0d1ad963-f5c4-45a4-a12a-815a911682e3,lecture0.pdf,CSCI_80,169,"B
A
Breadth-First Search",24,recursive
df81ac47-cb3d-46cc-9bfe-bae444ce03cc,lecture0.pdf,CSCI_80,170,"B
A
Breadth-First Search",24,recursive
4e562314-7205-4e48-a3d0-cf4a76f8fee1,lecture0.pdf,CSCI_80,171,"B
A
Breadth-First Search",24,recursive
523750c2-b304-4a99-ace6-eda0bfa2307b,lecture0.pdf,CSCI_80,172,"B
A
Breadth-First Search",24,recursive
374a635c-8f76-40b0-9d00-a5a8048e522d,lecture0.pdf,CSCI_80,173,"B
A
Breadth-First Search",24,recursive
2420562e-2be4-48a9-ab00-0d76f81f6f7c,lecture0.pdf,CSCI_80,174,"B
A
Breadth-First Search",24,recursive
464c9050-3b77-43e1-9b42-984c9a23f9f5,lecture0.pdf,CSCI_80,175,"B
A
Breadth-First Search",24,recursive
084c27d3-90d1-484d-8cff-c904a0cbad99,lecture0.pdf,CSCI_80,176,"B
A
Breadth-First Search",24,recursive
2a51188d-66ac-40db-ac6d-0b096b8b2eed,lecture0.pdf,CSCI_80,177,"B
A
Breadth-First Search",24,recursive
d3ba36bf-a4bb-4e9c-b122-c392724aba3e,lecture0.pdf,CSCI_80,178,"B
A
Breadth-First Search",24,recursive
5765496f-c83d-45cb-92ae-1641a2b0ad3e,lecture0.pdf,CSCI_80,179,"B
A
Breadth-First Search",24,recursive
c142e37c-229b-4dee-a38f-69be94673407,lecture0.pdf,CSCI_80,180,"B
A
Breadth-First Search",24,recursive
eab94ab4-9e48-4505-ac6b-385f0e995514,lecture0.pdf,CSCI_80,181,"B
A
Breadth-First Search",24,recursive
9efe5325-a064-465d-981a-85d067ea0914,lecture0.pdf,CSCI_80,182,"B
A
Breadth-First Search",24,recursive
38f651a2-0927-4b93-8c14-0097119f049e,lecture0.pdf,CSCI_80,183,"B
A
Breadth-First Search",24,recursive
28391b21-8438-4e8b-aef0-d1493ae654ea,lecture0.pdf,CSCI_80,184,"B
A
Breadth-First Search",24,recursive
41399f2c-1e82-4cb3-82df-dbc89ef6d52c,lecture0.pdf,CSCI_80,185,"B
A
Breadth-First Search",24,recursive
7190974c-e268-4c32-8158-dd57b2c900b9,lecture0.pdf,CSCI_80,186,"B
A
Breadth-First Search",24,recursive
97324133-faad-4b6a-8ead-dc11f0fdc11e,lecture0.pdf,CSCI_80,187,"B
A
Breadth-First Search",24,recursive
e35cd72c-b4d7-4b08-add4-847ac9171637,lecture0.pdf,CSCI_80,188,"B
A
Breadth-First Search",24,recursive
e9bc98bb-a603-4045-936b-a9b26438925c,lecture0.pdf,CSCI_80,189,"B
A
Breadth-First Search",24,recursive
ad26f6df-f475-4c1e-a418-cff14886e2e7,lecture0.pdf,CSCI_80,190,"B
A
Breadth-First Search",24,recursive
e1c864ae-6266-4bf9-ac65-dc9c9910c851,lecture0.pdf,CSCI_80,191,"B
A
Breadth-First Search",24,recursive
091723f0-af39-4dd9-8d59-3b6a7e457ca1,lecture0.pdf,CSCI_80,192,"B
A
Breadth-First Search",24,recursive
03809adc-692a-4940-a601-f893cd21af2f,lecture0.pdf,CSCI_80,193,"B
A
Breadth-First Search",24,recursive
283081c5-d8b3-4338-a5b7-1c7ce3b147d3,lecture0.pdf,CSCI_80,194,"B
A
Breadth-First Search",24,recursive
caf27475-f87c-4cd2-8851-bb031c15bfe1,lecture0.pdf,CSCI_80,195,"uninformed search
search strategy that uses no problem-
specific knowledge",74,recursive
4348f509-1d55-4501-b0b7-e303ca2863e4,lecture0.pdf,CSCI_80,196,"informed search
search strategy that uses problem-specific 
knowledge to find solutions more efficiently",104,recursive
699eea66-04f9-4391-988b-9c3066cc61a3,lecture0.pdf,CSCI_80,197,"greedy best-ﬁrst search
search algorithm that expands the node 
that is closest to the goal, as estimated by a 
heuristic function h(n)",135,recursive
1932431d-ac40-4206-8f73-f8c475fe2226,lecture0.pdf,CSCI_80,198,"B
A
Heuristic function?",23,recursive
28e1c458-00c8-473c-8406-2546f7ca7eea,lecture0.pdf,CSCI_80,199,"B
D
C
A
Heuristic function?",27,recursive
96a6b5ce-f2fb-4969-b159-3d77dfde5ae9,lecture0.pdf,CSCI_80,200,"B
D
C
A
Heuristic function? Manhattan distance.",47,recursive
c1285126-c879-4b9e-8994-811ea220824f,lecture0.pdf,CSCI_80,201,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
5d74081a-8b04-4bb4-a8e4-d026242e4541,lecture0.pdf,CSCI_80,202,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
89ef1f7d-f2a2-4416-b676-a996a03998da,lecture0.pdf,CSCI_80,203,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
36747084-c260-4e73-b68e-197e8ad11ca5,lecture0.pdf,CSCI_80,204,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
bbdf4e2c-0ff3-48fa-a340-9e462feb0ef7,lecture0.pdf,CSCI_80,205,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
9b5d3b9a-a9ff-4984-b2d6-9f23dba9467d,lecture0.pdf,CSCI_80,206,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
ad82671a-2c3d-442b-ab70-8da9ff292ba4,lecture0.pdf,CSCI_80,207,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
6176258f-ae67-4ab7-a908-1e89c918290b,lecture0.pdf,CSCI_80,208,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
ccf5e224-bde2-4829-a977-5a2f9e298c0f,lecture0.pdf,CSCI_80,209,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
b3a6e060-42a8-40a9-b4ae-f97e2daa1531,lecture0.pdf,CSCI_80,210,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
8f2fa8ca-d7b6-4a0d-b600-1a58eb71f45e,lecture0.pdf,CSCI_80,211,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
1e30df0c-2198-4c64-a97e-f86a32fefb09,lecture0.pdf,CSCI_80,212,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
8c9f9a36-2d7c-4bcb-934c-2d86591f6da7,lecture0.pdf,CSCI_80,213,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
4466de47-7205-4e20-91ad-d487f356a5fe,lecture0.pdf,CSCI_80,214,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
777d2851-2eea-4a36-b87c-bfc97914efe3,lecture0.pdf,CSCI_80,215,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
42998e84-5360-4b61-9267-d5b0c78a20e0,lecture0.pdf,CSCI_80,216,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
069e9f54-33db-41ba-984d-0b60c516c176,lecture0.pdf,CSCI_80,217,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
792ae6ae-fdee-43b5-bc1a-0bc3b4b40d67,lecture0.pdf,CSCI_80,218,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
d2372db2-7c1d-4c52-8ba5-2647df737d56,lecture0.pdf,CSCI_80,219,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
cc36a431-07b6-4d75-939a-a7c9c616bf8c,lecture0.pdf,CSCI_80,220,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
dc79ef6d-27a7-4813-8cc7-aa8a5c055e2e,lecture0.pdf,CSCI_80,221,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
10317411-2168-4647-8f7a-8c77d11e4605,lecture0.pdf,CSCI_80,222,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
a991144c-d8d1-4e47-9852-950042789155,lecture0.pdf,CSCI_80,223,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
93d1f553-9c9a-4be8-bc8a-20c575f7ee71,lecture0.pdf,CSCI_80,224,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
5dd19a1c-185c-4dbd-bd2a-2db7262c95db,lecture0.pdf,CSCI_80,225,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
f1ef0cbc-e507-453c-9b2d-57433ae92961,lecture0.pdf,CSCI_80,226,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
90d084f8-68f5-471f-a99e-9c58c548d948,lecture0.pdf,CSCI_80,227,"11 9 7 3 2 B
12 10 8 7 6 4 1
13 12 11 9 7 6 5 2
13 10 8 6 3
14 13 12 11 9 7 6 5 4
13 10
A 16 15 14 11 10 9 8 7 6
Greedy Best-First Search",137,recursive
67adb091-9d40-4910-ade5-38b261972d51,lecture0.pdf,CSCI_80,228,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 10 9 8 7 6 5 4 2
13 11 5 3
14 13 12 10 9 8 7 6 4
13 11 5
A 16 15 14 12 11 10 9 8 7 6
Greedy Best-First Search",140,recursive
4576713f-c057-415f-b425-db51706bbe31,lecture0.pdf,CSCI_80,229,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 10 9 8 7 6 5 4 2
13 11 5 3
14 13 12 10 9 8 7 6 4
13 11 5
A 16 15 14 12 11 10 9 8 7 6
Greedy Best-First Search",140,recursive
7c41fae3-d9cf-441b-82a8-5ab95f64681b,lecture0.pdf,CSCI_80,230,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 10 9 8 7 6 5 4 2
13 11 5 3
14 13 12 10 9 8 7 6 4
13 11 5
A 16 15 14 12 11 10 9 8 7 6
Greedy Best-First Search",140,recursive
0056206d-b7d0-4b2c-a090-58fa9f3c1f26,lecture0.pdf,CSCI_80,231,"A* search
search algorithm that expands node with 
lowest value of g(n) + h(n) 
g(n) = cost to reach node 
h(n) = estimated cost to goal",136,recursive
4b59c420-b8ea-44f7-a3b8-9d6b727255c9,lecture0.pdf,CSCI_80,232,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 10 9 8 7 6 5 4 2
13 11 5 3
14 13 12 10 9 8 7 6 4
13 11 5
A 16 15 14 12 11 10 9 8 7 6
A* Search",125,recursive
e8c23a47-62ce-441e-85b3-7ad4afabffb1,lecture0.pdf,CSCI_80,233,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 10 9 8 7 6 5 4 2
13 11 5 3
14 13 12 10 9 8 7 6 4
13 11 5
A 1+16 15 14 12 11 10 9 8 7 6
A* Search",127,recursive
112828b7-256f-431e-9c9f-b7c03117de04,lecture0.pdf,CSCI_80,234,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 10 9 8 7 6 5 4 2
13 11 5 3
14 13 12 10 9 8 7 6 4
13 11 5
A 1+16 2+15 14 12 11 10 9 8 7 6
A* Search",129,recursive
4ee3ce54-9f94-4168-b45c-7e27466546f7,lecture0.pdf,CSCI_80,235,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 10 9 8 7 6 5 4 2
13 11 5 3
14 13 12 10 9 8 7 6 4
13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",131,recursive
537dd232-142f-49af-872e-c7efbbb1005a,lecture0.pdf,CSCI_80,236,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 10 9 8 7 6 5 4 2
13 11 5 3
14 13 12 10 9 8 7 6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",133,recursive
d158a45a-0036-4972-a994-307413de2ea6,lecture0.pdf,CSCI_80,237,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 10 9 8 7 6 5 4 2
13 11 5 3
14 13 5+12 10 9 8 7 6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",135,recursive
beb91fb8-f18f-4db9-9e95-de76cb1e756c,lecture0.pdf,CSCI_80,238,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 10 9 8 7 6 5 4 2
13 6+11 5 3
14 13 5+12 10 9 8 7 6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",137,recursive
e98ff460-356b-4d20-871b-3ef0e267e6dc,lecture0.pdf,CSCI_80,239,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 7+10 9 8 7 6 5 4 2
13 6+11 5 3
14 13 5+12 10 9 8 7 6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",139,recursive
9866b1cd-353b-4d49-b3f3-2c24afd11d58,lecture0.pdf,CSCI_80,240,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 7+10 8+9 8 7 6 5 4 2
13 6+11 5 3
14 13 5+12 10 9 8 7 6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",141,recursive
724fcc64-29e8-4910-b00c-4b52288e54bc,lecture0.pdf,CSCI_80,241,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 7+10 8+9 9+8 7 6 5 4 2
13 6+11 5 3
14 13 5+12 10 9 8 7 6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",143,recursive
ba9efdb2-4531-4403-bdf6-15acd823c345,lecture0.pdf,CSCI_80,242,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 7+10 8+9 9+8 10+7 6 5 4 2
13 6+11 5 3
14 13 5+12 10 9 8 7 6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",146,recursive
b96dd407-8006-4180-8da5-cadfc35f9dc2,lecture0.pdf,CSCI_80,243,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 7+10 8+9 9+8 10+7 11+6 5 4 2
13 6+11 5 3
14 13 5+12 10 9 8 7 6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",149,recursive
d5c17445-32a9-4404-b622-64a1b7d473f7,lecture0.pdf,CSCI_80,244,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 7+10 8+9 9+8 10+7 11+6 12+5 4 2
13 6+11 5 3
14 13 5+12 10 9 8 7 6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",152,recursive
c7d7d5fb-be80-4fff-a205-10ffc4786e67,lecture0.pdf,CSCI_80,245,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
13 6+11 5 3
14 13 5+12 10 9 8 7 6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",155,recursive
bf9d3fd4-3362-44e1-bdcb-ea66c2674d70,lecture0.pdf,CSCI_80,246,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
13 6+11 14+5 3
14 13 5+12 10 9 8 7 6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",158,recursive
51e52a30-36ad-468d-a207-22d822dea70f,lecture0.pdf,CSCI_80,247,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
13 6+11 14+5 3
14 6+13 5+12 10 9 8 7 6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",160,recursive
718891b1-7293-4e04-82f6-fcf95c74341b,lecture0.pdf,CSCI_80,248,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
13 6+11 14+5 3
14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",163,recursive
02916a3b-d4d5-48de-96b2-20ed705fb121,lecture0.pdf,CSCI_80,249,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",165,recursive
91f9ad36-35c1-44ed-84a7-dfb94021cbc1,lecture0.pdf,CSCI_80,250,"10 9 8 7 6 5 4 3 2 1 B
11 1
12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",167,recursive
10a253e6-5fc4-471a-bd4b-57321eaf75f6,lecture0.pdf,CSCI_80,251,"10 9 8 7 6 5 4 3 2 1 B
11 1
9+12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",169,recursive
c1e4ca83-ed64-4f22-8ebe-eedf2f5d2925,lecture0.pdf,CSCI_80,252,"10 9 8 7 6 5 4 3 2 1 B
10+11 1
9+12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",172,recursive
78121a0e-7601-464a-9201-09e08eb581bb,lecture0.pdf,CSCI_80,253,"11+10 9 8 7 6 5 4 3 2 1 B
10+11 1
9+12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",175,recursive
376ab253-3784-46f0-8c48-540147b52f23,lecture0.pdf,CSCI_80,254,"11+10 12+9 8 7 6 5 4 3 2 1 B
10+11 1
9+12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",178,recursive
4639c136-a692-4085-8657-8a109a0df124,lecture0.pdf,CSCI_80,255,"11+10 12+9 13+8 7 6 5 4 3 2 1 B
10+11 1
9+12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",181,recursive
253403f9-7c13-414b-8e40-e32a0efcc819,lecture0.pdf,CSCI_80,256,"11+10 12+9 13+8 14+7 6 5 4 3 2 1 B
10+11 1
9+12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",184,recursive
d0c73a54-c2ee-43e0-93b6-e7faf2365445,lecture0.pdf,CSCI_80,257,"11+10 12+9 13+8 14+7 15+6 5 4 3 2 1 B
10+11 1
9+12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",187,recursive
8d10f053-b6d9-49dd-b90b-7b216b02d8b1,lecture0.pdf,CSCI_80,258,"11+10 12+9 13+8 14+7 15+6 16+5 4 3 2 1 B
10+11 1
9+12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",190,recursive
df80a92a-0e70-4d74-9a1b-3176fbe02f0b,lecture0.pdf,CSCI_80,259,"11+10 12+9 13+8 14+7 15+6 16+5 17+4 3 2 1 B
10+11 1
9+12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",193,recursive
c8305065-130a-4796-88f6-480d4d0cce6d,lecture0.pdf,CSCI_80,260,"11+10 12+9 13+8 14+7 15+6 16+5 17+4 18+3 2 1 B
10+11 1
9+12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",196,recursive
b9a85bcc-ba34-49ac-996e-c69d4bdf430d,lecture0.pdf,CSCI_80,261,"11+10 12+9 13+8 14+7 15+6 16+5 17+4 18+3 19+2 1 B
10+11 1
9+12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",199,recursive
30fbe620-c7c5-4e06-ae2b-e9303ded3181,lecture0.pdf,CSCI_80,262,"11+10 12+9 13+8 14+7 15+6 16+5 17+4 18+3 19+2 20+1 B
10+11 1
9+12 7+10 8+9 9+8 10+7 11+6 12+5 13+4 2
8+13 6+11 14+5 3
7+14 6+13 5+12 10 9 8 7 15+6 4
4+13 11 5
A 1+16 2+15 3+14 12 11 10 9 8 7 6
A* Search",202,recursive
0e42303f-25d5-4e93-9486-8c5c9ef98d40,lecture0.pdf,CSCI_80,263,"A* search
optimal if 
- h(n) is admissible (never overestimates the 
true cost), and 
- h(n) is consistent (for every node n and 
successor n' with step cost c, h(n) ≤ h(n') + c)",178,recursive
fc7a5afe-94dc-4a89-bf91-b7b77bb92cae,lecture0.pdf,CSCI_80,264,Adversarial Search,18,recursive
76c8de9f-421f-4309-8272-bd292ccdcd97,lecture0.pdf,CSCI_80,265,"X
O X
O
XO
X",12,recursive
b14746ce-8f96-4039-92a1-078c872a830d,lecture0.pdf,CSCI_80,266,"X
O X
O
XO
X",12,recursive
f05d55f8-a02f-4579-8c30-b1f0a56f6f5b,lecture0.pdf,CSCI_80,267,Minimax,7,recursive
7a7653f8-375d-447c-ba5e-ce863f22f7c5,lecture0.pdf,CSCI_80,268,"O X X
O O
O X X
X O X
O O X
X X O
O X
X O
X O X
1-1 0",53,recursive
8bdd6982-dd76-4fed-a392-968beeb2328a,lecture0.pdf,CSCI_80,269,"Minimax
•MAX (X) aims to maximize score. 
•MIN (O) aims to minimize score.",74,recursive
83a21c07-713c-4af5-9938-756d8b4ced97,lecture0.pdf,CSCI_80,270,"Game
•S0 : initial state 
•PLAYER(s) : returns which player to move in state s
•ACTIONS(s) : returns legal moves in state s
•RESULT(s, a) : returns state after action a taken in state s
•TERMINAL(s) : checks if state s is a terminal state
•UTILITY(s) : final numerical value for terminal state s",295,recursive
04dd5717-af1a-4c42-924f-ff4d59aaea31,lecture0.pdf,CSCI_80,271,Initial State,13,recursive
afc87ca9-47bc-46a8-a6f0-0f335a83f4bc,lecture0.pdf,CSCI_80,272,"PLAYER(s)
PLAYER(               ) = X
XPLAYER(               ) = O",66,recursive
a905a2c1-4889-46f5-a7fd-9960634ad801,lecture0.pdf,CSCI_80,273,"ACTIONS(s)
X O
O X X
X O
ACTIONS(               ) = {    ,    }O
O",66,recursive
0d8cad2e-964c-4521-bdbd-cfb50f53bac7,lecture0.pdf,CSCI_80,274,"RESULT(s, a)
X O
O X X
X O
RESULT(               ,         ) =O
O X O
O X X
X O",79,recursive
10c9b2af-220d-4c0f-8dc8-b35be550f0de,lecture0.pdf,CSCI_80,275,"TERMINAL(s)
O
O X
X O X
TERMINAL(               ) = false
O X
O X
X O X
TERMINAL(               ) = true",104,recursive
28785833-b7ca-4082-8c84-34e45fcf46ef,lecture0.pdf,CSCI_80,276,"UTILITY(s)
O X
O X
X O X
UTILITY(               ) = 1
O X X
X O
O X O
UTILITY(               ) = -1",99,recursive
895b024c-3894-4d08-9fb6-bd0e3dc2ee78,lecture0.pdf,CSCI_80,277,"VALUE: 1
O X O
O X X
X X O",26,recursive
3c91f353-950f-4a22-8b64-409570fb8fea,lecture0.pdf,CSCI_80,278,"X O
O X X
X O
PLAYER(s) = O
O X O
O X X
X O
X O
O X X
X O O
MIN-VALUE:
0
O X O
O X X
X X O
X X O
O X X
X O O
VALUE:
0
VALUE:
1
MAX-VALUE:
1
MAX-VALUE:
0",152,recursive
48011842-01c2-466b-b60f-39f53a0a1489,lecture0.pdf,CSCI_80,279,"X O
O X X
X O
O X O
O X X
X O
X O
O X X
X O O
MIN-VALUE:
0
O X O
O X X
X X O
X X O
O X X
X O O
VALUE:
0
VALUE:
1
MAX-VALUE:
1
MAX-VALUE:
0
PLAYER(s) = O",152,recursive
54ce1bf2-0713-4921-94a9-7a3d9cae1bd0,lecture0.pdf,CSCI_80,280,"PLAYER(s) = X
X O
O X X
X O
O X O
O X X
X O
X O
O X X
X O O
MIN-VALUE:
0
O X O
O X X
X X O
X X O
O X X
X O O
VALUE:
0
VALUE:
1
MAX-VALUE:
1
MAX-VALUE:
0
X O
O X
X O
X X O
O X
X O
X X O
O X O
X O
X X O
O X
X O O
MIN-VALUE:
-1
X X O
O X X
X O O
VALUE:
0
VALUE:
-1
MAX-VALUE:
0
X O
O X
X X O
VALUE:
1
MAX-VALUE:
1",310,recursive
58754930-cfdc-4e43-ac75-b187e320ae72,lecture0.pdf,CSCI_80,281,"9
5 3 9",7,recursive
02676a66-0a08-47aa-85f3-a33c645344cb,lecture0.pdf,CSCI_80,282,"9
5 3 9 2 8
8
8",15,recursive
aa2768d5-bf6a-48a1-862c-a2d473b6e4d7,lecture0.pdf,CSCI_80,283,"Minimax
•Given a state s: 
•MAX picks action a in ACTIONS(s) that produces 
highest value of MIN-VALUE(RESULT(s, a)) 
•MIN picks action a in ACTIONS(s) that produces 
smallest value of MAX-VALUE(RESULT(s, a))",208,recursive
22cf95b0-5dff-4882-895f-261699edcfd1,lecture0.pdf,CSCI_80,284,"Minimax
function MAX-VALUE(state): 
    if TERMINAL(state): 
        return UTILITY(state) 
    v = -∞ 
    for action in ACTIONS(state): 
        v = MAX(v, MIN-VALUE(RESULT(state, action))) 
    return v",205,recursive
154490fd-780c-48d2-9ecf-c2a30a0cf1c7,lecture0.pdf,CSCI_80,285,"Minimax
function MIN-VALUE(state): 
    if TERMINAL(state): 
        return UTILITY(state) 
    v = ∞ 
    for action in ACTIONS(state): 
        v = MIN(v, MAX-VALUE(RESULT(state, action))) 
    return v",204,recursive
9a883771-219e-4b20-9bde-0cb11eeaca43,lecture0.pdf,CSCI_80,286,Optimizations,13,recursive
cc8090c9-f50b-4c9e-99bd-d2f8ddbaf6c5,lecture0.pdf,CSCI_80,287,"4
5 2
2 64
3
9 73
4
4 58",24,recursive
430453da-ead7-492b-af6b-87fd3f341892,lecture0.pdf,CSCI_80,288,"4
5 ≤2
2
≤3
9 3
4
4 58",22,recursive
1eccb946-b9c1-494b-b599-786056084fab,lecture0.pdf,CSCI_80,289,Alpha-Beta Pruning,18,recursive
eac25756-5615-4e48-8dc3-99e5a0acdb07,lecture0.pdf,CSCI_80,290,"255,168
total possible Tic-Tac-Toe games",40,recursive
9c543796-f36b-4ec4-a412-340f4bc42284,lecture0.pdf,CSCI_80,291,"288,000,000,000
total possible chess games
after four moves each",64,recursive
50f2d5eb-a9f2-44d9-8827-236fac18127a,lecture0.pdf,CSCI_80,292,"total possible chess games
(lower bound)
29000
10",49,recursive
abb8f67c-1b8f-4aa6-8787-7616d69a209d,lecture0.pdf,CSCI_80,293,Depth-Limited Minimax,21,recursive
76381c76-a329-44c9-a689-6e53844dacd8,lecture0.pdf,CSCI_80,294,"evaluation function
function that estimates the expected utility 
of the game from a given state",96,recursive
8bdbb4f1-e91b-4bfb-8360-03825d8b295a,lecture0.pdf,CSCI_80,296,https://xkcd.com/832/,21,recursive
d30baa62-53bb-4323-ae98-88de03f2052f,lecture0.pdf,CSCI_80,297,Search,6,recursive
27423d6e-ec56-4530-b18d-42e3c1729489,lecture0.pdf,CSCI_80,298,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
2e21fca1-e6d9-438b-b963-0ff565296cca,Lecture_3.pdf,CSCI_80,0,"Lecture 3  1. Op&miza&on Op#miza#on is choosing the best op#on from a set of possible op#ons. We have already encountered problems where we tried to ﬁnd the best possible op#on, such as in the minimax algorithm, and today we will learn about tools that we can use to solve an even broader range of problems.  2. Local Search Local search is a search algorithm that maintains a single node and searches by moving to a neighboring node. This type of algorithm is diﬀerent from previous types of search that we saw. Whereas in maze solving, for example, we wanted to ﬁnd the quickest way to the goal, local search is interested in ﬁnding the best answer to a ques#on. ODen, local search will bring to an answer that is not op#mal but “good enough,” conserving computa#onal power. Consider the following example of a local search problem: we have four houses in set loca#ons. We want to build two hospitals, such that we minimize the distance from each house to a hospital",968,recursive
6c4beddf-7c8d-4d53-b009-50626105bc30,Lecture_3.pdf,CSCI_80,0,". Consider the following example of a local search problem: we have four houses in set loca#ons. We want to build two hospitals, such that we minimize the distance from each house to a hospital. This problem can be visualized as follows:  Example: Houses and Hospitals  In this illustra#on, we are seeing a possible conﬁgura#on of houses and hospitals. The distance between them is measured using ManhaMan distance (number of moves up, down, and to the sides; discussed in more detail in lecture 0), and the sum of the distances from each house to the nearest hospital is 17. We call this the cost, because we try to minimize this distance. In this case, a state would be any one conﬁgura#on of houses and hospitals.  Abstrac#ng this concept, we can represent each conﬁgura#on of houses and hospitals as the state-space landscape below. Each of the bars in the picture represents a value of a state, which in our example would be the cost of a certain conﬁgura#on of houses and hospitals.  3",991,recursive
5ea02b57-60a0-4302-b8f6-2a41c3bd6763,Lecture_3.pdf,CSCI_80,0,". Each of the bars in the picture represents a value of a state, which in our example would be the cost of a certain conﬁgura#on of houses and hospitals.  3. State-Space Landscape  Going oﬀ of this visualiza#on, we can deﬁne a few important terms for the rest of our discussion:  3.1. Objec)ve func)on An Objec#ve Func#on is a func#on that we use to maximize the value of the solu#on. A Cost Func#on is a func#on that we use to minimize the cost of the solu#on (this is the func#on that we would use in our example with houses and hospitals. We want to minimize the distance from houses to hospitals). A Current State is the state that is currently being considered by the func#on.",681,recursive
59ddaca0-4eb0-414f-9952-820b66debd2e,Lecture_3.pdf,CSCI_80,1,"A Neighbor State is a state that the current state can transi#on to. In the one-dimensional state-space landscape above, a neighbor state is the state to either side of the current state. In our example, a neighbor state could be the state resul#ng from moving one of the hospitals to any direc#on by one step. Neighbor states are usually similar to the current state, and, therefore, their values are close to the value of the current state. Note that the way local search algorithms work is by considering one node in a current state, and then moving the node to one of the current state’s neighbors. This is unlike the minimax algorithm, for example, where every single state in the state space was considered recursively.  4. Hill Climbing Hill climbing is one type of a local search algorithm. In this algorithm, the neighbor states are compared to the current state, and if any of them is beMer, we change the current node from the current state to that neighbor state",974,recursive
e9d8c0c4-6e63-4b82-a566-8773e5173bdd,Lecture_3.pdf,CSCI_80,1,". In this algorithm, the neighbor states are compared to the current state, and if any of them is beMer, we change the current node from the current state to that neighbor state. What qualiﬁes as beMer is deﬁned by whether we use an objec#ve func#on, preferring a higher value, or a decreasing func#on, preferring a lower value.  A hill climbing algorithm will look the following way in pseudocode:  func#on Hill-Climb(problem):  current = ini#al state of problem repeat: neighbor = best valued neighbor of current if neighbor not beMer than current: return current current = neighbor.  In this algorithm, we start with a current state. In some problems, we will know what the current state is, while, in others, we will have to start with selec#ng one randomly. Then, we repeat the following ac#ons: we evaluate the neighbors, selec#ng the one with the best value. Then, we compare this neighbor’s value to the current state’s value",933,recursive
52e3b4b2-5f50-469b-9343-0fd28c1575a1,Lecture_3.pdf,CSCI_80,1,". Then, we repeat the following ac#ons: we evaluate the neighbors, selec#ng the one with the best value. Then, we compare this neighbor’s value to the current state’s value. If the neighbor is beMer, we switch the current state to the neighbor state, and then repeat the process. The process ends when we compare the best neighbor to the current state, and the current state is beMer. Then, we return the current state.  Using the hill climbing algorithm, we can start to improve the loca#ons that we assigned to the hospitals in our example. ADer a few transi#ons, we get to the following state:  Examples: Houses and Hospitals at Local Minimum  At this state, the cost is 11, which is an improvement over 17, the cost of the ini#al state. However, this is not the op#mal state just yet. For example, moving the hospital on the leD to be underneath the top leD house would bring to a cost of 9, which is beMer than 11",918,recursive
37c5d77b-c485-4b76-872d-39ef0f0dcbb3,Lecture_3.pdf,CSCI_80,1,". However, this is not the op#mal state just yet. For example, moving the hospital on the leD to be underneath the top leD house would bring to a cost of 9, which is beMer than 11. However, this version of a hill climbing algorithm can’t get there, because all the neighbor states are at",287,recursive
0921ff74-54a0-45ca-aeee-3874de8ae42d,Lecture_3.pdf,CSCI_80,2,"least as costly as the current state. In this sense, a hill climbing algorithm is short-sighted, oDen seMling for solu#ons that are beMer than some others, but not necessarily the best of all possible solu#ons.  4.1. Local and Global Minima and Maxima  As men#oned above, a hill climbing algorithm can get stuck in local maxima or minima. A local maximum (plural: maxima) is a state that has a higher value than its neighboring states. As opposed to that, a global maximum is a state that has the highest value of all states in the state-space.  a. Maxima  In contrast, a local minimum (plural: minima) is a state that has a lower value than its neighboring states. As opposed to that, a global minimum is a state that has the lowest value of all states in the state-space.  b. Minima  The problem with hill climbing algorithms is that they may end up in local minima and maxima",878,recursive
f1e1f777-edb3-4353-ad17-8b4914f2fa32,Lecture_3.pdf,CSCI_80,2,".  b. Minima  The problem with hill climbing algorithms is that they may end up in local minima and maxima. Once the algorithm reaches a point whose neighbors are worse, for the func#on’s purpose, than the current state, the algorithm stops. Special types of local maxima and minima include the ﬂat local maximum/minimum, where mul#ple states of equal value are adjacent, forming a plateau whose neighbors have a worse value, and the shoulder, where mul#ple states of equal value are adjacent and the neighbors of the plateau can be both beMer and worse. Star#ng from the middle of the plateau, the algorithm will not be able to advance in any direc#on.  c. Flat Local Maximum/Minimum and Shoulder  5. Hill Climbing Variants  Due to the limita#ons of Hill Climbing, mul#ple variants have been thought of to overcome the problem of being stuck in local minima and maxima",869,recursive
cb7ea61a-c81d-4f90-b53c-7c4f90aec566,Lecture_3.pdf,CSCI_80,2,". Hill Climbing Variants  Due to the limita#ons of Hill Climbing, mul#ple variants have been thought of to overcome the problem of being stuck in local minima and maxima. What all varia#ons of the algorithm have in common is that, no maMer the strategy, each one s#ll has the poten#al of ending up in local minima and maxima and no means to con#nue op#mizing. The algorithms below are phrased such that a higher value is beMer, but they also apply to cost func#ons, where the goal is to minimize cost.  a. Steepest-ascent: choose the highest-valued neighbor. This is the standard varia#on that we discussed above. b. Stochas:c: choose randomly from higher-valued neighbors. Doing this, we choose to go to any direc#on that improves over our value. This makes sense if, for example, the highest-valued neighbor leads to a local maximum while another neighbor leads to a global maximum.",884,recursive
27d23860-3e7f-4460-9317-5fd86f135a35,Lecture_3.pdf,CSCI_80,3,"c. First-choice: choose the ﬁrst higher-valued neighbor. d. Random-restart: conduct hill climbing mul#ple #mes. Each #me, start from a random state. Compare the maxima from every trial, and choose the highest amongst those. e. Local Beam Search: chooses the k highest-valued neighbors. This is unlike most local search algorithms in that it uses mul#ple nodes for the search, and not just one.  Although local search algorithms don’t always give the best possible solu#on, they can oDen give a good enough solu#on in situa#ons where considering every possible state is computa#onally infeasible.  6. Simulated Annealing Although we have seen variants that can improve hill climbing, they all share the same fault: once the algorithm reaches a local maximum, it stops running. Simulated annealing allows the algorithm to “dislodge” itself if it gets stuck in a local maximum.  Annealing is the process of hea#ng metal and allowing it to cool slowly, which serves to toughen the metal",982,recursive
7a0bf182-e8a3-4f34-8f23-90a805b90846,Lecture_3.pdf,CSCI_80,3,".  Annealing is the process of hea#ng metal and allowing it to cool slowly, which serves to toughen the metal. This is used as a metaphor for the simulated annealing algorithm, which starts with a high temperature, being more likely to make random decisions, and, as the temperature decreases, it becomes less likely to make random decisions, becoming more “ﬁrm.” This mechanism allows the algorithm to change its state to a neighbor that’s worse than the current state, which is how it can escape from local maxima. The following is pseudocode for simulated annealing:  func#on Simulated-Annealing(problem, max):  current = ini#al state of problem for t = 1 to max: T = Temperature(t) neighbor = random neighbor of current ΔE = how much beMer neighbor is than current if ΔE > 0: current = neighbor  with probability e^(ΔE/T) set current = neighbor return current  The algorithm takes as input a problem and max, the number of #mes it should repeat itself",955,recursive
9b839bb1-ec61-4437-8a31-796031017eb3,Lecture_3.pdf,CSCI_80,3,". For each itera#on, T is set using a Temperature func#on. This func#on return a higher value in the early itera#ons (when t is low) and a lower value in later itera#ons (when t is high). Then, a random neighbor is selected, and ΔE is computed such that it quan#ﬁes how beMer the neighbor state is than the current state. If the neighbor state is beMer than the current state (ΔE > 0), as before, we set our current state to be the neighbor state. However, when the neighbor state is worse (ΔE < 0), we s#ll might set our current state to be that neighbor state, and we do so with probability e^(ΔE/T). The idea here is that a more nega#ve ΔE will result in lower",663,recursive
56210798-f32f-42b6-a44f-a10771d34de0,Lecture_3.pdf,CSCI_80,4,"probability of the neighbor state being chosen, and the higher the temperature T the higher the probability that the neighbor state will be chosen. This means that the worse the neighbor state, the less likely it is to be chosen, and the earlier the algorithm is in its process, the more likely it is to set a worse neighbor state as current state. The math behind this is as follows: e is a constant (around 2.72), and ΔE is nega#ve (since this neighbor is worse than the current state). The more nega#ve ΔE, the closer the resul#ng value to 0. The higher the temperature T is, the closer ΔE/T is to 0, making the probability closer to 1.  6.1. Traveling Salesman Problem In the traveling salesman problem, the task is to connect all points while choosing the shortest possible distance. This is, for example, what delivery companies need to do: ﬁnd the shortest route from the store to all the customers’ houses and back",922,recursive
2eb520ae-3a89-4623-90fd-caef0ea30aa6,Lecture_3.pdf,CSCI_80,4,". This is, for example, what delivery companies need to do: ﬁnd the shortest route from the store to all the customers’ houses and back.  Traveling Salesman Problem  In this case, a neighbor state might be seen as a state where two arrows swap places. Calcula#ng every possible combina#on makes this problem computa#onally demanding (having just 10 points gives us 10!, or 3,628,800 possible routes). By using the simulated annealing algorithm, a good solu#on can be found for a lower computa#onal cost.  7. Linear Programming Linear programming is a family of problems that op#mize a linear equa#on (an equa#on of the form y = ax₁ + bx₂ + …).  Linear programming will have the following components:  A cost func#on that we want to minimize: c₁x₁ + c₂x₂ + … + cₙxₙ. Here, each x₋ is a variable, and it is associated with some cost c₋",833,recursive
27a96c5f-2479-4baf-bf27-8e450fc470ef,Lecture_3.pdf,CSCI_80,4,".  Linear programming will have the following components:  A cost func#on that we want to minimize: c₁x₁ + c₂x₂ + … + cₙxₙ. Here, each x₋ is a variable, and it is associated with some cost c₋. A constraint that’s represented as a sum of variables that is either less than or equal to a value (a₁x₁ + a₂x₂ + … + aₙxₙ ≤ b) or precisely equal to this value (a₁x₁ + a₂x₂ + … + aₙxₙ = b). In this case, x₋ is a variable, and a₋ is some resource associated with it, and b is how much resources we can dedicate to this problem. Individual bounds on variables (for example, that a variable can’t be nega#ve) of the form lᵢ ≤ xᵢ ≤ uᵢ. Consider the following example:  Two machines, X₁ and X₂. X₁ costs $50/hour to run, X₂ costs $80/hour to run. The goal is to minimize cost. This can be formalized as a cost func#on: 50x₁ + 80x₂. X₁ requires 5 units of labor per hour. X₂ requires 2 units of labor per hour. Total of 20 units of labor to spend. This can be formalized as a constraint: 5x₁ + 2x₂ ≤ 20",990,recursive
580267fa-3eaf-4bd4-8760-1feb0a6b5641,Lecture_3.pdf,CSCI_80,4,". X₁ requires 5 units of labor per hour. X₂ requires 2 units of labor per hour. Total of 20 units of labor to spend. This can be formalized as a constraint: 5x₁ + 2x₂ ≤ 20. X₁ produces 10 units of output per hour. X₂ produces 12 units of output per hour. Company needs 90 units of output. This is another constraint. Literally, it can be rewriMen as 10x₁ + 12x₂ ≥ 90. However, constraints need to be of the form (a₁x₁ + a₂x₂ + … + aₙxₙ ≤ b) or (a₁x₁ + a₂x₂ + … +",462,recursive
cd514358-083c-4cc4-bc54-bb659b4c4a89,Lecture_3.pdf,CSCI_80,5,"aₙxₙ = b). Therefore, we mul#ply by (-1) to get to an equivalent equa#on of the desired form: (-10x₁) + (-12x₂) ≤ -90. An op#mizing algorithm for linear programming requires background knowledge in geometry and linear algebra that we don’t want to assume. Instead, we can use algorithms that already exist, such as Simplex and Interior-Point",341,recursive
41ab3721-3e2f-4f2f-92f4-fbef1a5b7506,Lecture_3.pdf,CSCI_80,5,". Instead, we can use algorithms that already exist, such as Simplex and Interior-Point.  The following is a linear programming example that uses the scipy library in Python:  import scipy.op#mize  # Objec#ve Func#on: 50x_1 + 80x_2 # Constraint 1: 5x_1 + 2x_2 <= 20 # Constraint 2: -10x_1 + -12x_2 <= -90  result = scipy.op#mize.linprog(     [50, 80],  # Cost func#on: 50x_1 + 80x_2     A_ub=[[5, 2], [-10, -12]],  # Coeﬃcients for inequali#es     b_ub=[20, -90],  # Constraints for inequali#es: 20 and -90 )  if result.success:     print(f""X1: {round(result.x[0], 2)} hours"")     print(f""X2: {round(result.x[1], 2)} hours"") else:     print(""No solu#on"") Constraint Sa#sfac#on Constraint Sa#sfac#on problems are a class of problems where variables need to be assigned values while sa#sfying some condi#ons.  Constraints sa#sfac#on problems have the following proper#es:  a. Set of variables (x₁, x₂, …, xₙ) b. Set of domains for each variable {D₁, D₂, …, Dₙ} c",960,recursive
90181c47-2cff-4687-b193-df2aa00e9b0e,Lecture_3.pdf,CSCI_80,5,".  Constraints sa#sfac#on problems have the following proper#es:  a. Set of variables (x₁, x₂, …, xₙ) b. Set of domains for each variable {D₁, D₂, …, Dₙ} c. Set of constraints C  Sudoku can be represented as a constraint sa#sfac#on problem, where each empty square is a variable, the domain is the numbers 1-9, and the constraints are the squares that can’t be equal to each other.  Consider another example. Each of students 1-4 is taking three courses from A, B, …, G. Each course needs to have an exam, and the possible days for exams are Monday, Tuesday, and Wednesday. However, the same student can’t have two exams on the same day. In this case, the variables are the courses, the domain is the days, and the constraints are which courses can’t be",753,recursive
0fac4b8e-2a43-400d-aa59-d138c209dc7d,Lecture_3.pdf,CSCI_80,6,"scheduled to have an exam on the same day because the same student is taking them. This can be visualized as follows:  8. Constraint Sa&sfac&on SeHng  This problem can be solved using constraints that are represented as a graph. Each node on the graph is a course, and an edge is drawn between two courses if they can’t be scheduled on the same day. In this case, the graph will look this:  Constraint Sa#sfac#on Constraints  A few more terms worth knowing about constraint sa#sfac#on problems:  a. A Hard Constraint is a constraint that must be sa#sﬁed in a correct solu#on. b. A SoD Constraint is a constraint that expresses which solu#on is preferred over others. c. A Unary Constraint is a constraint that involves only one variable. In our example, a unary constraint would be saying that course A can’t have an exam on Monday {A ≠ Monday}. Rules that prohibit assigning certain values from domain to a variable. d. A Binary Constraint is a constraint that involves two variables",984,recursive
c6a0907e-54a4-408d-baee-1d3cb6b0df6e,Lecture_3.pdf,CSCI_80,6,". Rules that prohibit assigning certain values from domain to a variable. d. A Binary Constraint is a constraint that involves two variables. This is the type of constraint that we used in the example above, saying that some two courses can’t have the same value {A ≠ B}. Represented by an edge.  9. Node Consistency/Unary constraints Node consistency is when all the values in a variable’s domain sa#sfy the variable’s unary constraints.  For example, let’s take two courses, A and B. The domain for each course is {Monday, Tuesday, Wednesday}, and the constraints are {A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}. Now, neither A nor B is consistent, because the exis#ng constraints prevent them from being able to take every value that’s in their domain. However, if we remove Monday from A’s domain, then it will have node consistency. To achieve node consistency in B, we will have to remove both Monday and Tuesday from its domain.  10",930,recursive
359e9112-b252-4495-bf8f-55f9bfb57e65,Lecture_3.pdf,CSCI_80,6,". However, if we remove Monday from A’s domain, then it will have node consistency. To achieve node consistency in B, we will have to remove both Monday and Tuesday from its domain.  10. Arc Consistency/Binary constraints Arc consistency is when all the values in a variable’s domain sa#sfy the variable’s binary constraints (note that we are now using “arc” to refer to what we previously referred to as “edge”). In other words, to make X arc-consistent with respect to Y , remove elements from X’s domain un#l every choice for X has a possible choice for Y .  Consider our previous example with the revised domains: A:{Tuesday, Wednesday} and B:{Wednesday}. For A to be arc-consistent with B, no maMer what day A’s exam gets scheduled (from its domain), B will s#ll be able to schedule an exam. Is A arc-consistent with B? If A takes the value Tuesday, then B can take the value Wednesday. However, if A takes the value",921,recursive
fb5cb773-3dc3-4c54-8e1d-737be3cb950d,Lecture_3.pdf,CSCI_80,7,"Wednesday, then there is no value that B can take (remember that one of the constraints is A ≠ B). Therefore, A is not arc-consistent with B. To change this, we can remove Wednesday from A’s domain. Then, any value that A takes (Tuesday being the only op#on) leaves a value for B to take (Wednesday). Now, A is arc-consistent with B. Let’s look at an algorithm in pseudocode that makes a variable arc-consistent with respect to some other variable (note that csp stands for “constraint sa#sfac#on problem”).  func#on Revise(csp, X, Y):  revised = false for x in X.domain: if no y in Y .domain sa#sﬁes constraint for (X,Y): delete x from X.domain revised = true return revised  This algorithm starts with tracking whether any change was made to X’s domain, using the variable revised. This will be useful in the next algorithm we examine. Then, the code repeats for every value in X’s domain and sees if Y has a value that sa#sﬁes the constraints",945,recursive
3a166b83-a00f-4fdc-8ae7-30cc1eccef04,Lecture_3.pdf,CSCI_80,7,". This will be useful in the next algorithm we examine. Then, the code repeats for every value in X’s domain and sees if Y has a value that sa#sﬁes the constraints. If yes, then do nothing, if not, remove this value from X’s domain.  ODen we are interested in making the whole problem arc-consistent and not just one variable with respect to another. In this case, we will use an algorithm called AC-3, which uses Revise:  func#on AC-3(csp):  queue = all arcs in csp while queue non-empty: (X, Y) = Dequeue(queue) if Revise(csp, X, Y): if size of X.domain == 0: return false for each Z in X.neighbors - {Y}: Enqueue(queue, (Z,X)) return true  This algorithm adds all the arcs in the problem to a queue. Each #me it considers an arc, it removes it from the queue. Then, it runs the Revise algorithm to see if this arc is consistent. If changes were made to make it consistent, further ac#ons are needed",901,recursive
86812411-9896-478a-95c4-5cc67fe9e97e,Lecture_3.pdf,CSCI_80,7,". Each #me it considers an arc, it removes it from the queue. Then, it runs the Revise algorithm to see if this arc is consistent. If changes were made to make it consistent, further ac#ons are needed. If the resul#ng domain of X is empty, it means that this constraint sa#sfac#on problem is unsolvable (since there are no values that X can take that will allow Y to take any value given the constraints). If the problem is not deemed unsolvable in the previous step, then, since X’s domain was changed, we need to see if all the arcs associated with X are s#ll consistent. That is, we take all of X’s neighbors except Y , and we add the arcs between them and X to the queue. However, if the Revise algorithm",708,recursive
ba65292f-c1f8-44c3-96f6-5c03bdb1beda,Lecture_3.pdf,CSCI_80,8,"returns false, meaning that the domain wasn’t changed, we simply con#nue considering the other arcs.  While the algorithm for arc consistency can simplify the problem, it will not necessarily solve it, since it considers binary constraints only and not how mul#ple nodes might be interconnected. Our previous example, where each of 4 students is taking 3 courses, remains unchanged by running AC-3 on it.  We have encountered search problems in our ﬁrst lecture. A constraint sa#sfac#on problem can be seen as a search problem:  a. Ini#al state: empty assignment (all variables don’t have any values assigned to them). b. Ac#ons: add a {variable = value} to assignment; that is, give some variable a value. c. Transi#on model: shows how adding the assignment changes the assignment. There is not much depth to this: the transi#on model returns the state that includes the assignment following the latest ac#on. d. Goal test: check if all variables are assigned a value and all constraints are sa#sﬁed",1000,recursive
75b77eff-1724-48c7-b133-f72bd51e577e,Lecture_3.pdf,CSCI_80,8,". d. Goal test: check if all variables are assigned a value and all constraints are sa#sﬁed. e. Path cost func#on: all paths have the same cost. As we men#oned earlier, as opposed to typical search problems, op#miza#on problems care about the solu#on and not the route to the solu#on. However, going about a constraint sa#sfac#on problem naively, as a regular search problem, is massively ineﬃcient. Instead, we can make use of the structure of a constraint sa#sfac#on problem to solve it more eﬃciently.  11. Backtracking Search Backtracking search is a type of a search algorithm that takes into account the structure of a constraint sa#sfac#on search problem. In general, it is a recursive func#on that aMempts to con#nue assigning values as long as they sa#sfy the constraints. If constraints are violated, it tries a diﬀerent assignment",841,recursive
059087dd-7a0a-4f72-9691-462a616e9f88,Lecture_3.pdf,CSCI_80,8,". In general, it is a recursive func#on that aMempts to con#nue assigning values as long as they sa#sfy the constraints. If constraints are violated, it tries a diﬀerent assignment. Let’s look at the pseudocode for it:  func#on Backtrack(assignment, csp):  if assignment complete: return assignment var = Select-Unassigned-Var(assignment, csp) for value in Domain-Values(var, assignment, csp): if value consistent with assignment: add {var = value} to assignment result = Backtrack(assignment, csp) if result ≠ failure: return result remove {var = value} from assignment return failure",585,recursive
fa3668a9-0a61-4e60-92c7-61c807338e21,Lecture_3.pdf,CSCI_80,9,"In words, this algorithm starts with returning the current assignment if it is complete. This means that, if the algorithm is done, it will not perform any of the addi#onal ac#ons. Instead, it will just return the completed assignment. If the assignment is not complete, the algorithm selects any of the variables that do not have an assignment yet. Then, the algorithm tries to assign a value to the variable, and runs the Backtrack algorithm again on the resul#ng assignment (recursion). Then, it checks the resul#ng value. If it is not failure, it means that the assignment worked out, and it should return this assignment. If the resul#ng value is failure, then the latest assignment is removed, and a new possible value is aMempted, repea#ng the same process. If all possible values in the domain returned failure, this means that we need to backtrack. That is, that the problem is with some previous assignment",916,recursive
8bea37a9-11f8-409c-a4f2-d5f5472505cb,Lecture_3.pdf,CSCI_80,9,". If all possible values in the domain returned failure, this means that we need to backtrack. That is, that the problem is with some previous assignment. If this happens with the variable we start with, then it means that no solu#on sa#sﬁes the constraints.  Consider the following course of ac#on:  Backtracking Example  We start with empty assignments (top leD). Then, we choose the variable A, and assign to it some value, Monday (top right). Then, using this assignment, we run the algorithm again. Now that A already has an assignment, the algorithm will consider B, and assign Monday to it (boMom leD). This assignment returns false, so instead of assigning a value to C given the previous assignment, the algorithm will try to assign a new value to B, Tuesday (boMom right). This new assignment sa#sﬁes the constraints, and a new variable will be considered next given this assignment",892,recursive
c6aea6da-75ef-4a5e-8e79-4e4ec7a2c050,Lecture_3.pdf,CSCI_80,9,". This new assignment sa#sﬁes the constraints, and a new variable will be considered next given this assignment. If, for example, assigning also Tuesday or Wednesday to B would bring to a failure, then the algorithm would backtrack and return to considering A, assigning another value to it, Tuesday. If also Tuesday and Wednesday return failure, then it means we have tried every possible assignment and the problem is unsolvable.  In the source code sec#on, you can ﬁnd an implementa#on from scratch of the backtrack algorithm. However, this algorithm is widely used, and, as such, mul#ple libraries already contain an implementa#on of it.  12. Inference  Although backtracking search is more eﬃcient than simple search, it s#ll takes a lot of computa#onal power. Enforcing arc consistency, on the other hand, is less resource intensive. By interleaving backtracking search with inference (enforcing arc consistency), we can get at a more eﬃcient algorithm",958,recursive
7308db93-67e5-459e-800f-7fbbe5a6d03e,Lecture_3.pdf,CSCI_80,9,". Enforcing arc consistency, on the other hand, is less resource intensive. By interleaving backtracking search with inference (enforcing arc consistency), we can get at a more eﬃcient algorithm. This algorithm is called the Maintaining Arc-Consistency algorithm. This algorithm will enforce arc-consistency aDer every new assignment of the backtracking search. Speciﬁcally, aDer we make a new assignment to X, we will call the AC-3 algorithm and start it with a queue of all arcs (Y ,X) where Y is a neighbor of X (and not a queue of all arcs in the problem). Following is a revised Backtrack algorithm that maintains arc-consistency, with the new addi#ons in bold.",666,recursive
46896cd0-442f-4e21-a879-a4ab5453dd89,Lecture_3.pdf,CSCI_80,10,"func#on Backtrack(assignment, csp):  if assignment complete: return assignment var = Select-Unassigned-Var(assignment, csp) for value in Domain-Values(var, assignment, csp): if value consistent with assignment: add {var = value} to assignment inferences = Inference(assignment, csp) if inferences ≠ failure: add inferences to assignment result = Backtrack(assignment, csp) if result ≠ failure: return result remove {var = value} and inferences from assignment return failure  The Inference func#on runs the AC-3 algorithm as described. Its output is all the inferences that can be made through enforcing arc-consistency. Literally, these are the new assignments that can be deduced from the previous assignments and the structure of the constrain sa#sfac#on problem.  There are addi#onal ways to make the algorithm more eﬃcient. So far, we selected an unassigned variable randomly. However, some choices are more likely to bring to a solu#on faster than others. This requires the use of heuris#cs",996,recursive
a7944b43-ab2a-4c07-a9be-35fcfd77716d,Lecture_3.pdf,CSCI_80,10,". So far, we selected an unassigned variable randomly. However, some choices are more likely to bring to a solu#on faster than others. This requires the use of heuris#cs. A heuris#c is a rule of thumb, meaning that, more oDen than not, it will bring to a beMer result than following a naive approach, but it is not guaranteed to do so.  Minimum Remaining Values (MRV) is one such heuris#c. The idea here is that if a variable’s domain was constricted by inference, and now it has only one value leD (or even if it’s two values), then by making this assignment we will reduce the number of backtracks we might need to do later. That is, we will have to make this assignment sooner or later, since it’s inferred from enforcing arc-consistency. If this assignment brings to failure, it is beMer to ﬁnd out about it as soon as possible and not backtrack later.  13",860,recursive
ecd4ae5d-b363-4344-8b3d-b6218b290db6,Lecture_3.pdf,CSCI_80,10,". If this assignment brings to failure, it is beMer to ﬁnd out about it as soon as possible and not backtrack later.  13. Minimum Remaining Values  For example, aDer having narrowed down the domains of variables given the current assignment, using the MRV heuris#c, we will choose variable C next and assign the value Wednesday to it.  The Degree heuris#c relies on the degrees of variables, where a degree is how many arcs connect a variable to other variables. By choosing the variable with the highest degree, with one assignment, we constrain mul#ple other variables, speeding the algorithm’s process.",605,recursive
e3df5599-db4a-4aa4-ba79-447bc7e5c924,Lecture_3.pdf,CSCI_80,11,"14. Degree Heuris&c  For example, all the variables above have domains of the same size. Thus, we should pick a domain with the highest degree, which would be variable E.  Both heuris#cs are not always applicable. For example, when mul#ple variables have the same least number of values in their domain, or when mul#ple variables have the same highest degree.  Another way to make the algorithm more eﬃcient is employing yet another heuris#c when we select a value from the domain of a variable. Here, we would like to use the Least Constraining Values heuris#c, where we select the value that will constrain the least other variables. The idea here is that, while in the degree heuris#c we wanted to use the variable that is more likely to constrain other variables, here we want this variable to place the least constraints on other variables",844,recursive
c22064f7-9f02-4008-acfc-29b36cfb2267,Lecture_3.pdf,CSCI_80,11,". That is, we want to locate what could be the largest poten#al source of trouble (the variable with the highest degree), and then render it the least troublesome that we can (assign the least constraining value to it).  15. Least Constraining Value  For example, let’s consider variable C. If we assign Tuesday to it, we will put a constraint on all of B, D, E, and F. However, if we choose Wednesday, we will put a constraint only on B, D, and E. Therefore, it is probably beMer to go with Wednesday.  To summarize, op#miza#on problems can be formulated in mul#ple ways. Today we considered local search, linear programming, and constraint sa#sfac#on.   Consider the following exam scheduling constraint satisfaction graph, where each node represents a course. Each course is associated with an initial domain of possible exam days (most courses could be on Monday, Tuesday, or Wednesday; a few are already restricted to just a single day)",941,recursive
870e5559-c089-452a-9b77-d2f8b137b9e0,Lecture_3.pdf,CSCI_80,11,". Each course is associated with an initial domain of possible exam days (most courses could be on Monday, Tuesday, or Wednesday; a few are already restricted to just a single day). An edge between two nodes means that those two classes must have exams on different days. After enforcing arc consistency on this entire problem, what are the resulting domains for each of the variables? Give one domain for each variable A, B, C, D, E, F, and G.",444,recursive
f7ffacfb-595c-48d7-9ded-2164c5a21f82,lecture4.pdf,CSCI_80,0,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
01083e3c-e300-4b1d-8acb-f8dd0c7e641a,lecture4.pdf,CSCI_80,1,Learning,8,recursive
3f615b66-d80d-430a-8ad4-8ecf5a5852ec,lecture4.pdf,CSCI_80,2,Supervised Learning,19,recursive
80deb15c-f247-4d4d-94ca-471b5d37fb0a,lecture4.pdf,CSCI_80,3,"supervised learning
given a data set of input-output pairs, learn 
a function to map inputs to outputs",102,recursive
fa43046d-4c79-4a9b-943e-754aa1e4fb40,lecture4.pdf,CSCI_80,4,"classiﬁcation
supervised learning task of learning a 
function mapping an input point to a 
discrete category",109,recursive
704d9df2-e163-4dec-8650-477cae4e5010,lecture4.pdf,CSCI_80,6,"Date Humidity 
(relative humidity)
Pressure 
(sea level, mb) Rain",65,recursive
629a3592-0a7d-43a4-adcb-8de66b7f2769,lecture4.pdf,CSCI_80,7,"Date Humidity 
(relative humidity)
Pressure 
(sea level, mb) Rain
January 1 93% 999.7 Rain
January 2 49% 1015.5 No Rain
January 3 79% 1031.1 No Rain
January 4 65% 984.9 Rain
January 5 90% 975.2 Rain",198,recursive
77c8877e-8ec4-4177-a395-ad5c94cfe583,lecture4.pdf,CSCI_80,8,"h(humidity, pressure)
f(93, 999.7) = Rain
f(49, 1015.5) = No Rain
f(humidity, pressure)
f(79, 1031.1) = No Rain",111,recursive
69f9dedd-fec9-4eed-8f94-3ff342c95a20,lecture4.pdf,CSCI_80,9,"humidity
pressure",17,recursive
ea73cf6b-0fde-4af0-99f9-cdaf1043ce26,lecture4.pdf,CSCI_80,10,"humidity
pressure",17,recursive
f5b5ad4a-6891-4420-b33e-31551d3736b9,lecture4.pdf,CSCI_80,11,"humidity
pressure",17,recursive
5f5dc77a-c143-40f7-8438-bdc9f7575601,lecture4.pdf,CSCI_80,12,"humidity
pressure",17,recursive
55519b66-22a6-49b3-b8f5-5d9e7b02c01c,lecture4.pdf,CSCI_80,13,"humidity
pressure",17,recursive
49e7e980-3bc9-4fad-b1c9-95b16b4364d0,lecture4.pdf,CSCI_80,14,"nearest-neighbor classiﬁcation
algorithm that, given an input, chooses the 
class of the nearest data point to that input",121,recursive
41da3432-42ae-457b-bde2-9b8a3a8bd063,lecture4.pdf,CSCI_80,15,"humidity
pressure",17,recursive
7f4cfdff-8a03-42a6-874c-7002319dda32,lecture4.pdf,CSCI_80,16,"humidity
pressure",17,recursive
587c81e9-d754-4bd9-abd4-200bfa191196,lecture4.pdf,CSCI_80,17,"humidity
pressure",17,recursive
5b0fa11b-bc7e-4d74-8bfe-791366cc6774,lecture4.pdf,CSCI_80,18,"humidity
pressure",17,recursive
0852af3e-53d9-4505-9196-318e1e54b6b5,lecture4.pdf,CSCI_80,19,"humidity
pressure",17,recursive
befaaeee-7b72-46a4-bf26-6c781bd5b7a5,lecture4.pdf,CSCI_80,20,"humidity
pressure",17,recursive
87496259-9cd0-4e76-ab4e-84a872abb08f,lecture4.pdf,CSCI_80,21,"k-nearest-neighbor classiﬁcation
algorithm that, given an input, chooses the 
most common class out of the k nearest 
data points to that input",143,recursive
610c93ce-8a12-454a-beac-1ce82b12a091,lecture4.pdf,CSCI_80,22,"humidity
pressure",17,recursive
3032e617-54a6-4d30-8875-150629c0b8ef,lecture4.pdf,CSCI_80,23,"humidity
pressure",17,recursive
15a6ff9c-b76f-4b79-8a82-ee75caef13a5,lecture4.pdf,CSCI_80,24,"x1 = Humidity
x2 = Pressure
h(x1, x2) = No Rain otherwise
Rain if   w0 + w1x1 + w2x2  ≥ 0",89,recursive
a2784f1f-8b24-4e7c-b7da-c4fd8e6879bc,lecture4.pdf,CSCI_80,25,"h(x1, x2) = 0 otherwise
1 if   w0 + w1x1 + w2x2  ≥ 0
Weight Vector w: (w0, w1, w2)
Input Vector x: (1, x1, x2)
w · x: w0 + w1x1 + w2x2",134,recursive
4bc289e6-7c87-47bb-bf35-289094a55ba6,lecture4.pdf,CSCI_80,26,"hw(x) =
0 otherwise
1 if  w · x  ≥ 0
Weight Vector w: (w0, w1, w2)
Input Vector x: (1, x1, x2)
w · x: w0 + w1x1 + w2x2",118,recursive
954da10f-3853-4b92-9e8a-5a16c6e802a2,lecture4.pdf,CSCI_80,27,"perceptron learning rule
Given data point  (x, y), update each weight 
according to: 
wi = wi + α(y - hw(x)) × xi",113,recursive
13024386-eb34-478d-b138-55426d40c4ca,lecture4.pdf,CSCI_80,28,"perceptron learning rule
Given data point  (x, y), update each weight 
according to: 
wi = wi + α(actual value - estimate) × xi",127,recursive
01d6ee28-f557-4b08-8644-a9d29484510a,lecture4.pdf,CSCI_80,29,"output
w · x
0
1",16,recursive
19e95322-86b5-42ff-a878-506f767733cf,lecture4.pdf,CSCI_80,30,"humidity
pressure",17,recursive
fa24098d-756a-4a1c-bc1c-c5d89c2e6b18,lecture4.pdf,CSCI_80,31,"humidity
pressure",17,recursive
13dbd31e-cce0-4d98-ab5a-af622c2b0715,lecture4.pdf,CSCI_80,32,"output
w · x
0
1
hard threshold",31,recursive
2824ea4d-4e8d-4a58-ab91-7caa0b1fb750,lecture4.pdf,CSCI_80,33,"output
w · x
0
1
soft threshold",31,recursive
de753e6b-9bc3-43ef-abf8-2259480c7d7e,lecture4.pdf,CSCI_80,34,Support Vector Machines,23,recursive
c7399ad3-2162-4391-aba7-4129c23ccd35,lecture4.pdf,CSCI_80,38,"maximum margin separator
boundary that maximizes the distance 
between any of the data points",93,recursive
80c8af5a-4a20-4076-8cd9-35788e72b0a3,lecture4.pdf,CSCI_80,41,"regression
supervised learning task of learning a 
function mapping an input point to a 
continuous value",105,recursive
1ad04146-55b1-4c6b-8ee8-95fefaad3848,lecture4.pdf,CSCI_80,42,"h(advertising)
f(1200) = 5800
f(2800) = 13400
f(advertising)
f(1800) = 8400",75,recursive
7eb603d0-cb44-40e8-83a9-d7e238456bde,lecture4.pdf,CSCI_80,43,"advertising
sales",17,recursive
8c9ac373-27f2-41b9-b317-b6edfc5a42ac,lecture4.pdf,CSCI_80,44,Evaluating Hypotheses,21,recursive
9091832e-8c24-41fd-8c9f-d9d60a2d809e,lecture4.pdf,CSCI_80,45,"loss function
function that expresses how poorly our 
hypothesis performs",73,recursive
5f41f084-dc79-409f-ab1a-d43495ca44a7,lecture4.pdf,CSCI_80,46,"0-1 loss function
L(actual, predicted) = 
        0 if actual = predicted, 
        1 otherwise",95,recursive
b26eeee5-29f2-4138-923c-b36e98abca9d,lecture4.pdf,CSCI_80,47,"humidity
pressure",17,recursive
fdc01a6c-9e3d-429c-8e3e-59ef70bfcfca,lecture4.pdf,CSCI_80,48,"humidity
pressure 0
0
0
0
0
0
0
0
0 0
0 0
0
00
0 0 0
0 0 0
0 0
0
0
1
1
1
1
0",76,recursive
c6fb4abb-099b-4237-a7a2-c84ff1c60412,lecture4.pdf,CSCI_80,49,"L1 loss function
L(actual, predicted) = | actual - predicted |",62,recursive
f7aad1d8-8d38-48bb-aeba-b76109b9becf,lecture4.pdf,CSCI_80,50,"advertising
sales",17,recursive
a96bb814-f67f-48d5-9e64-f862482c976d,lecture4.pdf,CSCI_80,51,"advertising
sales",17,recursive
22c9c595-8c30-40f7-a9a0-555c21d8d310,lecture4.pdf,CSCI_80,52,"L2 loss function
L(actual, predicted) = (actual - predicted)2",61,recursive
17dd03a1-0039-4d74-86a0-fc12b668dca5,lecture4.pdf,CSCI_80,53,"overﬁtting
a model that fits too closely to a particular 
data set and therefore may fail to generalize 
to future data",119,recursive
ecba6efe-3eff-4521-91a9-fb33fff5f7c3,lecture4.pdf,CSCI_80,54,"humidity
pressure",17,recursive
71717559-670a-49e4-9250-e33311f53eb7,lecture4.pdf,CSCI_80,55,"humidity
pressure",17,recursive
c22c88fe-f42c-43b9-beab-81acc5828998,lecture4.pdf,CSCI_80,56,"humidity
pressure",17,recursive
3910c5a5-0010-403c-965f-41ac0f784f04,lecture4.pdf,CSCI_80,57,"advertising
sales",17,recursive
9fca3bfd-3492-4574-aa1f-dd4c96acee4f,lecture4.pdf,CSCI_80,58,"advertising
sales",17,recursive
860f8e10-f99a-47b5-83b8-15c7665e7e12,lecture4.pdf,CSCI_80,59,"penalizing hypotheses that are more complex 
to favor simpler, more general hypotheses 
cost(h) = loss(h)",105,recursive
f9916f3c-8db1-4d90-9c51-85d610a0a3f3,lecture4.pdf,CSCI_80,60,"penalizing hypotheses that are more complex 
to favor simpler, more general hypotheses 
cost(h) = loss(h) +   complexity(h)",123,recursive
4113312a-cf8e-483e-8fd8-10bece5eef52,lecture4.pdf,CSCI_80,61,"penalizing hypotheses that are more complex 
to favor simpler, more general hypotheses 
cost(h) = loss(h) + λcomplexity(h)",122,recursive
bf6521b9-2bca-40e9-b63c-c08738bb6ff9,lecture4.pdf,CSCI_80,62,"regularization
penalizing hypotheses that are more complex 
to favor simpler, more general hypotheses 
cost(h) = loss(h) + λcomplexity(h)",137,recursive
21ac2e44-2794-48db-ab86-4b49a751be25,lecture4.pdf,CSCI_80,63,"holdout cross-validation
splitting data into a training set and a 
test set, such that learning happens on the 
training set and is evaluated on the test set",157,recursive
f13bc8ea-9c3a-456b-a6e0-26993f977601,lecture4.pdf,CSCI_80,64,"k-fold cross-validation
splitting data into k sets, and experimenting 
k times, using each set as a test set once, 
and using remaining data as training set",156,recursive
fa713c68-bd9c-4e2b-a85b-6c22840ebe9f,lecture4.pdf,CSCI_80,65,scikit-learn,12,recursive
55546fd5-4b6b-4994-bab4-e2078d3c2550,lecture4.pdf,CSCI_80,66,Reinforcement Learning,22,recursive
7e6c6b8d-f262-4a41-b15d-dc97bc6f7414,lecture4.pdf,CSCI_80,67,"reinforcement learning
given a set of rewards or punishments, learn 
what actions to take in the future",103,recursive
e5b94d02-1c79-4c69-b801-8d5abe53d8a3,lecture4.pdf,CSCI_80,68,"Agent
Environment
stateaction reward",36,recursive
55b33fd2-6229-46a7-80c3-2b52ccafb1f3,lecture4.pdf,CSCI_80,69,"Markov Decision Process
model for decision-making, representing 
states, actions, and their rewards",99,recursive
a386a3af-7b47-488d-9ba6-23f7343a8797,lecture4.pdf,CSCI_80,70,"Markov Decision Process
model for decision-making, representing 
states, actions, and their rewards",99,recursive
b5898ab4-cf26-4f9a-9ed5-8e6eda90773f,lecture4.pdf,CSCI_80,71,"X0 X1 X2 X3 X4
Markov Chain",27,recursive
12548bec-ce36-4ea7-8b1d-8188d8d55f62,lecture4.pdf,CSCI_80,74,"r
r
r
r r r
r r r
r r r",23,recursive
b7e0e22c-04ff-407c-b94a-50d2768d9cba,lecture4.pdf,CSCI_80,75,"Markov Decision Process
•Set of states S 
•Set of actions ACTIONS(s) 
•Transition model P(s' | s, a) 
•Reward function R(s, a, s')",130,recursive
9a1a18a4-9ac7-41cf-9a0d-8c6b77bd7044,lecture4.pdf,CSCI_80,84,"Q-learning
method for learning a function Q(s, a), 
estimate of the value of performing action a 
in state s",108,recursive
a55cc20b-8a05-444f-bacf-50ff3203d611,lecture4.pdf,CSCI_80,85,"Q-learning Overview
•Start with Q(s, a) = 0 for all s, a 
•When we taken an action and receive a reward: 
•Estimate the value of Q(s, a) based on current 
reward and expected future rewards 
•Update Q(s, a) to take into account old estimate as 
well as our new estimate",269,recursive
849bb91d-940f-4264-bfc5-a8386c699b7c,lecture4.pdf,CSCI_80,86,"Q-learning
•Start with Q(s, a) = 0 for all s, a 
•Every time we take an action a in state s and observe a 
reward r, we update: 
 
Q(s, a) ← Q(s, a) + α(new value estimate - old value estimate)",193,recursive
109851f9-82f9-4550-87d8-3ff181867bcf,lecture4.pdf,CSCI_80,87,"Q-learning
•Start with Q(s, a) = 0 for all s, a 
•Every time we take an action a in state s and observe a 
reward r, we update: 
 
Q(s, a) ← Q(s, a) + α(new value estimate - Q(s, a))",182,recursive
e6e3b9aa-0976-493f-a4ea-6956b122375b,lecture4.pdf,CSCI_80,88,"Q-learning
•Start with Q(s, a) = 0 for all s, a 
•Every time we take an action a in state s and observe a 
reward r, we update: 
 
Q(s, a) ← Q(s, a) + α((r + future reward estimate) - Q(s, a))",192,recursive
7e2ae1b7-4258-4d89-8089-2ea265b9a415,lecture4.pdf,CSCI_80,89,"Q-learning
•Start with Q(s, a) = 0 for all s, a 
•Every time we take an action a in state s and observe a 
reward r, we update: 
 
Q(s, a) ← Q(s, a) + α((r + maxa' Q(s', a')) - Q(s, a))",185,recursive
42077d82-5ea8-46e1-b851-f0ddbfae60b5,lecture4.pdf,CSCI_80,90,"Q-learning
•Start with Q(s, a) = 0 for all s, a 
•Every time we take an action a in state s and observe a 
reward r, we update: 
 
Q(s, a) ← Q(s, a) + α((r + γ maxa' Q(s', a')) - Q(s, a))",187,recursive
b865c684-6dec-4e5e-98f1-614fd8a77622,lecture4.pdf,CSCI_80,91,"Greedy Decision-Making
•When in state s, choose action a with highest Q(s, a)",77,recursive
6349cb81-0790-4519-87a6-11fda8f3d954,lecture4.pdf,CSCI_80,94,Explore vs. Exploit,19,recursive
e67448f3-89df-43e6-bf5a-1fe7fc4e9c27,lecture4.pdf,CSCI_80,95,"ε-greedy
•Set ε equal to how often we want to move randomly. 
•With probability 1 - ε, choose estimated best move. 
•With probability ε, choose a random move.",158,recursive
439d0ae2-eae3-4915-9f3b-6dce55cd6807,lecture4.pdf,CSCI_80,96,Nim,3,recursive
218db838-eec9-465f-b381-25c8c1bd7253,lecture4.pdf,CSCI_80,105,"function approximation
approximating Q(s, a), often by a function 
combining various features, rather than 
storing one value for every state-action pair",153,recursive
9d63b658-2d7c-4ba7-9b4f-db402a655870,lecture4.pdf,CSCI_80,106,Unsupervised Learning,21,recursive
260a1239-76f3-4412-8419-d07e61852100,lecture4.pdf,CSCI_80,107,"unsupervised learning
given input data without any additional 
feedback, learn patterns",87,recursive
dbc29403-0c3a-4a1b-ba74-bd282c11cd71,lecture4.pdf,CSCI_80,108,Clustering,10,recursive
3a268e53-9642-495f-a43d-0e26539c725e,lecture4.pdf,CSCI_80,109,"clustering
organizing a set of objects into groups in 
such a way that similar objects tend to be in 
the same group",116,recursive
3513a577-3c39-4e08-833c-1f281c956be2,lecture4.pdf,CSCI_80,110,"Some Clustering Applications
•Genetic research 
•Image segmentation 
•Market research 
•Medical imaging 
•Social network analysis.",130,recursive
fda11ee1-acf2-4364-94c7-2a26cab8c309,lecture4.pdf,CSCI_80,111,"k-means clustering
algorithm for clustering data based on 
repeatedly assigning points to clusters and 
updating those clusters' centers",136,recursive
1567f951-eb36-46ae-a6ed-640e4e5682da,lecture4.pdf,CSCI_80,123,"Learning
•Supervised Learning 
•Reinforcement Learning 
•Unsupervised Learning",78,recursive
8ddb0627-388d-43d2-a2e7-0e7c0257ec77,lecture4.pdf,CSCI_80,124,Learning,8,recursive
a1f9ca59-9ea0-429c-a79c-811f3e8cbc7f,lecture4.pdf,CSCI_80,125,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
ffcd9812-bbdd-4dbb-8737-f09eabbef73f,lecture5.pdf,CSCI_80,0,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
0bd5216f-2312-4623-b299-d2af6c7b290d,lecture5.pdf,CSCI_80,1,Neural Networks,15,recursive
79b8aa7f-a2a2-45c2-9001-074b7b7adc10,lecture5.pdf,CSCI_80,4,"Neural Networks
•Neurons are connected to and receive electrical 
signals from other neurons. 
•Neurons process input signals and can be activated.",147,recursive
1491726c-5b63-415f-bf86-f5a6f91d8204,lecture5.pdf,CSCI_80,5,"artiﬁcial neural network
mathematical model for learning inspired by 
biological neural networks",96,recursive
4c05364d-f1ca-4f72-85c1-6acfed939ac6,lecture5.pdf,CSCI_80,6,"Artiﬁcial Neural Networks
•Model mathematical function from inputs to outputs 
based on the structure and parameters of the 
network. 
•Allows for learning the network's parameters based 
on data.",196,recursive
d9993037-f089-41f4-8962-c1baaa725902,lecture5.pdf,CSCI_80,10,"(x1, x2)",8,recursive
00728d82-450a-4200-9a43-d3a5fd327389,lecture5.pdf,CSCI_80,11,"h(x1, x2) w0 + w1x1 + w2x2=",27,recursive
571464ff-1d0d-4acd-9d52-918ed38c6805,lecture5.pdf,CSCI_80,12,"h(x1, x2) w0 + w1x1 + w2x2=",27,recursive
eb5ecead-4b44-4cce-be01-35f42b140647,lecture5.pdf,CSCI_80,13,"h(x1, x2) w0 + w1x1 + w2x2=",27,recursive
a9833f3a-0c57-4283-ad8f-58c1693d7e28,lecture5.pdf,CSCI_80,14,"output
w · x
0
1
step function
g(x) = 1 if x ≥ 0, else 0",56,recursive
29a56202-133d-427e-b4ef-b128245c205f,lecture5.pdf,CSCI_80,15,"output
w · x
0
1
step function
g(x) = 1 if x ≥ 0, else 0",56,recursive
810cae43-07aa-4763-9cdb-52535b94f1c3,lecture5.pdf,CSCI_80,16,"output
w · x
0
1
logistic sigmoid
g(x) = ex
ex + 1",50,recursive
64c71a4e-5b02-47bb-96ab-001a878916eb,lecture5.pdf,CSCI_80,17,"output
w · x
0
rectiﬁed linear unit (ReLU)
g(x) = max(0, x)",59,recursive
138f3a31-d37e-490c-81ee-68fb713f2258,lecture5.pdf,CSCI_80,18,"h(x1, x2) g(w0 + w1x1 + w2x2)=",30,recursive
e4b1c6c8-df4f-4e83-851d-e65b0173e254,lecture5.pdf,CSCI_80,19,"h(x1, x2) g(w0 + w1x1 + w2x2)=",30,recursive
233d7833-633b-4b1b-bbb2-6cf3ddd9422b,lecture5.pdf,CSCI_80,22,"x1
x2",5,recursive
4503e96f-86df-421c-8bf4-8c6682fa9b73,lecture5.pdf,CSCI_80,23,"x1
x2
w1
w2",11,recursive
49c85164-3dd1-4e47-aa28-b217b50b5d7e,lecture5.pdf,CSCI_80,24,"x1
x2
w1
w2
g(w0 + w1x1 + w2x2)",31,recursive
dd88efa4-0ec4-431d-81d2-56850c292f46,lecture5.pdf,CSCI_80,25,"x1
x2
w1
w2
g(w0 + w1x1 + w2x2)
w0",34,recursive
67254c68-c4d3-45c1-9ac2-3ee3e2add840,lecture5.pdf,CSCI_80,26,"x1
x2
w1
w2
g(w0 + w1x1 + w2x2)",31,recursive
1eb171b6-1255-41bd-bd26-4e87ea954ed5,lecture5.pdf,CSCI_80,27,"Or
x y f(x, y)
0 0 0
0 1 1
1 0 1
1 1 1",38,recursive
0b340fb0-ff5b-46e9-b48f-bddc828d13d8,lecture5.pdf,CSCI_80,28,"x1
x2
w1
w2
g(w0 + w1x1 + w2x2)
w0",34,recursive
69281bdd-d659-465c-afdb-9fc53c9b9001,lecture5.pdf,CSCI_80,29,"x1
x2
1
1
-1
g(-1 + 1x1 + 1x2)
-1 0 1",37,recursive
58569961-f61e-41b1-bff4-59439366861b,lecture5.pdf,CSCI_80,30,"x1
x2
1
1
-1
g(-1 + 1x1 + 1x2)
-1 0 1
0
0
0",43,recursive
c1278aca-e685-4fb2-9323-ccf2932a7793,lecture5.pdf,CSCI_80,31,"x1
x2
1
1
-1
g(-1 + 1x1 + 1x2)
-1 0 1
0
1
1",43,recursive
bb3b349e-efe7-4c8a-8238-570c0fb88578,lecture5.pdf,CSCI_80,32,"x1
x2
1
1
-1
g(-1 + 1x1 + 1x2)
-1 0 1
1
1
1",43,recursive
8f1b436b-785d-4e39-bc41-9b5b0593dc8c,lecture5.pdf,CSCI_80,33,"And
x y f(x, y)
0 0 0
0 1 0
1 0 0
1 1 1",39,recursive
98a169c8-e86e-41aa-9f07-2862a8128baa,lecture5.pdf,CSCI_80,34,"x1
x2
1
1
-1
g(-1 + 1x1 + 1x2)
-1 0 1",37,recursive
398d49f6-150b-4b0e-960b-91b4b94e7c66,lecture5.pdf,CSCI_80,35,"x1
x2
1
1
-2
g(-2 + 1x1 + 1x2)
-1 0 1",37,recursive
e4a4bba6-2bea-4103-96c6-c900965322fd,lecture5.pdf,CSCI_80,36,"x1
x2
1
1
-2
g(-2 + 1x1 + 1x2)
-1 0 1
1
1
1",43,recursive
0ad83136-d963-4102-b9bb-4721fceba48d,lecture5.pdf,CSCI_80,37,"x1
x2
1
1
-2
g(-2 + 1x1 + 1x2)
-1 0 1
0
1
0",43,recursive
09371185-fcb8-4fd0-8baf-f4b92e2b6310,lecture5.pdf,CSCI_80,39,"humidity
pressure
probability 
of rain",38,recursive
71b6f3ce-03ef-42a5-9c7d-61896ffd46da,lecture5.pdf,CSCI_80,40,"advertising
month
sales",23,recursive
97899ab0-6e05-4720-9955-6dab76c632d3,lecture5.pdf,CSCI_80,43,…,1,recursive
17515e2b-c483-4018-8260-e0fb5919c682,lecture5.pdf,CSCI_80,44,"x1
x2
w1
w2
g(w0 + w1x1 + w2x2)",31,recursive
bc160fd9-317f-4417-8445-2303d4f87eb7,lecture5.pdf,CSCI_80,45,"x1
x2
w1
w3
g(w0 + w1x1 + w2x2 
     + w3x3)
w2
x3",50,recursive
f5209cf0-0498-4e2b-a74a-b23db6d5146c,lecture5.pdf,CSCI_80,46,"x1
x2
x3
x4
x5
w1
w2
w3
w4
w5
g(
5
∑i=1
xiwi + w0)",50,recursive
5c4f031c-21da-4d5b-9fe0-b6b68c6fe3b9,lecture5.pdf,CSCI_80,47,"…
x1
x2
xn-1
xn
w1
w2
wn-1
wn
g(
n
∑i=1
xiwi + w0)",50,recursive
2d0aeb38-fbb2-4add-952c-c4d329c95da8,lecture5.pdf,CSCI_80,48,"gradient descent
algorithm for minimizing loss when training 
neural network",76,recursive
1d904b79-b9b2-42fa-9c7d-48b6ab488478,lecture5.pdf,CSCI_80,49,"Gradient Descent
•Start with a random choice of weights. 
•Repeat: 
•Calculate the gradient based on all data points: 
direction that will lead to decreasing loss. 
•Update weights according to the gradient.",207,recursive
811eb810-7ae1-47dd-aabe-40ff9d187280,lecture5.pdf,CSCI_80,50,"Gradient Descent
•Start with a random choice of weights. 
•Repeat: 
•Calculate the gradient based on all data points: 
direction that will lead to decreasing loss. 
•Update weights according to the gradient.",207,recursive
6051b6f5-3dcc-47e9-a0b3-ff673756baa2,lecture5.pdf,CSCI_80,51,"Stochastic Gradient Descent
•Start with a random choice of weights. 
•Repeat: 
•Calculate the gradient based on one data point: 
direction that will lead to decreasing loss. 
•Update weights according to the gradient.",217,recursive
ab5c442e-b494-4565-a90e-ac63484ffcad,lecture5.pdf,CSCI_80,52,"Mini-Batch Gradient Descent
•Start with a random choice of weights. 
•Repeat: 
•Calculate the gradient based on one small batch: 
direction that will lead to decreasing loss. 
•Update weights according to the gradient.",218,recursive
6ff40b4b-512b-415b-982c-6087d6e0f1bb,lecture5.pdf,CSCI_80,56,"rainy
sunny
cloudy
snowy",24,recursive
97d8d1d1-1c8c-43a7-aff5-09e216946ddb,lecture5.pdf,CSCI_80,57,"rainy
sunny
cloudy
snowy",24,recursive
0a02e862-5ff3-48b9-8a71-b984e4014c02,lecture5.pdf,CSCI_80,58,"rainy
sunny
cloudy
snowy",24,recursive
d9053f27-b3cc-4038-bce3-ad9d670e2e5f,lecture5.pdf,CSCI_80,59,"rainy
sunny
cloudy
snowy",24,recursive
bc4213d1-825d-45f1-8efe-c5f4f56ee56f,lecture5.pdf,CSCI_80,60,"rainy
sunny
cloudy
snowy
0.1
0.1
0.2
0.6",40,recursive
2b26aa47-1085-4d8d-8a82-b3594965b156,lecture5.pdf,CSCI_80,61,"rainy
sunny
cloudy
snowy
0.1
0.1
0.6
0.2",40,recursive
fd6bfc34-661c-4f52-bc03-619d8c079818,lecture5.pdf,CSCI_80,63,"action 1
action 2
action 3
action 4",35,recursive
913b0cdf-9b41-41cc-8b8d-e2dd37bb4f82,lecture5.pdf,CSCI_80,73,"Perceptron
•Only capable of learning linearly separable decision 
boundary.",75,recursive
6b08a9ed-507e-430c-8fc1-b49cbfc2c2ca,lecture5.pdf,CSCI_80,74,"multilayer neural network
artificial neural network with an input layer, 
an output layer, and at least one hidden layer",120,recursive
b46d421b-4d4d-4bfb-829f-7b8dbc32ff1f,lecture5.pdf,CSCI_80,83,"backpropagation
algorithm for training neural networks with 
hidden layers",74,recursive
dbcf2293-360f-45b1-869b-13066695cd02,lecture5.pdf,CSCI_80,84,"Backpropagation
•Start with a random choice of weights. 
•Repeat: 
•Calculate error for output layer. 
•For each layer, starting with output layer, and 
moving inwards towards earliest hidden layer: 
•Propagate error back one layer. 
•Update weights.",250,recursive
e0c255a3-2b37-4469-a670-0b0e26c34019,lecture5.pdf,CSCI_80,92,"deep neural networks
neural network with multiple hidden layers",63,recursive
257a698d-48ed-4be9-8432-65ad3865c66b,lecture5.pdf,CSCI_80,94,Overﬁtting,10,recursive
fa84a6e4-edf4-418a-8652-838d12b94ddb,lecture5.pdf,CSCI_80,95,"dropout
temporarily removing units — selected at 
random — from a neural network to prevent 
over-reliance on certain units",123,recursive
479af4c3-75be-458e-9941-2eb8e0f2bec9,lecture5.pdf,CSCI_80,101,TensorFlow,10,recursive
24952f4a-d02f-418b-9d45-e45780792c83,lecture5.pdf,CSCI_80,102,playground.tensorflow.org,25,recursive
31e41899-0c04-4fed-8b79-15b58342856d,lecture5.pdf,CSCI_80,103,"computer vision
computational methods for analyzing and 
understanding digital images",85,recursive
56866165-7096-46f1-bd17-e83813406d08,lecture5.pdf,CSCI_80,108,0 255,5,recursive
cbfe654a-7f30-47cb-8c68-d83d232f5df6,lecture5.pdf,CSCI_80,109,0 255,5,recursive
3b882963-6304-4b00-b105-700afbff5852,lecture5.pdf,CSCI_80,110,0 255,5,recursive
eed092c3-3daa-4461-9327-4d97bbfaff5e,lecture5.pdf,CSCI_80,111,0 25500 255255,14,recursive
83ad8b76-be8c-4bda-8cbf-4b1baa450e1d,lecture5.pdf,CSCI_80,112,"0 255
0 255
0 255",17,recursive
3e7fd555-d9a5-4c67-879a-fae77a136c63,lecture5.pdf,CSCI_80,113,"0 255
0 255
0 255",17,recursive
61b2aa22-5632-4f8f-bed8-cde87f37e7c9,lecture5.pdf,CSCI_80,114,"0 255
0 255
0 255",17,recursive
eb974802-2f09-4a6a-b068-a1c33cb15575,lecture5.pdf,CSCI_80,115,"0 255
0 255
0 255",17,recursive
69e34cd4-6e84-411f-8cbe-f68667cbb9ab,lecture5.pdf,CSCI_80,116,"0 255
0 255
0 255",17,recursive
87afdf13-c4b5-4f45-9900-95353a6b203f,lecture5.pdf,CSCI_80,117,"0 255
0 255
0 255",17,recursive
4bc1d797-0373-4c4c-a6c5-f0fb1b7ca84b,lecture5.pdf,CSCI_80,118,"0 255
0 255
0 255",17,recursive
f21ce69d-4da9-4fb8-bcd9-5ea18f6a1ae7,lecture5.pdf,CSCI_80,119,"0 255
0 255
0 255",17,recursive
6f157c2d-548e-4118-b90e-3a71f73bc5b2,lecture5.pdf,CSCI_80,121,"...
...",7,recursive
62d0719b-dceb-4484-80af-3d918ca0773c,lecture5.pdf,CSCI_80,122,"image convolution
applying a filter that adds each pixel value 
of an image to its neighbors, weighted 
according to a kernel matrix",132,recursive
fb547b1b-9c63-4a7b-87c3-6f576e38c88d,lecture5.pdf,CSCI_80,123,"0 -1 0
-1 5 -1
0 -1 0",21,recursive
abeb762c-f469-477c-8e66-03b87aa1410a,lecture5.pdf,CSCI_80,124,"0 -1 0
-1 5 -1
0 -1 0
10 20 30 40
10 20 30 40
20 30 40 50
20 30 40 50",69,recursive
3a68754f-749d-48de-94f8-b42337831cfc,lecture5.pdf,CSCI_80,125,"0 -1 0
-1 5 -1
0 -1 0
10 20 30 40
10 20 30 40
20 30 40 50
20 30 40 50",69,recursive
708665c5-5855-4cd3-91de-a5319daa2d42,lecture5.pdf,CSCI_80,126,"0 -1 0
-1 5 -1
0 -1 0
10 20 30 40
10 20 30 40
20 30 40 50
20 30 40 50",69,recursive
2dac53c7-9a36-4867-9f18-dab775043af3,lecture5.pdf,CSCI_80,127,"0 -1 0
-1 5 -1
0 -1 0
10 20 30 40
10 20 30 40
20 30 40 50
20 30 40 50
10",72,recursive
d566f5fc-b340-4d2f-9d88-a956cf4dedba,lecture5.pdf,CSCI_80,128,"0 -1 0
-1 5 -1
0 -1 0
10 20 30 40
10 20 30 40
20 30 40 50
20 30 40 50
10",72,recursive
a498e336-3977-44fc-8028-ac7ad97089dc,lecture5.pdf,CSCI_80,129,"0 -1 0
-1 5 -1
0 -1 0
10 20 30 40
10 20 30 40
20 30 40 50
20 30 40 50
10 20",75,recursive
bb795d7a-e8f8-4d7d-970c-f1050013df35,lecture5.pdf,CSCI_80,130,"0 -1 0
-1 5 -1
0 -1 0
10 20 30 40
10 20 30 40
20 30 40 50
20 30 40 50
10 20
40",78,recursive
e451fa1f-289f-4c2c-a747-33a307e311f9,lecture5.pdf,CSCI_80,131,"0 -1 0
-1 5 -1
0 -1 0
10 20 30 40
10 20 30 40
20 30 40 50
20 30 40 50
10 20
40",78,recursive
cd10f6ee-4460-4aa3-afef-832601641269,lecture5.pdf,CSCI_80,132,"0 -1 0
-1 5 -1
0 -1 0
10 20 30 40
10 20 30 40
20 30 40 50
20 30 40 50
10 20
40 50",81,recursive
9177ef38-cb93-417a-bde3-601f34b3e1ca,lecture5.pdf,CSCI_80,133,"0 -1 0
-1 5 -1
0 -1 0
10 20 30 40
10 20 30 40
20 30 40 50
20 30 40 50
10 20
40 50",81,recursive
5a267a10-7618-4c12-83f8-f617c9cfc439,lecture5.pdf,CSCI_80,134,"-1 -1 -1
-1 8 -1
-1 -1 -1",25,recursive
4c387ce0-b99e-4c84-8e29-48d81cfc8f8d,lecture5.pdf,CSCI_80,135,"-1 -1 -1
-1 8 -1
-1 -1 -1
20 20 20
20 20 20
20 20 20
  (20)(-1) + (20)(-1) + (20)(-1) 
+ (20)(-1) + (20)(8)  + (20)(-1) 
+ (20)(-1) + (20)(-1) + (20)(-1)
0",155,recursive
7966e465-420b-480b-9368-35c9c888bca5,lecture5.pdf,CSCI_80,136,"-1 -1 -1
-1 8 -1
-1 -1 -1
20 20 20
50 50 50
50 50 50
  (20)(-1) + (20)(-1) + (20)(-1) 
+ (50)(-1) + (50)(8)  + (50)(-1) 
+ (50)(-1) + (50)(-1) + (50)(-1)
90",156,recursive
eedda56f-aa54-4e8b-b88e-a120f9ee39e6,lecture5.pdf,CSCI_80,139,"pooling
reducing the size of an input by sampling 
from regions in the input",76,recursive
7c49f230-0d4b-420e-a194-64a9011de7d1,lecture5.pdf,CSCI_80,140,"max-pooling
pooling by choosing the maximum value in 
each region",65,recursive
25fda3cf-5d36-48e3-86d9-59073bfa97c3,lecture5.pdf,CSCI_80,141,"30 40 80 90
20 50 100 110
0 10 20 30
10 20 40 30",48,recursive
047bfd4a-3793-41e1-b148-9c55f912bd37,lecture5.pdf,CSCI_80,142,"30 40 80 90
20 50 100 110
0 10 20 30
10 20 40 30",48,recursive
a66788fa-8a98-4e89-9f03-a2de9010f44c,lecture5.pdf,CSCI_80,143,"30 40 80 90
20 50 100 110
0 10 20 30
10 20 40 30",48,recursive
675530e2-79c4-444b-bb92-3af0a86e0a09,lecture5.pdf,CSCI_80,144,"30 40 80 90
20 50 100 110
0 10 20 30
10 20 40 30
50",51,recursive
98a803e0-934d-487c-8033-ebde0d8b7442,lecture5.pdf,CSCI_80,145,"30 40 80 90
20 50 100 110
0 10 20 30
10 20 40 30
50",51,recursive
1ba082e7-0418-4aee-bb63-8331134b62f4,lecture5.pdf,CSCI_80,146,"30 40 80 90
20 50 100 110
0 10 20 30
10 20 40 30
50 110",55,recursive
197324f6-5751-46e9-a9c4-a4858afa7eca,lecture5.pdf,CSCI_80,147,"30 40 80 90
20 50 100 110
0 10 20 30
10 20 40 30
50 110",55,recursive
87735564-67df-4ec6-97ce-ee04c1d2f8ab,lecture5.pdf,CSCI_80,148,"30 40 80 90
20 50 100 110
0 10 20 30
10 20 40 30
50 110
20",58,recursive
40866aa9-41b4-4cb5-9475-2b92e81d5688,lecture5.pdf,CSCI_80,149,"30 40 80 90
20 50 100 110
0 10 20 30
10 20 40 30
50 110
20",58,recursive
1966e0e6-be3e-4cba-a00f-beec8f5f93e2,lecture5.pdf,CSCI_80,150,"30 40 80 90
20 50 100 110
0 10 20 30
10 20 40 30
50 110
20 40",61,recursive
22bba6e5-b8fa-481d-a019-2de2992f75bf,lecture5.pdf,CSCI_80,151,"30 40 80 90
20 50 100 110
0 10 20 30
10 20 40 30
50 110
20 40",61,recursive
d7d37818-a789-433a-9382-42ff22916118,lecture5.pdf,CSCI_80,152,"convolutional neural network
neural networks that use convolution, 
usually for analyzing images",96,recursive
e9670523-ac37-4f7e-bd1c-87a95d9a9218,lecture5.pdf,CSCI_80,153,convolution pooling flattening,30,recursive
3a006a05-9a71-4df2-931d-83a144b30979,lecture5.pdf,CSCI_80,154,"first 
convolution and pooling
second 
convolution and pooling
low-level features: 
edges, curves, shapes
high-level features: 
objects",135,recursive
2a4c2811-5174-4ed9-bce5-e2cadf1a37b1,lecture5.pdf,CSCI_80,156,input network output,20,recursive
5cb66532-6437-4a8f-9046-3f82406391ec,lecture5.pdf,CSCI_80,157,input network output,20,recursive
a0872d31-36ff-4c2d-ad4c-df7b3d1cda86,lecture5.pdf,CSCI_80,158,"feed-forward neural network
neural network that has connections only in 
one direction",86,recursive
8f8f4dcf-4c6e-4f90-b072-34b884a33f5a,lecture5.pdf,CSCI_80,159,"recurrent neural network
neural network that generates output that 
feeds back into its own inputs",98,recursive
e6422bca-6e02-48f0-a0a0-d155356f4170,lecture5.pdf,CSCI_80,160,input network output,20,recursive
945dbc22-43e3-4b21-a880-efad3561459f,lecture5.pdf,CSCI_80,161,group of people walking in front of a building,46,recursive
e488175b-79e3-41a2-9412-e11cde3afd02,lecture5.pdf,CSCI_80,162,"input network output
network output
network output
network output",65,recursive
65955cfb-2e84-489a-b5d1-fe11fc447265,lecture5.pdf,CSCI_80,164,"input network
network
network
network output
input
input
input",62,recursive
101fb37c-2cee-4afe-bae7-d4abb1baae2a,lecture5.pdf,CSCI_80,165,"She is in the library.
她在圖書館",28,recursive
e3c6e9ed-7f1a-4de7-9ac7-62488bbcbb53,lecture5.pdf,CSCI_80,166,"input network
networkinput
networkinput
networkinput output
network output
network output",89,recursive
b5553aa3-ee52-4be4-ab30-78c0b00a1a62,lecture5.pdf,CSCI_80,167,Neural Networks,15,recursive
2fb5d4e0-f983-4745-b0a8-59021118a43f,lecture5.pdf,CSCI_80,168,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
22c6ccd1-12c2-4402-b15e-bae023f301e1,lecture3.pdf,CSCI_80,0,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
931da3aa-750c-4e51-ab5b-64c520d77aac,lecture3.pdf,CSCI_80,1,Optimization,12,recursive
8203528b-db9d-4a26-91b6-8cb193c8aad2,lecture3.pdf,CSCI_80,2,"optimization
choosing the best option from a set of 
options",60,recursive
c23a14bf-6c5e-4d2d-9be9-7badbccf5e99,lecture3.pdf,CSCI_80,3,"local search
search algorithms that maintain a single 
node and searches by moving to a 
neighboring node",105,recursive
3c5c6b99-3faa-4081-946d-f5b0d2b46025,lecture3.pdf,CSCI_80,4,"B
A",3,recursive
73664d17-8eb0-4461-9692-83d515e46203,lecture3.pdf,CSCI_80,5,B,1,recursive
31ef510b-59e6-4536-a926-ac8b9904d5e3,lecture3.pdf,CSCI_80,7,Cost: 17,8,recursive
e8b384be-c4f4-4d21-bb5a-5d863c96a08a,lecture3.pdf,CSCI_80,8,state-space landscape,21,recursive
d7efbb79-0982-4c3e-b5e5-6f3523d5594e,lecture3.pdf,CSCI_80,9,"global maximumobjective 
function",33,recursive
3df0e8cd-61fb-4f6a-9dd7-4e51e4dff98f,lecture3.pdf,CSCI_80,10,"global minimumcost 
function",28,recursive
bacf196e-7ba8-456c-bce0-bdc06ea2a59f,lecture3.pdf,CSCI_80,11,current state,13,recursive
07aaf56e-522c-4dd5-a341-f4aa4a413219,lecture3.pdf,CSCI_80,12,neighbors,9,recursive
0a0fda0b-9dd1-4cad-aaa6-9afce2c30522,lecture3.pdf,CSCI_80,13,Hill Climbing,13,recursive
8c5a43c3-6c1b-4ace-8b70-2097353efdc5,lecture3.pdf,CSCI_80,25,"Hill Climbing
function HILL-CLIMB(problem): 
    current = initial state of problem 
    repeat: 
        neighbor = highest valued neighbor of current 
        if neighbor not better than current: 
            return current 
        current = neighbor",253,recursive
572b39a1-eb83-4629-a98d-f8b0f5098712,lecture3.pdf,CSCI_80,26,Cost: 17,8,recursive
b37372f3-c1e1-4526-9883-6a2533343b2f,lecture3.pdf,CSCI_80,27,Cost: 17,8,recursive
3b19f9bf-726a-4364-aaf5-f40fe18fd81c,lecture3.pdf,CSCI_80,28,Cost: 17,8,recursive
140b276e-832e-433c-a0be-eb42ff8b61a5,lecture3.pdf,CSCI_80,29,Cost: 15,8,recursive
64286c7c-0d58-4387-9b52-0317b5d005c8,lecture3.pdf,CSCI_80,30,Cost: 13,8,recursive
93172cab-5ad0-4db1-a8fe-397e15f9a31f,lecture3.pdf,CSCI_80,31,Cost: 11,8,recursive
7fb919fd-42da-4515-9e19-41f2e5a49204,lecture3.pdf,CSCI_80,32,Cost: 9,7,recursive
a5bd3823-669a-4bb3-b9fd-769b305238e7,lecture3.pdf,CSCI_80,34,global maximum,14,recursive
c60425df-d119-490c-b54b-dd16e55ef5a4,lecture3.pdf,CSCI_80,35,local maxima,12,recursive
c44748c9-2c34-4a06-bf97-7c4979146eb8,lecture3.pdf,CSCI_80,36,global minimum,14,recursive
9d4f3f54-58bb-4671-a375-8940d5ee6f39,lecture3.pdf,CSCI_80,37,local minima,12,recursive
f0463c15-3aca-4adc-993a-0a0bbd111962,lecture3.pdf,CSCI_80,43,ﬂat local maximum,17,recursive
f03c2a64-3a26-4434-b0c7-5de45dcad841,lecture3.pdf,CSCI_80,44,shoulder,8,recursive
3b054026-e92c-478f-b269-6ffbbd881b12,lecture3.pdf,CSCI_80,45,"Variant Definition
steepest-ascent choose the highest-valued neighbor
stochastic choose randomly from higher-valued 
neighbors
first-choice choose the first higher-valued neighbor
random-restart conduct hill climbing multiple times
local beam search chooses the k highest-valued neighbors
Hill Climbing Variants",311,recursive
b941b4b6-c45a-48d1-ae3a-72cef407c012,lecture3.pdf,CSCI_80,46,Simulated Annealing,19,recursive
55e74121-5b44-4911-aa17-36c796a7bf76,lecture3.pdf,CSCI_80,55,"Simulated Annealing
•Early on, higher ""temperature"": more likely to accept 
neighbors that are worse than current state 
•Later on, lower ""temperature"": less likely to accept 
neighbors that are worse than current state",219,recursive
26100244-1756-4bd0-97b6-f9bdee8a91b5,lecture3.pdf,CSCI_80,56,"Simulated Annealing
function SIMULATED-ANNEALING(problem, max): 
    current = initial state of problem 
    for t = 1 to max: 
        T = TEMPERATURE(t) 
        neighbor = random neighbor of current 
        ΔE = how much better neighbor is than current 
        if ΔE > 0: 
            current = neighbor 
        with probability eΔE/T set current = neighbor 
    return current",383,recursive
2ad7c2d4-d1d8-4d09-bc7c-43250418cfa8,lecture3.pdf,CSCI_80,57,Traveling Salesman Problem,26,recursive
58abb047-94ba-4762-bb8d-8b6c1a2e3113,lecture3.pdf,CSCI_80,65,Linear Programming,18,recursive
6dd5cf96-6cf2-4b38-9d0a-e8a7e5baf1f8,lecture3.pdf,CSCI_80,66,"Linear Programming
•Minimize a cost function c1x1 + c2x2 + ... + cnxn  
•With constraints of form a1x1 + a2x2 + ... + anxn ≤ b 
or of form a1x1 + a2x2 + ... + anxn = b 
•With bounds for each variable li ≤ xi ≤ ui",212,recursive
e06755ee-5892-4288-bbb2-b0d67c209b08,lecture3.pdf,CSCI_80,67,"Linear Programming Example
•Two machines X1 and X2. X1 costs $50/hour to run, X2 
costs $80/hour to run. Goal is to minimize cost. 
• X1 requires 5 units of labor per hour. X2 requires 2 
units of labor per hour. Total of 20 units of labor to 
spend. 
• X1 produces 10 units of output per hour. X2 produces 
12 units of output per hour. Company needs 90 units 
of output.",371,recursive
406c4021-4b5a-4d9f-aae5-effb182bbf08,lecture3.pdf,CSCI_80,68,"Linear Programming Example
•Two machines X1 and X2. X1 costs $50/hour to run, X2 
costs $80/hour to run. 
• X1 requires 5 units of labor per hour. X2 requires 2 
units of labor per hour. Total of 20 units of labor to 
spend. 
• X1 produces 10 units of output per hour. X2 produces 
12 units of output per hour. Company needs 90 units 
of output.
50x1 + 80x2Cost Function:",371,recursive
20d94ba0-f657-4589-a300-99feb03dc302,lecture3.pdf,CSCI_80,69,"Linear Programming Example
•Two machines X1 and X2. X1 costs $50/hour to run, X2 
costs $80/hour to run. 
• X1 requires 5 units of labor per hour. X2 requires 2 
units of labor per hour. Total of 20 units of labor to 
spend. 
• X1 produces 10 units of output per hour. X2 produces 
12 units of output per hour. Company needs 90 units 
of output.
50x1 + 80x2Cost Function:
5x1 + 2x2 ≤ 20Constraint:",397,recursive
5be3bc17-2c2f-4ced-aa65-a2f5017339c9,lecture3.pdf,CSCI_80,70,"Linear Programming Example
•Two machines X1 and X2. X1 costs $50/hour to run, X2 
costs $80/hour to run. 
• X1 requires 5 units of labor per hour. X2 requires 2 
units of labor per hour. Total of 20 units of labor to 
spend. 
• X1 produces 10 units of output per hour. X2 produces 
12 units of output per hour. Company needs 90 units 
of output.
50x1 + 80x2Cost Function:
5x1 + 2x2 ≤ 20Constraint:
10x1 + 12x2 ≥ 90Constraint:",425,recursive
8a0d9c61-83d2-4eda-99dc-be72b585479f,lecture3.pdf,CSCI_80,71,"Linear Programming Example
•Two machines X1 and X2. X1 costs $50/hour to run, X2 
costs $80/hour to run. 
• X1 requires 5 units of labor per hour. X2 requires 2 
units of labor per hour. Total of 20 units of labor to 
spend. 
• X1 produces 10 units of output per hour. X2 produces 
12 units of output per hour. Company needs 90 units 
of output.
50x1 + 80x2Cost Function:
5x1 + 2x2 ≤ 20Constraint:
(−10x1) + (−12x2) ≤ − 90Constraint:",433,recursive
ded950f3-a5b2-4578-8b46-c3f1bc216eba,lecture3.pdf,CSCI_80,72,"Linear Programming Algorithms
•Simplex 
•Interior-Point",55,recursive
5b5a5767-6cbf-4164-9417-1fefbf4d064c,lecture3.pdf,CSCI_80,73,Constraint Satisfaction,23,recursive
e2fe6486-2dda-49d7-a6f7-4aeb1f6dd66c,lecture3.pdf,CSCI_80,74,"1
2
3
4
Student:",16,recursive
b5d41f88-1bb6-49f0-ac51-d66eadc8fe30,lecture3.pdf,CSCI_80,75,"1
2
3
4
Student: Taking classes:
A B C
B D E
C E F
E F G",56,recursive
973db45b-b53e-4484-bf0d-4562bad54216,lecture3.pdf,CSCI_80,76,"1
2
3
4
Student: Taking classes:
A B C
B D E
C E F
E F G
Exam slots:
Monday
Tuesday
Wednesday",93,recursive
5e3900e1-4460-49bc-b806-b89be1eab461,lecture3.pdf,CSCI_80,77,"1
2
3
4
A B C
B D E
C E F
E F G
A
B C
D
E
F
G",45,recursive
714806bf-1091-4bce-b831-f7341c8d73e9,lecture3.pdf,CSCI_80,78,"1
2
3
4
A B C
B D E
C E F
E F G
A
B C
D
E
F
G",45,recursive
91ee4166-2826-42be-92aa-5f973d93d1cd,lecture3.pdf,CSCI_80,79,"1
2
3
4
A B C
B D E
C E F
E F G
A
B C
D
E
F
G",45,recursive
f5dea34d-8a01-4c96-8cfd-b2acb9ab7954,lecture3.pdf,CSCI_80,80,"1
2
3
4
A B C
B D E
C E F
E F G
A
B C
D
E
F
G",45,recursive
96a23525-eaae-44f0-833d-ff2e67caa897,lecture3.pdf,CSCI_80,81,"1
2
3
4
A B C
B D E
C E F
E F G
A
B C
D
E
F
G",45,recursive
798acaf6-6b1b-4509-a01c-f7c5a635cdaa,lecture3.pdf,CSCI_80,82,"1
2
3
4
A B C
B D E
C E F
E F G
A
B C
D
E
F
G",45,recursive
bf31802a-9051-4e44-a286-d282faaaf835,lecture3.pdf,CSCI_80,83,"1
2
3
4
A B C
B D E
C E F
E F G
A
B C
D
E
F
G",45,recursive
f585dbae-a15a-4b84-b33a-4c903440239f,lecture3.pdf,CSCI_80,84,"1
2
3
4
A B C
B D E
C E F
E F G
A
B C
D
E
F
G",45,recursive
8c70f0fa-39de-4ab8-9ce9-34b9b84559ad,lecture3.pdf,CSCI_80,85,"1
2
3
4
A B C
B D E
C E F
E F G
A
B C
D
E
F
G",45,recursive
060ee990-629e-4821-9d3b-ff7ac5764c93,lecture3.pdf,CSCI_80,86,"A
B C
D
E
F
G",13,recursive
49049a39-30c0-463c-8840-bb40de3e17e4,lecture3.pdf,CSCI_80,87,"Constraint Satisfaction Problem
•Set of variables {X1, X2, ..., Xn} 
•Set of domains for each variable {D1, D2, ..., Dn} 
•Set of constraints C",143,recursive
f2aba8b8-14ee-43a2-be66-f7d7d6913367,lecture3.pdf,CSCI_80,88,"Variables
{(0, 2), (1, 1), (1, 2), (2, 0), ...}
Domains
{1, 2, 3, 4, 5, 6, 7, 8, 9}
for each variable
Constraints
{(0, 2) ≠ (1, 1) ≠ (1, 2) ≠ (2, 0), ...}
5 3 7
6 1 9 5
9 8 6
8 6 3
4 8 3 1
7 2 6
6 2 8
4 1 9 5
8 7 9",214,recursive
6164651a-c33c-4d90-a8dc-08efb503623a,lecture3.pdf,CSCI_80,89,"A
B C
D
E
F
G
Variables
{A, B, C, D, E, F, G}
Domains
{Monday, Tuesday, Wednesday}
for each variable
Constraints
{A≠B, A≠C, B≠C, B≠D, B≠E, C≠E, 
C≠F, D≠E, E≠F, E≠G, F≠G}",169,recursive
79c921ac-ed56-4151-a406-197505327c63,lecture3.pdf,CSCI_80,90,"hard constraints
constraints that must be satisfied in a 
correct solution",74,recursive
4c9757c7-2567-45ef-be88-e12bb1755ea9,lecture3.pdf,CSCI_80,91,"soft constraints
constraints that express some notion of 
which solutions are preferred over others",99,recursive
4828b560-5fad-4311-9357-e96dd5018b0f,lecture3.pdf,CSCI_80,92,"A
B C
D
E
F
G",13,recursive
370a44d9-0654-43a8-9fbc-1368d9dbce49,lecture3.pdf,CSCI_80,93,"unary constraint
constraint involving only one variable",55,recursive
7a23489b-3ba5-453f-b0a9-70d018b85b88,lecture3.pdf,CSCI_80,94,"unary constraint
{A ≠ Monday}",29,recursive
f3138be4-9ab6-49ee-a43b-3cc90868e957,lecture3.pdf,CSCI_80,95,"binary constraint
constraint involving two variables",52,recursive
7ba518a5-2e14-4660-aeec-6232ea85bef0,lecture3.pdf,CSCI_80,96,"binary constraint
{A ≠ B}",25,recursive
5d0e36fb-2fdd-449f-a5d8-adb4d775fd4e,lecture3.pdf,CSCI_80,97,"node consistency
when all the values in a variable's domain 
satisfy the variable's unary constraints",101,recursive
19514fa9-9196-4f63-b5da-9edc5decefe8,lecture3.pdf,CSCI_80,98,"A B
{Mon, Tue, Wed} {Mon, Tue, Wed}
{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}",70,recursive
78f86573-3754-4bfd-863e-3d5356c5d464,lecture3.pdf,CSCI_80,99,"A B
{Mon, Tue, Wed} {Mon, Tue, Wed}
{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}",70,recursive
06dad628-e7fd-4231-b89f-10917c7f81f9,lecture3.pdf,CSCI_80,100,"A B
{Tue, Wed} {Mon, Tue, Wed}
{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}",65,recursive
1bd31cf0-70b8-4ba7-90dc-34f9ffe5cba5,lecture3.pdf,CSCI_80,101,"A B
{Tue, Wed}
{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}
{Mon, Tue, Wed}",65,recursive
8ae19e9e-a0e2-459e-a4b7-c7f76151cc67,lecture3.pdf,CSCI_80,102,"A B
{Tue, Wed} {Mon, Wed}
{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}",60,recursive
309f2160-623a-41cb-b6ba-641b1d9c798c,lecture3.pdf,CSCI_80,103,"A B
{Tue, Wed} {Mon, Wed}
{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}",60,recursive
33671492-df63-4807-8fa2-97ddb26bcc88,lecture3.pdf,CSCI_80,104,"A B
{Tue, Wed} {Wed}
{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}",55,recursive
1cd7af39-d255-42b9-93a6-c3acb734bebc,lecture3.pdf,CSCI_80,105,"A B
{Tue, Wed} {Wed}
{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}",55,recursive
dc4c7d20-edb3-496e-8062-f7e189e15977,lecture3.pdf,CSCI_80,106,"arc consistency
when all the values in a variable's domain 
satisfy the variable's binary constraints",101,recursive
4be6a652-691e-4001-a055-19ff903a1316,lecture3.pdf,CSCI_80,107,"arc consistency
To make X arc-consistent with respect to Y, 
remove elements from X's domain until every 
choice for X has a possible choice for Y",146,recursive
d1c3999e-07d7-475b-b745-ee971bf3e8ad,lecture3.pdf,CSCI_80,108,"A B
{Tue, Wed} {Wed}
{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}",55,recursive
ffdb1a5f-5202-4f94-9cd1-1b1c90cabe5a,lecture3.pdf,CSCI_80,109,"A B
{Tue, Wed} {Wed}
{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}",55,recursive
19c04a6a-c8d2-4473-9462-0b1c89e4aac0,lecture3.pdf,CSCI_80,110,"A B
{Tue} {Wed}
{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}",50,recursive
da843e3b-8017-485b-bd99-4b2c6dfbcc80,lecture3.pdf,CSCI_80,111,"A B
{Tue} {Wed}
{A ≠ Mon, B ≠ Tue, B ≠ Mon, A ≠ B}",50,recursive
a8f8c38d-6020-49b6-85ae-5d4b496bbd75,lecture3.pdf,CSCI_80,112,"Arc Consistency
function REVISE(csp, X, Y): 
    revised = false 
    for x in X.domain: 
        if no y in Y.domain satisfies constraint for (X, Y): 
            delete x from X.domain 
            revised = true 
    return revised",234,recursive
cd6bb857-888b-4217-8929-3522955bc00c,lecture3.pdf,CSCI_80,113,"Arc Consistency
function AC-3(csp): 
    queue = all arcs in csp 
    while queue non-empty: 
        (X, Y) = DEQUEUE(queue) 
        if REVISE(csp, X, Y): 
            if size of X.domain == 0: 
                return false 
            for each Z in X.neighbors - {Y}: 
                ENQUEUE(queue, (Z, X)) 
    return true",328,recursive
7cdc6811-4ae8-4132-af90-5a8163d4871f,lecture3.pdf,CSCI_80,114,"A
B C
D
E
F
G",13,recursive
f38dca29-3dc7-4ca6-9a56-50b8c4b9d62d,lecture3.pdf,CSCI_80,115,"A
B C
D
E
F
G
{Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",125,recursive
d3b997a9-c864-471e-8ba7-423dd4c3212e,lecture3.pdf,CSCI_80,116,"Search Problems
•initial state 
•actions 
•transition model 
•goal test 
•path cost function",92,recursive
74b289f5-1e40-4010-8bf4-d633e62890a1,lecture3.pdf,CSCI_80,117,"CSPs as Search Problems
•initial state: empty assignment (no variables) 
•actions: add a {variable = value} to assignment 
•transition model: shows how adding an assignment 
changes the assignment 
•goal test: check if all variables assigned and 
constraints all satisfied 
•path cost function: all paths have same cost",319,recursive
16fe5f64-11f4-4157-bf05-8aedffb9341c,lecture3.pdf,CSCI_80,118,Backtracking Search,19,recursive
01c7b58d-65b3-4c3b-a8d8-fdc74b1572a9,lecture3.pdf,CSCI_80,119,"Backtracking Search
function BACKTRACK(assignment, csp): 
    if assignment complete: return assignment 
    var = SELECT-UNASSIGNED-VAR(assignment, csp) 
    for value in DOMAIN-VALUES(var, assignment, csp): 
        if value consistent with assignment: 
            add {var = value} to assignment 
            result = BACKTRACK(assignment, csp) 
            if result ≠ failure: return result 
        remove {var = value} from assignment 
    return failure",462,recursive
18e6df56-fab9-469f-956b-68863b41b868,lecture3.pdf,CSCI_80,120,"A
B C
D
E
F
G
{Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",125,recursive
397ce42d-5c81-496e-bfed-d8acae05af15,lecture3.pdf,CSCI_80,121,"A
B C
D
E
F
G
Mon
{Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",113,recursive
939c1a94-c4cc-4080-891e-df9045001b9a,lecture3.pdf,CSCI_80,122,"A
B C
D
E
F
G
Mon
Mon
{Mon, Tue, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",101,recursive
e93eb6fa-97a9-4614-8f44-840dcda8ecd5,lecture3.pdf,CSCI_80,123,"A
B C
D
E
F
G
Mon
Mon
{Mon, Tue, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",101,recursive
5008890e-8ece-490f-85c1-c2725e9103a9,lecture3.pdf,CSCI_80,124,"A
B C
D
E
F
G
Mon
Tue
{Mon, Tue, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",101,recursive
5046877b-fca1-40b3-b102-fc299bb098fb,lecture3.pdf,CSCI_80,125,"A
B C
D
E
F
G
Mon
Tue
Mon
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",89,recursive
85ac7020-efaf-4522-b550-4c96187bce49,lecture3.pdf,CSCI_80,126,"A
B C
D
E
F
G
Mon
Tue
Mon
Mon {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",77,recursive
c58546f4-d990-4730-bc03-5579561847ef,lecture3.pdf,CSCI_80,127,"A
B C
D
E
F
G
Mon
Tue
Mon
Mon {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",77,recursive
aaed3ab7-d453-4ffe-bd12-bdb2f6e71227,lecture3.pdf,CSCI_80,128,"A
B C
D
E
F
G
Mon
Tue
Mon
Tue {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",77,recursive
57a50d72-f479-4c3f-8172-47f9e83cd081,lecture3.pdf,CSCI_80,129,"A
B C
D
E
F
G
Mon
Tue
Mon
Tue {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",77,recursive
fb42ead0-7442-46a6-8089-c574131cfb9b,lecture3.pdf,CSCI_80,130,"A
B C
D
E
F
G
Mon
Tue
Mon
Wed {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",77,recursive
44644df0-160e-4854-a6ae-866e927afcf4,lecture3.pdf,CSCI_80,131,"A
B C
D
E
F
G
Mon
Tue
Mon
Wed {Mon, Tue, Wed}
{Mon, Tue, Wed}
Mon",65,recursive
3881b438-3b9c-44f2-a787-4b0bf8cff763,lecture3.pdf,CSCI_80,132,"A
B C
D
E
F
G
Mon
Tue
Mon
Wed {Mon, Tue, Wed}
{Mon, Tue, Wed}
Mon",65,recursive
5873a02b-f7f4-4f6d-b865-559a2bb2f989,lecture3.pdf,CSCI_80,133,"A
B C
D
E
F
G
Mon
Tue
Mon
Wed {Mon, Tue, Wed}
{Mon, Tue, Wed}
Tue",65,recursive
1912b311-084e-48b7-9bc0-879fd65789e3,lecture3.pdf,CSCI_80,134,"A
B C
D
E
F
G
Mon
Tue
Mon
Wed {Mon, Tue, Wed}
{Mon, Tue, Wed}
Tue",65,recursive
f2b3715a-abde-4533-96f9-1352a9971773,lecture3.pdf,CSCI_80,135,"A
B C
D
E
F
G
Mon
Tue
Mon
Wed {Mon, Tue, Wed}
{Mon, Tue, Wed}
Wed",65,recursive
71a27d2e-1a38-435c-ad8a-c87b26de09b5,lecture3.pdf,CSCI_80,136,"A
B C
D
E
F
G
Mon
Tue
Mon
Wed {Mon, Tue, Wed}
{Mon, Tue, Wed}
Wed",65,recursive
ec3736d3-d0ff-42cc-aebc-1a60fa94b4c9,lecture3.pdf,CSCI_80,137,"A
B C
D
E
F
G
Mon
Tue
Mon
Wed {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",77,recursive
6945fe00-c501-443b-89f4-b28ecf58dfb1,lecture3.pdf,CSCI_80,138,"A
B C
D
E
F
G
Mon
Tue
Mon
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",89,recursive
eb7a3325-c178-40e2-84fc-69f6de40e295,lecture3.pdf,CSCI_80,139,"A
B C
D
E
F
G
Mon
Tue
{Mon, Tue, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",101,recursive
31d2a39b-927f-4572-bda0-a2afd03ce979,lecture3.pdf,CSCI_80,140,"A
B C
D
E
F
G
Mon
Tue
Tue
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",89,recursive
38762c09-f981-48a5-9744-8325cb762016,lecture3.pdf,CSCI_80,141,"A
B C
D
E
F
G
Mon
Tue
Tue
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",89,recursive
9e58a850-03be-4c47-b12c-6fec9166ba9b,lecture3.pdf,CSCI_80,142,"A
B C
D
E
F
G
Mon
Tue
Wed
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",89,recursive
dce4b26f-96c5-4386-82b0-cce30864a5f0,lecture3.pdf,CSCI_80,143,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",77,recursive
29349b01-17e6-4130-be0b-200ff2103bd4,lecture3.pdf,CSCI_80,144,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon {Mon, Tue, Wed}
{Mon, Tue, Wed}
Mon",65,recursive
ec38efc6-00cb-4623-9262-37db22ed20e5,lecture3.pdf,CSCI_80,145,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon {Mon, Tue, Wed}
{Mon, Tue, Wed}
Mon",65,recursive
fd1579a6-cef2-432c-9dae-8865bbe0f709,lecture3.pdf,CSCI_80,146,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon {Mon, Tue, Wed}
{Mon, Tue, Wed}
Tue",65,recursive
442e6231-535b-4e8b-a13d-f31136814847,lecture3.pdf,CSCI_80,147,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon {Mon, Tue, Wed}
{Mon, Tue, Wed}
Tue",65,recursive
28379780-4b51-4a86-88ec-3d13dcf44917,lecture3.pdf,CSCI_80,148,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon {Mon, Tue, Wed}
{Mon, Tue, Wed}
Wed",65,recursive
7d8528c7-c5ae-48c8-841e-0f25ea7173bf,lecture3.pdf,CSCI_80,149,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon {Mon, Tue, Wed}
Mon
Wed",53,recursive
d63552b4-4d52-48fd-a8df-98e39c341e73,lecture3.pdf,CSCI_80,150,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon {Mon, Tue, Wed}
Mon
Wed",53,recursive
5f794658-df77-4e9b-8129-94c1c730753e,lecture3.pdf,CSCI_80,151,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon {Mon, Tue, Wed}
Tue
Wed",53,recursive
3b0afe7f-03e0-480e-ac99-5e405c577452,lecture3.pdf,CSCI_80,152,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon Mon
Tue
Wed",41,recursive
a6d113f4-2784-410d-9ca9-f7a37e467f35,lecture3.pdf,CSCI_80,153,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon Mon
Tue
Wed",41,recursive
b1bde241-8bd6-4097-b5ff-ab2c0e8bd9a6,lecture3.pdf,CSCI_80,154,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon Tue
Tue
Wed",41,recursive
c56224ae-f92b-436d-a565-cbb233b1f54c,lecture3.pdf,CSCI_80,155,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon Tue
Tue
Wed",41,recursive
0b2e7003-ec2c-46db-9272-ee323a4b4ab3,lecture3.pdf,CSCI_80,156,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon Wed
Tue
Wed",41,recursive
b5c08596-98f4-47fe-a5aa-d6885009631b,lecture3.pdf,CSCI_80,157,Inference,9,recursive
ad518da8-01fd-4100-aeef-be2004ddfd36,lecture3.pdf,CSCI_80,158,"A
B C
D
E
F
G
Mon
Tue
{Mon, Tue, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",101,recursive
e9518521-80b4-4413-bfb3-b9b2c260184d,lecture3.pdf,CSCI_80,159,"A
B C
D
E
F
G
Mon
Tue
Mon
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",89,recursive
db25a591-5ff2-4f54-ad8c-33c95d3e9516,lecture3.pdf,CSCI_80,160,"A
B C
D
E
F
G
Mon
Tue
Mon
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",89,recursive
c55a0669-901d-4a91-81c2-ac0517290574,lecture3.pdf,CSCI_80,161,"A
B C
D
E
F
G
Mon
Tue
{Mon, Tue, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",101,recursive
4524b164-3d43-4004-aeac-2c5c4d01a410,lecture3.pdf,CSCI_80,162,"A
B C
D
E
F
G
Mon
Tue
{Mon, Tue, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Wed}",91,recursive
4acbfc32-3a9a-4e9c-b41f-8ac911d96b03,lecture3.pdf,CSCI_80,163,"A
B C
D
E
F
G
Mon
Tue
{Mon, Tue, Wed}
{Mon} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Wed}",81,recursive
463d65e2-54d4-49a5-b913-c0f7de3c7be9,lecture3.pdf,CSCI_80,164,"A
B C
D
E
F
G
Mon
Tue
{Wed}
{Mon} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Wed}",71,recursive
12b4e808-ec21-40ee-9efb-5a1b8a02e9eb,lecture3.pdf,CSCI_80,165,"A
B C
D
E
F
G
Mon
Tue
{Wed}
{Mon} {Mon, Tue, Wed}
{Tue}
{Wed}",61,recursive
8acc7574-1cd9-46e5-bd33-7ffb10363ce8,lecture3.pdf,CSCI_80,166,"A
B C
D
E
F
G
Mon
Tue
{Wed}
{Mon} {Wed}
{Tue}
{Wed}",51,recursive
49817359-1b60-4666-93cb-a8cd3662ab8d,lecture3.pdf,CSCI_80,167,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon Wed
Tue
Wed",41,recursive
fa4415b6-f611-4703-9501-41e561aa98b0,lecture3.pdf,CSCI_80,168,"maintaining arc-consistency
algorithm for enforcing arc-consistency 
every time we make a new assignment",104,recursive
7f1fe8fa-ec39-4379-88ef-37dddeb4d41a,lecture3.pdf,CSCI_80,169,"maintaining arc-consistency
When we make a new assignment to X, calls 
AC-3, starting with a queue of all arcs (Y, X) 
where Y is a neighbor of X",145,recursive
86b5aed4-891b-4323-abcf-8c2fb5909464,lecture3.pdf,CSCI_80,170,"function BACKTRACK(assignment, csp): 
    if assignment complete: return assignment 
    var = SELECT-UNASSIGNED-VAR(assignment, csp) 
    for value in DOMAIN-VALUES(var, assignment, csp): 
        if value consistent with assignment: 
            add {var = value} to assignment 
            inferences = INFERENCE(assignment, csp) 
            if inferences ≠ failure: add inferences to assignment 
            result = BACKTRACK(assignment, csp) 
            if result ≠ failure: return result 
        remove {var = value} and inferences from assignment 
    return failure",577,recursive
43cb20ac-c9d2-4570-8032-2690ab18929b,lecture3.pdf,CSCI_80,171,"function BACKTRACK(assignment, csp): 
    if assignment complete: return assignment 
    var = SELECT-UNASSIGNED-VAR(assignment, csp) 
    for value in DOMAIN-VALUES(var, assignment, csp): 
        if value consistent with assignment: 
            add {var = value} to assignment 
            inferences = INFERENCE(assignment, csp) 
            if inferences ≠ failure: add inferences to assignment 
            result = BACKTRACK(assignment, csp) 
            if result ≠ failure: return result 
        remove {var = value} and inferences from assignment 
    return failure",577,recursive
0e3f37d0-5a93-41ef-804f-0fec9e206de1,lecture3.pdf,CSCI_80,172,"function BACKTRACK(assignment, csp): 
    if assignment complete: return assignment 
    var = SELECT-UNASSIGNED-VAR(assignment, csp) 
    for value in DOMAIN-VALUES(var, assignment, csp): 
        if value consistent with assignment: 
            add {var = value} to assignment 
            inferences = INFERENCE(assignment, csp) 
            if inferences ≠ failure: add inferences to assignment 
            result = BACKTRACK(assignment, csp) 
            if result ≠ failure: return result 
        remove {var = value} and inferences from assignment 
    return failure",577,recursive
c5cb28d0-4106-45c5-af8f-e2d90475df61,lecture3.pdf,CSCI_80,173,"SELECT-UNASSIGNED-VAR
•minimum remaining values (MRV) heuristic: select 
the variable that has the smallest domain 
•degree heuristic: select the variable that has the 
highest degree",183,recursive
0bc17c3f-c7a0-40b6-a29a-5edd7653dfdf,lecture3.pdf,CSCI_80,174,"A
B C
D
E
F
G
Mon
Tue
{Mon, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Wed}",86,recursive
1b8e0b75-0aff-4857-b3e6-1f628a532a2f,lecture3.pdf,CSCI_80,175,"A
B C
D
E
F
G
Mon
Tue
{Mon, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Wed}",86,recursive
41da37ad-8d3f-4211-b242-481bdafdbf2c,lecture3.pdf,CSCI_80,176,"A
B C
D
E
F
G
{Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",125,recursive
a743d389-9efb-4d75-aeb2-8ee1bf7bee57,lecture3.pdf,CSCI_80,177,"A
B C
D
E
F
G
{Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed} {Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed}",125,recursive
bca72b1f-3f98-4521-ad97-7fd26f28ebb4,lecture3.pdf,CSCI_80,178,"function BACKTRACK(assignment, csp): 
    if assignment complete: return assignment 
    var = SELECT-UNASSIGNED-VAR(assignment, csp) 
    for value in DOMAIN-VALUES(var, assignment, csp): 
        if value consistent with assignment: 
            add {var = value} to assignment 
            inferences = INFERENCE(assignment, csp) 
            if inferences ≠ failure: add inferences to assignment 
            result = BACKTRACK(assignment, csp) 
            if result ≠ failure: return result 
        remove {var = value} and inferences from assignment 
    return failure",577,recursive
d9cb9ed8-0c1d-4e7b-855b-3d267324b265,lecture3.pdf,CSCI_80,179,"function BACKTRACK(assignment, csp): 
    if assignment complete: return assignment 
    var = SELECT-UNASSIGNED-VAR(assignment, csp) 
    for value in DOMAIN-VALUES(var, assignment, csp): 
        if value consistent with assignment: 
            add {var = value} to assignment 
            inferences = INFERENCE(assignment, csp) 
            if inferences ≠ failure: add inferences to assignment 
            result = BACKTRACK(assignment, csp) 
            if result ≠ failure: return result 
        remove {var = value} and inferences from assignment 
    return failure",577,recursive
184f320c-7c65-45b6-a9c2-87bff17bfc60,lecture3.pdf,CSCI_80,180,"DOMAIN-VALUES
•least-constraining values heuristic: return variables in 
order by number of choices that are ruled out for 
neighboring variables 
•try least-constraining values first",183,recursive
1fb37e2d-c3d1-4560-9981-7c824a5fe21f,lecture3.pdf,CSCI_80,181,"A
B C
D
E
F
G
Mon
{Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed} Wed
{Mon, Tue}
{Tue, Wed}",91,recursive
8092a90d-4c79-4b59-97dd-3d1d0476f9bf,lecture3.pdf,CSCI_80,182,"A
B C
D
E
F
G
Mon
{Mon, Tue, Wed}
{Mon, Tue, Wed}
{Mon, Tue, Wed} Wed
{Mon, Tue}
Wed",84,recursive
9a08a98b-4963-4222-9210-c4b4f240bed0,lecture3.pdf,CSCI_80,183,"A
B C
D
E
F
G
Mon
Tue
Wed
Mon Wed
Tue
Wed",41,recursive
f7b355f0-6899-4bdc-9a12-ffc70e2efcd0,lecture3.pdf,CSCI_80,184,"Problem Formulation
Local 
Search
50x1 + 80x2
5x1 + 2x2 ≤ 20
(−10x1) + (−12x2) ≤ − 90
Linear 
Programming
Constraint 
Satisfaction
A
B C
D
E
F
G",144,recursive
7c9afb30-fd79-4e80-bec2-ac8785e4c660,lecture3.pdf,CSCI_80,185,Optimization,12,recursive
b67edcb5-e81c-4a84-bc47-1163d1ddb20e,lecture3.pdf,CSCI_80,186,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
8eefd52b-b1dd-40a6-91f0-c7dd92fcb422,Week_2.pdf,CSCI_80,0,"Week 2  1. Knowledge Humans reason based on exis/ng knowledge and draw conclusions. The concept of represen/ng knowledge and drawing conclusions from it is also used in AI, and in this lecture we will explore how we can achieve this behavior.  2. Knowledge-Based Agents These are agents that reason by opera/ng on internal representa/ons of knowledge.  What does “reasoning based on knowledge to draw a conclusion” mean?  Let’s start answering this with a Harry PoGer example. Consider the following sentences:  If it didn’t rain, Harry visited Hagrid today. Harry visited Hagrid or Dumbledore today, but not both. Harry visited Dumbledore today. Based on these three sentences, we can answer the ques/on “did it rain today?”, even though none of the individual sentences tells us anything about whether it is raining today. Here is how we can go about it: looking at sentence 3, we know that Harry visited Dumbledore",917,recursive
1f2a9798-80c0-4f3b-a95a-9dfb852a660e,Week_2.pdf,CSCI_80,0,". Here is how we can go about it: looking at sentence 3, we know that Harry visited Dumbledore. Looking at sentence 2, we know that Harry visited either Dumbledore or Hagrid, and thus we can conclude  Harry did not visit Hagrid. Now, looking at sentence 1, we understand that if it didn’t rain, Harry would have visited Hagrid. However, knowing sentence 4, we know that this is not the case. Therefore, we can conclude  It rained today. To come to this conclusion, we used logic, and today’s lecture explores how AI can use logic to reach to new conclusions based on exis/ng informa/on.  3. Sentence A sentence is an asser/on about the world in a knowledge representa/on language. A sentence is how AI stores knowledge and uses it to infer new informa/on.  4. Proposi;onal Logic Proposi/onal logic is based on proposi/ons, statements about the world that can be either true or false, as in sentences 1-5 above.  5",913,recursive
d8a8a120-daa4-4350-a159-9883ffe6796e,Week_2.pdf,CSCI_80,0,".  4. Proposi;onal Logic Proposi/onal logic is based on proposi/ons, statements about the world that can be either true or false, as in sentences 1-5 above.  5. Proposi/onal Symbols Proposi/onal symbols are most oUen leGers (P , Q, R) that are used to represent a proposi/on.",275,recursive
48ce206b-1a05-4496-b986-ede8f858b798,Week_2.pdf,CSCI_80,1,"6. Logical Connec;ves Logical connec/ves are logical symbols that connect proposi/onal symbols in order to reason in a more complex way about the world.  a. NOT Not (¬) inverses the truth value of the proposi/on. So, for example, if P: “It is raining,” then ¬P: “It is not raining”.  Truth tables are used to compare all possible truth assignments to proposi/ons. This tool will help us beGer understand the truth values of proposi/ons when connected with diﬀerent logical connec/ves. For example, below is our ﬁrst truth table:  P         ¬P false True true False  b. AND  And (∧) connects two diﬀerent proposi/ons. When these two proposi/on, P and Q, are connected by ∧, the resul/ng proposi/on P ∧ Q is true only in the case that both P and Q are true.  P             Q        P ∧ Q false false false false true false true false false true true true  c. OR  Or (∨) is true as as long as either of its arguments is true. This means that for P ∨ Q to be true, at least one of P or Q has to be true",998,recursive
0ce2f5d5-7994-4032-9142-95593f18bdb3,Week_2.pdf,CSCI_80,1,". OR  Or (∨) is true as as long as either of its arguments is true. This means that for P ∨ Q to be true, at least one of P or Q has to be true.  P            Q         P ∨ Q false false false false true true true false true true true true  It is worthwhile to men/on that there are two types of Or: an inclusive Or and an exclusive Or. In an exclusive Or, P ∨ Q is false if P ∧ Q is true. That is, an exclusive Or requires only one of its arguments to be true and not both. An inclusive Or is true if any of P , Q, or P ∧ Q is true. In the case of Or (∨), the inten/on is an inclusive Or.",589,recursive
01f2b6fb-42a4-4af5-9352-1c9928ab5373,Week_2.pdf,CSCI_80,2,"A couple of side notes not men/oned in lecture:  Some/mes an example helps understand inclusive versus exclusive Or. Inclusive Or: “in order to eat dessert, you have to clean your room or mow the lawn.” In this case, if you do both chores, you will s/ll get the cookies. Exclusive Or: “For dessert, you can have either cookies or ice cream.” In this case, you can’t have both. If you are curious, the exclusive Or is oUen shortened to XOR and a common symbol for it is ⊕).  d. Implica2on  Implica/on (→) represents a structure of “if P then Q.” For example, if P: “It is raining” and Q: “I’m indoors”, then P → Q means “If it is raining, then I’m indoors.” In the case of P implies Q (P → Q), P is called the antecedent and Q is called the consequent.  When the antecedent is true, the whole implica/on is true in the case that the consequent is true (that makes sense: if it is raining and I’m indoors, then the sentence “if it is raining, then I’m indoors” is true)",967,recursive
76a58eab-b4d6-4ba1-b056-cdfddd80e6f5,Week_2.pdf,CSCI_80,2,". When the antecedent is true, the implica/on is false if the consequent is false (if I’m outside while it is raining, then the sentence “If it is raining, then I’m indoors” is false). However, when the antecedent is false, the implica/on is always true, regardless of the consequent. This can some/mes be a confusing concept. Logically, we can’t learn anything from an implica/on (P → Q) if the antecedent (P) is false. Looking at our example, if it is not raining, the implica/on doesn’t say anything about whether I’m indoors or not. I could be an indoors type and never walk outside, even when it is not raining, or I could be an outdoors type and be outside all the /me when it is not raining. When the antecedent is false, we say that the implica/on is trivially true.  P            Q.       P → Q false false true false true true true false false true true true  e. Bicondi2onal  Bicondi/onal (↔) is an implica/on that goes both direc/ons",945,recursive
672be1be-a904-4aa0-a530-76894777f903,Week_2.pdf,CSCI_80,2,".  P            Q.       P → Q false false true false true true true false false true true true  e. Bicondi2onal  Bicondi/onal (↔) is an implica/on that goes both direc/ons. You can read it as “if and only if.” P ↔ Q is the same as P → Q and Q → P taken together. For example, if P: “It is raining.” and Q: “I’m indoors,” then P ↔ Q means that “If it is raining, then I’m indoors,” and “if I’m indoors, then it is raining.” This means that we can infer more than we could with a simple implica/on. If P is false, then Q is also false; if it is not raining, we know that I’m also not indoors.  (P implies Q) and (Q implies P)",624,recursive
d5e5e948-51a4-4730-a40a-720ee785749f,Week_2.pdf,CSCI_80,3,"P            Q       P ↔ Q false false true false true false true false false true true true   f. NAND Not and. Not (P and Q).  P            Q.       P and Q     Not false false false        True false true false.       True true false false.        True true true true.         False    7. Model The model is an assignment of a truth value to every proposi/on. To reiterate, proposi/ons are statements about the world that can be either true or false. However, knowledge about the world is represented in the truth values of these proposi/ons. The model is the truth-value assignment that provides informa/on about the world.  For example, if P: “It is raining.” and Q: “It is Tuesday.”, a model could be the following truth-value assignment: {P = True, Q = False}. This model means that it is raining, but it is not Tuesday. However, there are more possible models in this situa/on (for example, {P = True, Q = True}, where it is both raining an a Tuesday)",958,recursive
f0fce8c0-0467-44f9-bebc-087e4f664d5d,Week_2.pdf,CSCI_80,3,". This model means that it is raining, but it is not Tuesday. However, there are more possible models in this situa/on (for example, {P = True, Q = True}, where it is both raining an a Tuesday). In fact, the number of possible models is 2 to the power of the number of proposi/ons. In this case, we had 2 proposi/ons, so 2²=4 possible models.  8. Knowledge Base (KB) The knowledge base is a set of sentences known by a knowledge-based agent. This is knowledge that the AI is provided about the world in the form of proposi/onal logic sentences that can be used to make addi/onal inferences about the world.  9. Entailment (⊨)  If α ⊨ β (α entails β), then in any world where α is true, β is true, too.  For example, if α: “It is a Tuesday in January” and β: “It is January,” then we know that α ⊨ β. If it is true that it is a Tuesday in January, we also know that it is January. Entailment is diﬀerent from implica/on. Implica/on is a logical connec/ve between two proposi/ons. Entailment, on",993,recursive
5cd3bf8b-61b0-41d0-a9eb-db3ecd35f23b,Week_2.pdf,CSCI_80,4,"the other hand, is a rela/on that means that if all the informa/on in α is true, then all the informa/on in β is true.  10. Inference Inference is the process of deriving new sentences from old ones.  For instance, in the Harry PoGer example earlier, sentences 4 and 5 were inferred from sentences 1, 2, and 3.  There are mul/ple ways to infer new knowledge based on exis/ng knowledge. First, we will consider the Model Checking algorithm.  To determine if KB ⊨ α (in other words, answering the ques/on: “can we conclude that α is true based on our knowledge base”) Enumerate all possible models. If in every model where KB is true, α is true as well, then KB entails α (KB ⊨ α). Consider the following example:  P: It is a Tuesday. Q: It is raining. R: Harry will go for a run",777,recursive
fe346905-0fae-4b06-b5db-e797c90a8d94,Week_2.pdf,CSCI_80,4,". If in every model where KB is true, α is true as well, then KB entails α (KB ⊨ α). Consider the following example:  P: It is a Tuesday. Q: It is raining. R: Harry will go for a run. KB: (P ∧ ¬Q) → R (in words, P and not Q imply R) P (P is true) ¬Q (Q is false) Query: R (We want to know whether R is true or false; Does KB ⊨ R?)  To answer the query using the Model Checking algorithm, we enumerate all possible models.  P.            Q.        R              KB false false false   false false true   false true false   false true true   true false false   true false true   true true false   true true true   Then, we go through every model and check whether it is true given our Knowledge Base.  First, in our KB, we know that P is true. Thus, we can say that the KB is false in all models where P is not true.  P             Q          R          KB false false false false false false true false false true false false false true true false true false false",964,recursive
fbb62ccc-966d-458d-96e9-f1d7610ae3a2,Week_2.pdf,CSCI_80,5,"true false true   true true false   true true true    Next, similarly, in our KB, we know that Q is false. Thus, we can say that the KB is false in all models where Q is true.  P             Q         R           KB false false false false false false true false false true false false false true true false true false false   true false true   true true false false true true true false Finally, we are leU with two models. In both, P is true and Q is false. In one model R is true and in the other R is false. Due to (P ∧ ¬Q) → R being in our KB, we know that in the case where P is true and Q is false, R must be true. Thus, we say that our KB is false for the model where R is false, and true for the model where R is true",726,recursive
dbad5579-1580-42f4-a691-c05c8dda044c,Week_2.pdf,CSCI_80,5,". Thus, we say that our KB is false for the model where R is false, and true for the model where R is true.  P            Q          R         KB false false false false false false true false false true false false false true true false true false false false true false true true true true false false true true true false  Looking at this table, there is only one model where our knowledge base is true. In this model, we see that R is also true. By our deﬁni/on of entailment, if R is true in all models where the KB is true, then KB ⊨ R.  a. Example: Harry Po?er  Next, let’s look at how knowledge and logic can be represented as code.  from logic import *  # Create new classes, each having a name, or a symbol, represen/ng each proposi/on. rain = Symbol(""rain"")  # It is raining. hagrid = Symbol(""hagrid"")  # Harry visited Hagrid",836,recursive
941735f5-15e0-4f1f-a957-7a39afdce777,Week_2.pdf,CSCI_80,6,"dumbledore = Symbol(""dumbledore"")  # Harry visited Dumbledore  # Save sentences into the KB knowledge = And(  # Star/ng from the ""And"" logical connec/ve, becasue each proposi/on represents knowledge that we know to be true.      Implica/on(Not(rain), hagrid),  # ¬(It is raining) → (Harry visited Hagrid)      Or(hagrid, dumbledore),  # (Harry visited Hagrid) ∨ (Harry visited Dumbledore).      Not(And(hagrid, dumbledore)),  # ¬(Harry visited Hagrid ∧ Harry visited Dumbledore) i.e. Harry did not visit both Hagrid and Dumbledore.      dumbledore  # Harry visited Dumbledore. Note that while previous proposi/ons contained mul/ple symbols with connectors, this is a proposi/on consis/ng of one symbol. This means that we take as a fact that, in this KB, Harry visited Dumbledore",779,recursive
92e4eec1-234a-48b0-b827-9d29b3d9fcc5,Week_2.pdf,CSCI_80,6,". This means that we take as a fact that, in this KB, Harry visited Dumbledore.     ) To run the Model Checking algorithm, the following informa/on is needed:  Knowledge Base, which will be used to draw inferences A query, or the proposi/on that we are interested in whether it is entailed by the KB Symbols, a list of all the symbols (or atomic proposi/ons) used (in our case, these are rain, hagrid, and dumbledore) Model, an assignment of truth and false values to symbols The model checking algorithm looks as follows:  def check_all(knowledge, query, symbols, model):      # If model has an assignment for each symbol     # (The logic below might be a liGle confusing: we start with a list of symbols. The func/on is recursive, and every /me it calls itself it pops one symbol from the symbols list and generates models from it",832,recursive
6ffa6626-22ac-42d6-9610-44ca0ea3e60e,Week_2.pdf,CSCI_80,6,". The func/on is recursive, and every /me it calls itself it pops one symbol from the symbols list and generates models from it. Thus, when the symbols list is empty, we know that we ﬁnished genera/ng models with every possible truth assignment of symbols.)     if not symbols:          # If knowledge base is true in model, then query must also be true         if knowledge.evaluate(model):             return query.evaluate(model)         return True     else:          # Choose one of the remaining unused symbols         remaining = symbols.copy()         p = remaining.pop()",579,recursive
a3cd4035-1910-4cae-b901-797acef5ca0a,Week_2.pdf,CSCI_80,7,"# Create a model where the symbol is true         model_true = model.copy()         model_true[p] = True          # Create a model where the symbol is false         model_false = model.copy()         model_false[p] = False          # Ensure entailment holds in both models         return(check_all(knowledge, query, remaining, model_true) and check_all(knowledge, query, remaining, model_false)) Note that we are interested only in the models where the KB is true. If the KB is false, then the condi/ons that we know to be true are not occurring in these models, making them irrelevant to our case.  An example from outside lecture: Let P: Harry plays seeker, Q: Oliver plays keeper, R: Gryﬃndor wins. Our KB speciﬁes that P Q (P ∧ Q) → R. In other words, we know that P is true, i.e. Harry plays seeker, and that Q is true, i.e. Oliver plays keeper, and that if both P and Q are true, then R is true, too, meaning that Gryﬃndor wins the match",943,recursive
68ccba04-d089-4c71-9a89-f193cb31e46b,Week_2.pdf,CSCI_80,7,". Harry plays seeker, and that Q is true, i.e. Oliver plays keeper, and that if both P and Q are true, then R is true, too, meaning that Gryﬃndor wins the match. Now imagine a model where Harry played beater instead of seeker (thus, Harry did not play seeker, ¬P). Well, in this case, we don’t care whether Gryﬃndor won (whether R is true or not), because we have the informa/on in our KB that Harry played seeker and not beater. We are only interested in the models where, as in our case, P and Q are true.)  Further, the way the check_all func/on works is recursive. That is, it picks one symbol, creates two models, in one of which the symbol is true and in the other the symbol is false, and then calls itself again, now with two models that diﬀer by the truth assignment of this symbol. The func/on will keep doing so un/l all symbols will have been assigned truth-values in the models, leaving the list symbols empty",922,recursive
5eedefa3-ce5d-41cb-a045-f250b58512cd,Week_2.pdf,CSCI_80,7,". The func/on will keep doing so un/l all symbols will have been assigned truth-values in the models, leaving the list symbols empty. Once it is empty (as iden/ﬁed by the line if not symbols), in each instance of the func/on (wherein each instance holds a diﬀerent model), the func/on checks whether the KB is true given the model. If the KB is true in this model, the func/on checks whether the query is true, as described earlier.  Knowledge Engineering Knowledge engineering is the process of ﬁguring out how to represent proposi/ons and logic in AI.  b. Example: Clue  Let’s prac/ce knowledge engineering using the game Clue.  In the game, a murder was commiGed by a person, using a tool in a loca/on. People, tools, and loca/ons are represented by cards. One card of each category is picked at random and put in an",819,recursive
a64779d9-1a89-4d07-8b60-c1aef4da1bab,Week_2.pdf,CSCI_80,8,"envelope, and it is up to the par/cipants to uncover whodunnit. Par/cipants do so by uncovering cards and deducing from these clues what must be in the envelope. We will use the Model Checking algorithm from before to uncover the mystery. In our model, we mark as True items that we know are related to the murder and False otherwise.  For our purposes, suppose we have three people: Mustard, Plum, and Scarlet, three tools: knife, revolver, and wrench, and three loca/ons: ballroom, kitchen, and library.  We can start crea/ng our knowledge base by adding the rules of the game. We know for certain that one person is the murderer, that one tool was used, and that the murder happened in one loca/on. This can be represented in proposi/onal logic the following way:  (Mustard ∨ Plum ∨ Scarlet)  (knife ∨ revolver ∨ wrench)  (ballroom ∨ kitchen ∨ library)  The game starts with each player seeing one person, one tool, and one loca/on, thus knowing that they are not related to the murder",988,recursive
0a441f12-c1e1-44d0-8859-7a3a30467e07,Week_2.pdf,CSCI_80,8,". Players do not share the informa/on that the saw in these cards. Suppose our player gets the cards of Mustard, kitchen, and revolver. Thus, we know that these are not related to the murder and we can add to our KB  ¬(Mustard)  ¬(kitchen)  ¬(revolver)  In other situa/ons in the game, one can make a guess, sugges/ng one combina/on of person, tool and loca/on. Suppose that the guess is that Scarlet used a wrench to commit the crime in the library. If this guess is wrong, then the following can be deduced and added to the KB:  (¬Scarlet ∨ ¬library ∨ ¬wrench)  Now, suppose someone shows us the Plum card. Thus, we can add  ¬(Plum)  to our KB.  At this point, we can conclude that the murderer is Scarlet, since it has to be one of Mustard, Plum, and Scarlet, and we have evidence that the ﬁrst two are not it.",813,recursive
ea1694f6-b38a-4c17-9b95-227b53e954b7,Week_2.pdf,CSCI_80,9,"Adding just one more piece of knowledge, for example, that it is not the ballroom, can give us more informa/on. First, we update our KB  ¬(ballroom)  And now, using mul/ple previous pieces of data, we can deduce that Scarlet commiGed the murder with a knife in the library. We can deduce that it’s the library because it has to be either the ballroom, the kitchen, or the library, and the ﬁrst two were proven to not be the loca/ons. However, when someone guessed Scarlet, library, wrench, the guess was false. Thus, at least one of the elements in this statement has to be false. Since we know both Scarlet and library to be true, we know that the wrench is the false part here. Since one of the three instruments has to be true, and it’s not the wrench nor the revolver, we can conclude that it is the knife",809,recursive
32179d71-9e01-4dad-b6d1-fa4798ed5e47,Week_2.pdf,CSCI_80,9,". Since one of the three instruments has to be true, and it’s not the wrench nor the revolver, we can conclude that it is the knife.  Here is how the informa/on would be added to the knowledge base in Python:  # Add the clues to the KB knowledge = And(      # Start with the game condi/ons: one item in each of the three categories has to be true.     Or(mustard, plum, scarlet),     Or(ballroom, kitchen, library),     Or(knife, revolver, wrench),      # Add the informa/on from the three ini/al cards we saw     Not(mustard),     Not(kitchen),     Not(revolver),      # Add the guess someone made that it is Scarlet, who used a wrench in the library     Or(Not(scarlet), Not(library), Not(wrench)),      # Add the cards that we were exposed to     Not(plum),     Not(ballroom) )   c. Example: Logic Puzzle  We can look at other logic puzzles as well",851,recursive
0be90840-5a5b-43f6-9c13-36eb2d0dfe70,Week_2.pdf,CSCI_80,9,". Example: Logic Puzzle  We can look at other logic puzzles as well. Consider the following example: four diﬀerent people, Gilderoy, Pomona, Minerva, and Horace, are assigned to four diﬀerent houses, Gryﬃndor, Huﬄepuﬀ, Ravenclaw, and Slytherin. There is exactly one person in each house. Represen/ng the puzzle’s condi/ons in proposi/onal logic is quite cumbersome. First, each of the possible assignments will have to be a proposi/on in itself: MinervaGryﬃndor,",462,recursive
77867ecd-94d0-4ea5-a0d7-3cc3ae26ce40,Week_2.pdf,CSCI_80,10,"MinervaHuﬄepuﬀ, MinervaRavenclaw, MinervaSlytherin, PomonaGryﬃndor… Second, to represent that each person belongs to a house, an Or statement is required with all the possible house assignments per person  (MinervaGryﬃndor ∨ MinervaHuﬄepuﬀ ∨ MinervaRavenclaw ∨ MinervaSlytherin), repeat for every person.  Then, to encode that if one person is assigned to one house, they are not assigned to the other houses, we will write  (MinervaGryﬃndor → ¬MinervaHuﬄepuﬀ) ∧ (MinervaGryﬃndor → ¬MinervaRavenclaw) ∧ (MinervaGryﬃndor → ¬MinervaSlytherin) ∧ (MinervaHuﬄepuﬀ → ¬MinervaGryﬃndor)…  and so on for all houses and all people. A solu/on to this ineﬃciency is oﬀered in the sec/on on ﬁrst order logic. However, this type of riddle can s/ll be solved with either type of logic, given enough cues.  Another type of puzzle that can be solved using proposi/onal logic is a Mastermind game. In this game, player one arranges colors in a certain order, and then player two has to guess this order",984,recursive
dcaa0573-5a5d-4a06-867c-d83adf3e36f6,Week_2.pdf,CSCI_80,10,".  Another type of puzzle that can be solved using proposi/onal logic is a Mastermind game. In this game, player one arranges colors in a certain order, and then player two has to guess this order. Each turn, player two makes a guess, and player one gives back a number, indica/ng how many colors player two got right. Let’s simulate a game with four colors. Suppose player two suggests the following ordering:  d. Example: Mastermind Player one answers “two.” Thus we know that some two of the colors are in the correct posi/on, and the other two are in the wrong place. Based on this informa/on, player two tries to switch the loca/ons of two colors.  Mastermind2  Now player one answers “zero.” Thus, player two knows that the switched colors were in the right loca/on ini/ally, which means the untouched two colors were in the wrong loca/on. Player two switches them.  Mastermind3  Player one says “four” and the game is over",929,recursive
62d66d0b-36ea-4804-806a-5974e6afd21c,Week_2.pdf,CSCI_80,10,". Player two switches them.  Mastermind3  Player one says “four” and the game is over.  Represen/ng this in proposi/onal logic would require us to have (number of colors)² atomic proposi/ons. So, in the case of four colors, we would have the proposi/ons red0, red1, red2, red3, blue0… standing for color and posi/on. The next step would be represen/ng the rules of the game in proposi/onal logic (that there is only one color in each posi/on and no colors repeat) and adding them to the KB. The ﬁnal step would be adding all the cues that we have to the KB. In our case, we would add that, in the ﬁrst guess, two posi/ons were wrong and two",640,recursive
2d50ef09-6847-4f19-b8dd-5a53c4730b5b,Week_2.pdf,CSCI_80,11,"were right, and in the second guess, none was right. Using this knowledge, a Model Checking algorithm can give us the solu/on to the puzzle.  11. Inference Rules Model Checking is not an eﬃcient algorithm because it has to consider every possible model before giving the answer (a reminder: a query R is true if under all the models (truth assignments) where the KB is true, R is true as well). Inference rules allow us to generate new informa/on based on exis/ng knowledge without considering every possible model.  Inference rules are usually represented using a horizontal bar that separates the top part, the premise, from the boGom part, the conclusion. The premise is whatever knowledge we have, and the conclusion is what knowledge can be generated based on the premise.  a. Modus Ponens Example  In this example, our premise consists of the following proposi/ons:  If it is raining, then Harry is inside. It is raining. Based on this, most reasonable humans can conclude that  Harry is inside",1000,recursive
231a0728-2701-4629-9a70-024ace8e96b6,Week_2.pdf,CSCI_80,11,". It is raining. Based on this, most reasonable humans can conclude that  Harry is inside. Modus Ponens  The type of inference rule we use in this example is Modus Ponens, which is a fancy way of saying that if we know an implica/on and its antecedent to be true, then the consequent is true as well.  Modus Ponens  b. Elimina2on  If an And proposi/on is true, then any one atomic proposi/on within it is true as well. For example, if we know that Harry is friends with Ron and Hermione, we can conclude that Harry is friends with Hermione.  And Elimina/on  c. Double Nega2on Elimina2on  A proposi/on that is negated twice is true. For example, consider the proposi/on “It is not true that Harry did not pass the test”. We can parse it the following way: “It is not true that (Harry did not pass the test)”, or “¬(Harry did not pass the test)”, and, ﬁnally “¬(¬(Harry passed the",878,recursive
01fdb995-24bc-46a1-b320-fb692209043e,Week_2.pdf,CSCI_80,12,"test)).” The two nega/ons cancel each other, marking the proposi/on “Harry passed the test” as true.  Double Nega/on Elimina/on  d. Implica2on Elimina2on  An implica/on is equivalent to an Or rela/on between the negated antecedent and the consequent. As an example, the proposi/on “If it is raining, Harry is inside” is equivalent to the proposi/on “(it is not raining) or (Harry is inside).”  Implica/on Elimina/on  This one can be a liGle confusing. However, consider the following truth table:   P            Q         P → Q  ¬P ∨ Q false false true true false true true true true false false false true true true true Since P → Q and ¬P ∨ Q have the same truth-value assignment, we know them to be equivalent logically. Another way to think about this is that an implica/on is true if either of two possible condi/ons is met: ﬁrst, if the antecedent is false, the implica/on is trivially true (as discussed earlier, in the sec/on on implica/on)",948,recursive
1ca71fd5-5535-494a-a7ce-b65145b5fcff,Week_2.pdf,CSCI_80,12,". This is represented by the negated antecedent P in ¬P ∨ Q, meaning that the proposi/on is always true if P is false. Second, the implica/on is true when the antecedent is true only when the consequent is true as well. That is, if P and Q are both true, then ¬P ∨ Q is true. However, if P is true and Q is not, then ¬P ∨ Q is false.  e. Bicondi2onal Elimina2on  A bicondi/onal proposi/on is equivalent to an implica/on and its inverse with an And connec/ve. For example, “It is raining if and only if Harry is inside” is equivalent to (“If it is raining, Harry is inside” And “If Harry is inside, it is raining”).  Bicondi/onal Elimina/on  12. De Morgan’s Law  It is possible to turn an And connec/ve into an Or connec/ve. Consider the following proposi/on: “It is not true that both Harry and Ron passed the test.” From this, it is possible to conclude that “It is not true that Harry passed the test” Or “It is not true that Ron passed the",942,recursive
605b1d0c-df1e-4095-9951-2f0a479ae30e,Week_2.pdf,CSCI_80,13,"test.” That is, for the And proposi/on earlier to be true, at least one of the proposi/ons in the Or proposi/ons must be true.  De Morgan's 1  Similarly, it is possible to conclude the reverse. Consider the proposi/on “It is not true that Harry or Ron passed the test.” This can be rephrased as “Harry did not pass the test” And “Ron did not pass the test.”  De Morgan's 2  Distribu/ve Property  A proposi/on with two elements that are grouped with And or Or connec/ves can be distributed, or broken down into, smaller units consis/ng of And and Or.  Not(a and b) = not a or not b Not (a or b) = not a and not b (a and (b or c)) = (a and b) or (a and c) (a or (b and c)) = (a or b) and (a or c)  13. Knowledge and Search Problems  Inference can be viewed as a search problem with the following proper/es:  i. Ini/al state: star/ng knowledge base ii. Ac/ons: inference rules iii. Transi/on model: new knowledge base aUer inference iv",932,recursive
d0852800-1e33-44e9-b25c-73f30281430c,Week_2.pdf,CSCI_80,13,". Ini/al state: star/ng knowledge base ii. Ac/ons: inference rules iii. Transi/on model: new knowledge base aUer inference iv. Goal test: checking whether the statement that we are trying to prove is in the KB v. Path cost func/on: the number of steps in the proof  This shows just how versa/le search algorithms are, allowing us to derive new informa/on based on exis/ng knowledge using inference rules.  14. Resolu;on Resolu/on is a powerful inference rule that states that if one of two atomic proposi/ons in an Or proposi/on is false, the other has to be true. For example, given the proposi/on “Ron is in the Great Hall” Or “Hermione is in the library”, in addi/on to the proposi/on “Ron is not in the Great Hall,” we can conclude that “Hermione is in the library.” More formally, we can deﬁne resolu/on the following way: P or Q, not P , then Q  Resolu/on",861,recursive
75a3e1a3-cd0a-473e-a1c0-5f74cf29aa01,Week_2.pdf,CSCI_80,14,"Resolu/on relies on Complementary Literals, two of the same atomic proposi/ons where one is negated and the other is not, such as P and ¬P .  Resolu/on can be further generalized. Suppose that in addi/on to the proposi/on “Ron is in the Great Hall” Or “Hermione is in the library”, we also know that “Ron is not in the Great Hall” Or “Harry is sleeping.” We can infer from this, using resolu/on, that “Hermione is in the library” Or “Harry is sleeping.” To put it in formal terms:  Resolu/on  Complementary literals allow us to generate new sentences through inferences by resolu/on. Thus, inference algorithms locate complementary literals to generate new knowledge.  A Clause is a disjunc/on of literals (a proposi/onal symbol or a nega/on of a proposi/onal symbol, such as P , ¬P). A disjunc/on consists of proposi/ons that are connected with an Or logical connec/ve (P ∨ Q ∨ R). A conjunc/on, on the other hand, consists of proposi/ons that are connected with an And logical connec/ve (P ∧ Q ∧ R)",1000,recursive
23ca4ed5-268c-41e5-b0f0-6e268969c6fe,Week_2.pdf,CSCI_80,14,". A conjunc/on, on the other hand, consists of proposi/ons that are connected with an And logical connec/ve (P ∧ Q ∧ R). Clauses allow us to convert any logical statement into a Conjunc/ve Normal Form (CNF), which is a conjunc/on of clauses, for example: (A ∨ B ∨ C) ∧ (D ∨ ¬E) ∧ (F ∨ G).  Steps in Conversion of Proposi/ons to Conjunc/ve Normal Form  i. Eliminate bicondi/onals Turn (α ↔ β) into (α → β) ∧ (β → α).  ii. Eliminate implica/ons Turn (α → β) into ¬α ∨ β.  iii. Move nega/on inwards un/l only literals are being negated (and not clauses), using De Morgan’s Laws. Turn ¬(α ∧ β) into ¬α ∨ ¬β   Here’s an example of conver/ng (P ∨ Q) → R to Conjunc/ve Normal Form:  (P ∨ Q) → R ¬(P ∨ Q) ∨ R /Eliminate implica/on (¬P ∧ ¬Q) ∨ R /De Morgan’s Law (¬P ∨ R) ∧ (¬Q ∨ R) /Distribu/ve Law  At this point, we can run an inference algorithm on the conjunc/ve normal form",870,recursive
37f7bbcb-1052-46d2-8096-bc4c7626b2b8,Week_2.pdf,CSCI_80,14,". Occasionally, through the process of inference by resolu/on, we might end up in cases where a clause contains the same literal twice. In these cases, a process called factoring is used, where the",197,recursive
ce7c73e7-7186-4069-8b4a-93bed0d1b438,Week_2.pdf,CSCI_80,15,"duplicate literal is removed. For example, (P ∨ Q ∨ S) ∧ (¬P ∨ R ∨ S) allow us to infer by resolu/on that (Q ∨ S ∨ R ∨ S). The duplicate S can be removed to give us (Q ∨ R ∨ S).  Resolving a literal and its nega/on, i.e. ¬P and P , gives the empty clause (). The empty clause is always false, and this makes sense because it is impossible that both P and ¬P are true. This fact is used by the resolu/on algorithm.  To determine if KB ⊨ α: Check: is (KB ∧ ¬α) a contradic/on? If so, then KB ⊨ α. Otherwise, no entailment. Proof by contradic/on is a tool used oUen in computer science. If our knowledge base is true, and it contradicts ¬α, it means that ¬α is false, and, therefore, α must be true. More technically, the algorithm would perform the following ac/ons:  To determine if KB ⊨ α: Convert (KB ∧ ¬α) to Conjunc/ve Normal Form. Keep checking to see if we can use resolu/on to produce a new clause",903,recursive
6fb1b04d-0a2d-4e73-b774-b5edb1644b02,Week_2.pdf,CSCI_80,15,". Keep checking to see if we can use resolu/on to produce a new clause. If we ever produce the empty clause (equivalent to False), congratula/ons! We have arrived at a contradic/on, thus proving that KB ⊨ α. However, if contradic/on is not achieved and no more clauses can be inferred, there is no entailment. Here is an example that illustrates how this algorithm might work:  Does (A ∨ B) ∧ (¬B ∨ C) ∧ (¬C) entail A? First, to prove by contradic/on, we assume that A is false. Thus, we arrive at (A ∨ B) ∧ (¬B ∨ C) ∧ (¬C) ∧ (¬A). Now, we can start genera/ng new informa/on. Since we know that C is false (¬C), the only way (¬B ∨ C) can be true is if B is false, too. Thus, we can add (¬B) to our KB. Next, since we know (¬B), the only way (A ∨ B) can be true is if A is true. Thus, we can add (A) to our KB. Now our KB has two complementary literals, (A) and (¬A). We resolve them, arriving at the empty set, (). The empty set is false by deﬁni/on, so we have arrived at a contradic/on.  15",992,recursive
f630027a-4bb0-4ef4-8249-3f78818506da,Week_2.pdf,CSCI_80,15,". Now our KB has two complementary literals, (A) and (¬A). We resolve them, arriving at the empty set, (). The empty set is false by deﬁni/on, so we have arrived at a contradic/on.  15. First Order Logic First order logic is another type of logic that allows us to express more complex ideas more succinctly than proposi/onal logic. First order logic uses two types of symbols: Constant Symbols and Predicate Symbols. Constant symbols represent objects, while predicate symbols are like rela/ons or func/ons that take an argument and return a true or false value.  For example, we return to the logic puzzle with diﬀerent people and house assignments at Hogwarts. The constant symbols are people or houses, like Minerva, Pomona, Gryﬃndor, Huﬄepuﬀ, etc. The predicate symbols are proper/es that hold true or false of some constant symbols. For example, we can express the idea that Minerva is a person using the sentence",919,recursive
de08f3c9-b60e-4594-a1c4-e4d7103ea8fc,Week_2.pdf,CSCI_80,16,"Person(Minerva). Similarly, we can express the idea the Gryﬃndor is a house using the sentence House(Gryﬃndor). All the logical connec/ves work in ﬁrst order logic the same way as before. For example, ¬House(Minerva) expresses the idea that Minerva is not a house. A predicate symbol can also take two or more arguments and express a rela/on between them. For example, BelongsTo expresses a rela/on between two arguments, the person and the house to which the person belongs. Thus, the idea that Minerva belongs to Gryﬃndor can be expressed as BelongsTo(Minerva, Gryﬃndor). First order logic allows having one symbol for each person and one symbol for each house. This is more succinct than proposi/onal logic, where each person—house assignment would require a diﬀerent symbol.  Universal Quan/ﬁca/on  Quan/ﬁca/on is a tool that can be used in ﬁrst order logic to represent sentences without using a speciﬁc constant symbol",924,recursive
4ede8992-200a-4b78-86e8-f33fdc971c59,Week_2.pdf,CSCI_80,16,".  Universal Quan/ﬁca/on  Quan/ﬁca/on is a tool that can be used in ﬁrst order logic to represent sentences without using a speciﬁc constant symbol. Universal quan/ﬁca/on uses the symbol ∀ to express “for all.” So, for example, the sentence ∀x. BelongsTo(x, Gryﬃndor) → ¬BelongsTo(x, Huﬄepuﬀ) expresses the idea that it is true for every symbol that if this symbol belongs to Gryﬃndor, it does not belong to Huﬄepuﬀ.  Existen/al Quan/ﬁca/on  Existen/al quan/ﬁca/on is an idea parallel to universal quan/ﬁca/on. However, while universal quan/ﬁca/on was used to create sentences that are true for all x, existen/al quan/ﬁca/on is used to create sentences that are true for at least one x. It is expressed using the symbol ∃. For example, the sentence ∃x. House(x) ∧ BelongsTo(Minerva, x) means that there is at least one symbol that is both a house and that Minerva belongs to it. In other words, this expresses the idea that Minerva belongs to a house",950,recursive
0e489b9a-9bd9-4acd-b1e2-e171e368b3e0,Week_2.pdf,CSCI_80,16,". House(x) ∧ BelongsTo(Minerva, x) means that there is at least one symbol that is both a house and that Minerva belongs to it. In other words, this expresses the idea that Minerva belongs to a house.  Existen/al and universal quan/ﬁca/on can be used in the same sentence. For example, the sentence ∀x. Person(x) → (∃y. House(y) ∧ BelongsTo(x, y)) expresses the idea that if x is a person, then there is at least one house, y, to which this person belongs. In other words, this sentence means that every person belongs to a house.  There are other types of logic as well, and the commonality between them is that they all exist in pursuit of represen/ng informa/on. These are the systems we use to represent knowledge in our AI.",728,recursive
9d96423f-03cb-4017-96dc-fb0d4d321e27,lecture1.pdf,CSCI_80,0,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
6f630119-938f-4611-9c78-89c47a5cb9a1,lecture1.pdf,CSCI_80,1,Knowledge,9,recursive
b07babee-0df4-4918-afe7-1f8a933c58bc,lecture1.pdf,CSCI_80,2,"knowledge-based agents
agents that reason by operating on 
internal representations of knowledge",96,recursive
12b29ded-65f1-465d-92d8-6bedd7ef6edf,lecture1.pdf,CSCI_80,3,"If it didn't rain, Harry visited Hagrid today.
Harry visited Hagrid or Dumbledore today, but not both.
Harry visited Dumbledore today.
It rained today.
Harry did not visit Hagrid today.",185,recursive
4dd17d33-5c45-44c8-afb1-40a999966e4d,lecture1.pdf,CSCI_80,4,Logic,5,recursive
9155cbb7-0527-4ad5-b220-4c3dd84a0bd0,lecture1.pdf,CSCI_80,5,"sentence
an assertion about the world 
in a knowledge representation language",77,recursive
dbf9f940-54da-4a94-9fb0-b5d49a974487,lecture1.pdf,CSCI_80,6,Propositional Logic,19,recursive
652b5f3a-9d29-4500-abe4-5c7856da0bd3,lecture1.pdf,CSCI_80,7,"Proposition Symbols
P Q R",25,recursive
16a57136-2e5f-43f2-8445-e202f6f1c3a3,lecture1.pdf,CSCI_80,8,"Logical Connectives
¬
not
∧
and
∨
or
→
implication
↔
biconditional",66,recursive
a3c562a3-c1a8-4915-8b32-b2cefd44c649,lecture1.pdf,CSCI_80,9,"Not (¬ )
P ¬P
false true
true false",35,recursive
ecb1b9ee-1c20-437e-bd03-399aaa0dbdb3,lecture1.pdf,CSCI_80,10,"And (∧)
P Q P ∧ Q
false false false
false true false
true false false
true true true",84,recursive
4fd1663c-6886-43b6-86e6-051d8b4b05ab,lecture1.pdf,CSCI_80,11,"Or (∨)
P Q P ∨ Q
false false false
false true true
true false true
true true true",81,recursive
d3ea9aa2-002c-44f8-9c10-8e022160ee35,lecture1.pdf,CSCI_80,12,"Implication (→)
P Q P → Q
false false true
false true true
true false false
true true true",90,recursive
a5754bec-2d4e-4af4-ae83-797c2731d0c4,lecture1.pdf,CSCI_80,13,"Biconditional (↔)
P Q P ↔ Q
false false true
false true false
true false false
true true true",93,recursive
f47e4ba1-2522-4fe2-b7db-1a2ba2ade611,lecture1.pdf,CSCI_80,14,"model
assignment of a truth value to every 
propositional symbol (a ""possible world"")",85,recursive
602d5977-ebc8-4fe5-a287-86ae39dd9f22,lecture1.pdf,CSCI_80,15,"model P:  It is raining.
Q:  It is a Tuesday.
{P = true, Q = false}",67,recursive
799b9146-03af-43e7-b21a-2e44808ea025,lecture1.pdf,CSCI_80,16,"knowledge base
a set of sentences known by a 
knowledge-based agent",67,recursive
f25193b5-4718-4059-9c46-cdc6ba3ff736,lecture1.pdf,CSCI_80,17,"Entailment
α ⊨ β
In every model in which sentence α is true, 
sentence β is also true.",86,recursive
62c7bb39-8181-4c29-ab3f-73fae4454631,lecture1.pdf,CSCI_80,18,"If it didn't rain, Harry visited Hagrid today.
Harry visited Hagrid or Dumbledore today, but not both.
Harry visited Dumbledore today.
It rained today.
Harry did not visit Hagrid today.",185,recursive
236777b2-182b-4c55-a2ae-069d5787026e,lecture1.pdf,CSCI_80,19,"inference
the process of deriving new sentences 
from old ones",62,recursive
74e3be39-e97d-4472-bf0e-5568001f1875,lecture1.pdf,CSCI_80,20,"P:  It is a Tuesday.
Q:  It is raining.
R:  Harry will go for a run.
KB: (P ∧ ¬ Q) → R P ¬Q
Inference: R",104,recursive
d2f95263-6f2b-4ff3-a707-168c454b2306,lecture1.pdf,CSCI_80,21,Inference Algorithms,20,recursive
665a59d2-d0f0-4206-a45f-44a60d59d1df,lecture1.pdf,CSCI_80,22,"Does
?
KB ⊨ α",13,recursive
9190e0fc-3f7c-4362-8eb0-4ade4f9fb8a9,lecture1.pdf,CSCI_80,23,Model Checking,14,recursive
dc90b38e-f8ca-4e51-8fc0-df51a8984e7a,lecture1.pdf,CSCI_80,24,"Model Checking
•To determine if KB ⊨ α: 
•Enumerate all possible models. 
•If in every model where KB is true, α is true, then 
KB entails α. 
•Otherwise, KB does not entail α.",176,recursive
baec4ce4-eb96-4367-9f6c-7f1caca70e37,lecture1.pdf,CSCI_80,25,"P:  It is a Tuesday. Q:  It is raining. R:  Harry will go for a run.
KB: (P ∧ ¬ Q) → R P ¬Q
Query: R
P Q R KB
false false false
false false true
false true false
false true true
true false false
true false true
true true false
true true true",241,recursive
844c82d0-9f47-4c5a-b11c-ecb7bbbb813a,lecture1.pdf,CSCI_80,26,"P:  It is a Tuesday. Q:  It is raining. R:  Harry will go for a run.
KB: (P ∧ ¬ Q) → R P ¬Q
Query: R
P Q R KB
false false false false
false false true false
false true false false
false true true false
true false false false
true false true true
true true false false
true true true false",288,recursive
ee829b25-8539-41f2-b5a7-c440080d100d,lecture1.pdf,CSCI_80,27,"P:  It is a Tuesday. Q:  It is raining. R:  Harry will go for a run.
KB: (P ∧ ¬ Q) → R P ¬Q
Query: R
P Q R KB
false false false false
false false true false
false true false false
false true true false
true false false false
true false true true
true true false false
true true true false",288,recursive
5d7533ed-1b80-4fe4-ad77-ab7c168b0c9c,lecture1.pdf,CSCI_80,28,Knowledge Engineering,21,recursive
dfeafe5f-20f1-4bb7-a512-c59257136046,lecture1.pdf,CSCI_80,29,Clue,4,recursive
308c1d8e-d7ab-4f2c-879c-c29d6d9919b6,lecture1.pdf,CSCI_80,30,"Clue
Col. Mustard
People
Prof. Plum
Ms. Scarlet
Ballroom
Rooms
Kitchen
Library
Knife
Weapons
Revolver
Wrench",108,recursive
bb674898-a631-4572-b84b-5655cc06046b,lecture1.pdf,CSCI_80,31,"Clue
Col. Mustard
People
Prof. Plum
Ms. Scarlet
Ballroom
Rooms
Kitchen
Library
Knife
Weapons
Revolver
Wrench",108,recursive
195f2cbc-4ae6-43d8-86f8-0709701a6955,lecture1.pdf,CSCI_80,32,"Clue
Col. Mustard
People
Prof. Plum
Ms. Scarlet
Ballroom
Rooms
Kitchen
Library
Knife
Weapons
Revolver
Wrench",108,recursive
55a37cfe-0f03-4814-a643-4fe4b662acde,lecture1.pdf,CSCI_80,33,"Col. Mustard
People
Prof. Plum
Ms. Scarlet
Ballroom
Rooms
Kitchen
Library
Knife
Weapons
Revolver
Wrench",103,recursive
064d618c-5383-4ab8-a660-4a4c2acd00a7,lecture1.pdf,CSCI_80,34,"Col. Mustard
People
Prof. Plum
Ms. Scarlet
Ballroom
Rooms
Kitchen
Library
Knife
Weapons
Revolver
Wrench",103,recursive
4bb27da8-242a-4130-a6e1-4702744de08e,lecture1.pdf,CSCI_80,35,"Clue
Propositional Symbols
mustard 
plum 
scarlet
ballroom 
kitchen 
library
knife 
revolver 
wrench",100,recursive
ff4f0be1-d508-4fe8-8b3f-7627369258c7,lecture1.pdf,CSCI_80,36,"Clue
(mustard ∨ plum ∨ scarlet)
(ballroom ∨ kitchen ∨ library)
(knife ∨ revolver ∨ wrench)
¬ plum
¬ mustard ∨ ¬ library ∨ ¬ revolver",132,recursive
3e528c19-ed42-4438-97b7-086c2bd2e4d5,lecture1.pdf,CSCI_80,37,"Logic Puzzles
•Gilderoy, Minerva, Pomona and Horace each belong 
to a different one of the four houses: Gryffindor, 
Hufflepuff, Ravenclaw, and Slytherin House. 
•Gilderoy belongs to Gryffindor or Ravenclaw. 
•Pomona does not belong in Slytherin. 
•Minerva belongs to Gryffindor.",279,recursive
a5d4fe13-1f8a-47b8-807a-9a958ae830e7,lecture1.pdf,CSCI_80,38,"Logic Puzzles
Propositional Symbols
GilderoyGryffindor 
GilderoyHufflepuff 
GilderoyRavenclaw 
GilderoySlytherin
MinervaGryffindor 
MinervaHufflepuff 
MinervaRavenclaw 
MinervaSlytherin
PomonaGryffindor 
PomonaHufflepuff 
PomonaRavenclaw 
PomonaSlytherin
HoraceGryffindor 
HoraceHufflepuff 
HoraceRavenclaw 
HoraceSlytherin",323,recursive
80ec804f-0fc7-4724-889b-83755b2cfe9e,lecture1.pdf,CSCI_80,39,"Logic Puzzles
(GilderoyGryffindor ∨ GilderoyRavenclaw)
(PomonaSlytherin → ¬ PomonaHufflepuff)
(MinervaRavenclaw → ¬ GilderoyRavenclaw)",134,recursive
6753a7da-b904-4861-8dfb-bb964d007c20,lecture1.pdf,CSCI_80,40,"Mastermind
2
0
4",16,recursive
131f178a-0beb-4b61-a3c7-ee2fc86d12ce,lecture1.pdf,CSCI_80,41,Inference Rules,15,recursive
092a65eb-1c13-42cc-8808-34ee6f3ee560,lecture1.pdf,CSCI_80,42,"If it is raining, then Harry is inside.
It is raining.
Harry is inside.
Modus Ponens",84,recursive
6eb79162-d593-4b60-b755-ef343824632c,lecture1.pdf,CSCI_80,43,"α →  β
α
β
Modus Ponens",23,recursive
31c7a397-0f3e-451d-9085-cd02c908f1e0,lecture1.pdf,CSCI_80,44,"Harry is friends with Ron and Hermione.
Harry is friends with Hermione.
And Elimination",87,recursive
222aec49-dacf-4b03-9956-53f7308f665f,lecture1.pdf,CSCI_80,45,"α ∧ β
α
And Elimination",23,recursive
9a623924-a6b9-4ba4-bc70-c3521f00ebc8,lecture1.pdf,CSCI_80,46,"It is not true that Harry did not pass the test.
Harry passed the test.
Double Negation Elimination",99,recursive
c0d125d2-15db-4f8c-836b-0a07289a5bd8,lecture1.pdf,CSCI_80,47,"¬(¬ α)
α
Double Negation Elimination",36,recursive
ab9f81a0-4029-43a9-9cdc-f4eee354f17e,lecture1.pdf,CSCI_80,48,"If it is raining, then Harry is inside.
It is not raining or Harry is inside.
Implication Elimination",101,recursive
1683e228-b3a9-4cef-9f25-faca87366063,lecture1.pdf,CSCI_80,49,"α →  β
¬ α ∨ β
Implication Elimination",38,recursive
cde2b806-bbe4-491c-a4ab-8e1bea55fde3,lecture1.pdf,CSCI_80,50,"It is raining if and only if Harry is inside.
If it is raining, then Harry is inside, 
and if Harry is inside, then it is raining.
Biconditional Elimination",156,recursive
e904fb88-a4a0-4684-94fd-65ed49669223,lecture1.pdf,CSCI_80,51,"α ↔  β
(α →  β) ∧ (β → α)
Biconditional Elimination",51,recursive
a9c40d7c-92b1-4a5c-8577-61e8493cb245,lecture1.pdf,CSCI_80,52,"It is not true that both 
Harry and Ron passed the test.
Harry did not pass the test 
or Ron did not pass the test.
De Morgan's Law",131,recursive
d210657b-9c5f-4511-9726-476f175fef88,lecture1.pdf,CSCI_80,53,"¬( α ∧ β)
¬ α ∨ ¬ β
De Morgan's Law",35,recursive
173fcc49-7d9e-4823-98d1-e2a01d8ab218,lecture1.pdf,CSCI_80,54,"It is not true that  
Harry or Ron passed the test.
Harry did not pass the test 
and Ron did not pass the test.
De Morgan's Law",127,recursive
409f1087-a936-48d1-89eb-3ca752e4eb3a,lecture1.pdf,CSCI_80,55,"¬( α ∨ β)
¬ α ∧ ¬ β
De Morgan's Law",35,recursive
fb5e9533-9e3d-4090-b18d-4ad2f4e59209,lecture1.pdf,CSCI_80,56,"(α ∧ (β ∨ γ))
(α ∧ β) ∨  (α ∧ γ)
Distributive Property",54,recursive
3dbbb43a-e8b2-4031-9aec-9cffad1528e0,lecture1.pdf,CSCI_80,57,"(α ∨ (β ∧ γ))
(α ∨ β) ∧ (α ∨ γ)
Distributive Property",53,recursive
1aab6c61-b6df-432b-99d4-1838b4e8ac89,lecture1.pdf,CSCI_80,58,"Search Problems
•initial state 
•actions 
•transition model 
•goal test 
•path cost function",92,recursive
c8647938-e566-4bea-ae48-59408f88aaad,lecture1.pdf,CSCI_80,59,"Theorem Proving
•initial state: starting knowledge base 
•actions: inference rules 
•transition model: new knowledge base after inference 
•goal test: check statement we're trying to prove 
•path cost function: number of steps in proof",235,recursive
59c74bde-6f48-42a4-a015-4c5cddb57524,lecture1.pdf,CSCI_80,60,Resolution,10,recursive
1d913cbc-6c96-4013-ad9b-71408b6a894a,lecture1.pdf,CSCI_80,61,"(Ron is in the Great Hall) ∨ (Hermione is in the library)
Ron is not in the Great Hall
Hermione is in the library",113,recursive
c03f03fb-0bb1-4ef8-aa81-a24e0d8b82ef,lecture1.pdf,CSCI_80,62,"P ∨ Q
¬ P
Q",11,recursive
0f93c690-e233-425d-b891-b8d9655539e6,lecture1.pdf,CSCI_80,63,"P ∨ Q1 ∨ Q2 ∨ ...∨ Qn
¬ P
Q1 ∨ Q2 ∨ ...∨ Qn",43,recursive
fe86be16-8f0a-4f21-b009-40fd53b88477,lecture1.pdf,CSCI_80,64,"(Ron is in the Great Hall) ∨ (Hermione is in the library)
(Ron is not in the Great Hall) ∨ (Harry is sleeping)
(Hermione is in the library) ∨ (Harry is sleeping)",161,recursive
c0af847c-57a5-409b-9309-aef0144b4e0b,lecture1.pdf,CSCI_80,65,"P ∨ Q
¬ P ∨ R
Q ∨ R",19,recursive
cbf6c2d4-82ec-4f6a-bffd-05ccdc710924,lecture1.pdf,CSCI_80,66,"P ∨ Q1 ∨ Q2 ∨ ...∨ Qn
¬ P ∨ R1 ∨ R2 ∨ ...∨ Rm
Q1 ∨ Q2 ∨ ...∨ Qn ∨ R1 ∨ R2 ∨ ...∨ Rm",83,recursive
7a7df3c5-32d0-4830-8777-aab0208586d8,lecture1.pdf,CSCI_80,67,"clause
a disjunction of literals 
e.g. P ∨ Q ∨ R",48,recursive
7cafd9bd-9205-4768-92c4-2ae77a4ef85f,lecture1.pdf,CSCI_80,68,"conjunctive normal form
logical sentence that is a conjunction of 
clauses 
e.g. (A ∨ B ∨ C) ∧ (D ∨ ¬ E) ∧ (F ∨ G)",114,recursive
0baba204-6df8-4c64-99e4-1563a0c311b2,lecture1.pdf,CSCI_80,69,"Conversion to CNF
•Eliminate biconditionals 
•turn (α ↔  β) into (α →  β) ∧ (β → α) 
•Eliminate implications 
•turn (α →  β) into ¬ α ∨ β 
•Move ¬ inwards using De Morgan's Laws 
•e.g. turn ¬( α ∧ β) into ¬ α ∨ ¬ β 
•Use distributive law to distribute ∨ wherever possible",271,recursive
fb66a37d-6b97-40b7-9b9e-dba0651471f5,lecture1.pdf,CSCI_80,70,"Conversion to CNF
(P ∨ Q) → R 
¬ (P ∨ Q) ∨ R 
(¬P ∧ ¬Q ) ∨ R 
(¬P ∨ R) ∧  (¬Q ∨ R)
eliminate implication
De Morgan's Law
distributive law",137,recursive
2898b8be-695f-47f3-b65d-7f3c55d25328,lecture1.pdf,CSCI_80,71,Inference by Resolution,23,recursive
63ce017f-61e1-4adc-91e4-b17f2d8b8fff,lecture1.pdf,CSCI_80,72,"P ∨ Q
¬ P ∨ R
(Q ∨ R)",21,recursive
d8e5d03f-f2a7-4293-99f3-5cb41bdba63b,lecture1.pdf,CSCI_80,73,"P ∨ Q ∨ S
¬ P ∨ R ∨ S
(Q ∨ S ∨ R ∨ S)",37,recursive
df039163-9de7-4617-b889-efbee9fc9285,lecture1.pdf,CSCI_80,74,"P ∨ Q ∨ S
¬ P ∨ R ∨ S
(Q ∨ R ∨ S)",33,recursive
7d6878c5-f085-4f65-af06-4e0547386a7c,lecture1.pdf,CSCI_80,75,"P
¬ P
( )",9,recursive
2f68f0aa-6f8c-4772-81cc-fa18fbb4b599,lecture1.pdf,CSCI_80,76,"Inference by Resolution
•To determine if KB ⊨ α: 
•Check if (KB ∧ ¬ α) is a contradiction? 
•If so, then KB ⊨ α. 
•Otherwise, no entailment.",140,recursive
e5660607-bbd2-4667-9d68-8ba20e074a17,lecture1.pdf,CSCI_80,77,"Inference by Resolution
•To determine if KB ⊨ α: 
•Convert (KB ∧ ¬ α) to Conjunctive Normal Form. 
•Keep checking to see if we can use resolution to 
produce a new clause. 
•If ever we produce the empty clause (equivalent 
to False), we have a contradiction, and KB ⊨ α. 
•Otherwise, if we can't add new clauses, no 
entailment.",328,recursive
f078deaa-3fb8-4166-bb53-080532a051a8,lecture1.pdf,CSCI_80,78,"Inference by Resolution
Does (A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) entail A?
(A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) ∧ (¬ A)
(A ∨ B)    (¬ B ∨ C)    (¬ C)    (¬ A)",141,recursive
39da6722-2524-457c-b515-2cbffdd4d622,lecture1.pdf,CSCI_80,79,"Inference by Resolution
Does (A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) entail A?
(A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) ∧ (¬ A)
(A ∨ B)    (¬ B ∨ C)    (¬ C)    (¬ A)",141,recursive
ebbb9312-0047-4cbf-bac4-b208029186ed,lecture1.pdf,CSCI_80,80,"Inference by Resolution
Does (A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) entail A?
(A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) ∧ (¬ A)
(¬ B)(A ∨ B)    (¬ B ∨ C)    (¬ C)    (¬ A)",146,recursive
092af28a-7882-4802-a153-2454b261946e,lecture1.pdf,CSCI_80,81,"Inference by Resolution
Does (A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) entail A?
(A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) ∧ (¬ A)
(¬ B)(A ∨ B)    (¬ B ∨ C)    (¬ C)    (¬ A)",146,recursive
d1d33903-27d3-475c-ba87-adf1faa3314d,lecture1.pdf,CSCI_80,82,"Inference by Resolution
Does (A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) entail A?
(A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) ∧ (¬ A)
(¬ B)(A ∨ B)    (¬ B ∨ C)    (¬ C)    (¬ A)",146,recursive
9b205240-3049-4c98-b343-40d83053be04,lecture1.pdf,CSCI_80,83,"Inference by Resolution
Does (A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) entail A?
(A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) ∧ (¬ A)
(¬ B)(A ∨ B)    (¬ B ∨ C)    (¬ C)    (¬ A) (A)",150,recursive
3f11860e-08cc-4b69-aa16-330879aada7e,lecture1.pdf,CSCI_80,84,"Inference by Resolution
Does (A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) entail A?
(A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) ∧ (¬ A)
(¬ B)(A ∨ B)    (¬ B ∨ C)    (¬ C)    (¬ A) (A)",150,recursive
1e9eb57d-f67e-465c-8524-ee748653bea6,lecture1.pdf,CSCI_80,85,"Inference by Resolution
Does (A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) entail A?
(A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) ∧ (¬ A)
(¬ B)(A ∨ B)    (¬ B ∨ C)    (¬ C)    (¬ A) (A)",150,recursive
ef340fae-8c4c-4ba7-bacc-1a3f9be182ce,lecture1.pdf,CSCI_80,86,"Inference by Resolution
Does (A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) entail A?
(A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) ∧ (¬ A)
(¬ B)(A ∨ B)    (¬ B ∨ C)    (¬ C)    (¬ A) (A) ( )",154,recursive
46812353-16ca-46fd-9d7c-d753d5dcfa50,lecture1.pdf,CSCI_80,87,"Inference by Resolution
Does (A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) entail A?
(A ∨ B) ∧ (¬ B ∨ C) ∧ (¬ C) ∧ (¬ A)
(¬ B)(A ∨ B)    (¬ B ∨ C)    (¬ C)    (¬ A) (A) ( )",154,recursive
34a56f56-9d00-493c-b4ea-dd20afbfa961,lecture1.pdf,CSCI_80,88,First-Order Logic,17,recursive
b026884f-2477-4e7d-9f62-2eabe2c2abaa,lecture1.pdf,CSCI_80,89,"Propositional Logic
MinervaGryffindor
MinervaHufflepuff
Propositional Symbols
MinervaRavenclaw
MinervaSlytherin
…",113,recursive
bb26ef1b-5b2c-452b-88b1-d4ac00502309,lecture1.pdf,CSCI_80,90,"First-Order Logic
Minerva 
Pomona 
Horace 
Gilderoy 
Gryffindor 
Hufflepuff 
Ravenclaw 
Slytherin
Constant Symbol Predicate Symbol
Person 
House 
BelongsTo",155,recursive
ab9e69bc-1f83-402e-9cd1-a47955aaf7f4,lecture1.pdf,CSCI_80,91,"First-Order Logic
Person(Minerva) Minerva is a person.
House(Gryffindor) Gryffindor is a house.
¬ House(Minerva) Minerva is not a house.
BelongsTo(Minerva, Gryffindor)
Minerva belongs to Gryffindor.",198,recursive
4a74666c-4478-4950-8d1e-fedc9c8349cf,lecture1.pdf,CSCI_80,92,Universal Quantiﬁcation,23,recursive
dadd376a-5b7f-4bca-b859-c68fc9a9652c,lecture1.pdf,CSCI_80,93,"Universal Quantiﬁcation
∀x. BelongsTo(x, Gryffindor) → 
       ¬ BelongsTo(x, Hufflepuff)
For all objects x, if x belongs to Gryffindor, 
then x does not belong to Hufflepuff. 
Anyone in Gryffindor is not in Hufflepuff.",219,recursive
b52c6dc7-c960-4928-a157-2aa1fb09be42,lecture1.pdf,CSCI_80,94,Existential Quantiﬁcation,25,recursive
ffc71e1e-f91e-489d-a5e6-5a06f3bed55d,lecture1.pdf,CSCI_80,95,"Existential Quantiﬁcation
∃x. House(x) ∧ BelongsTo(Minerva, x)
There exists an object x such that 
x is a house and Minerva belongs to x.
Minerva belongs to a house.",165,recursive
673196ec-ebc1-4b4f-8c3c-58fae246925b,lecture1.pdf,CSCI_80,96,"Existential Quantiﬁcation
∀x. Person(x) →  (∃y. House(y) ∧ BelongsTo(x, y))
For all objects x, if x is a person, then 
there exists an object y such that 
y is a house and x belongs to y. 
Every person belongs to a house.",221,recursive
47dd4f4b-d765-4e9b-9142-8f8d61529ba6,lecture1.pdf,CSCI_80,97,Knowledge,9,recursive
5fa441ae-ec3b-4e84-99c3-98e13f4d0c83,lecture1.pdf,CSCI_80,98,"Introduction to 
Artiﬁcial Intelligence 
with Python",52,recursive
83b09c2a-c15d-4f78-9d88-8f324c8020aa,Lecture_4.pdf,CSCI_80,0,"Lecture 4  1. Machine Learning Machine learning provides a computer with data, rather than explicit instruc7ons. Using these data, the computer learns to recognize pa;erns and becomes able to execute tasks on its own. There are three primary ways of doing this: Supervised (labeled input-output pair), reinforcement (reward, punishment), and unsupervised.  2. Supervised Learning Supervised learning is a task where a computer learns a func7on that maps inputs to outputs based on a dataset of input-output pairs.  There are mul7ple tasks under supervised learning, and one of those is Classiﬁca(on. This is a task where the func7on maps an input to a discrete output/categories. For example, given some informa7on on humidity and air pressure for a par7cular day (input), the computer decides whether it will rain that day or not (output). The computer does this aHer training on a dataset with mul7ple days where humidity and air pressure are already mapped to whether it rained or not",987,recursive
4a8e3e14-db7c-4278-8f59-68436c673277,Lecture_4.pdf,CSCI_80,0,". The computer does this aHer training on a dataset with mul7ple days where humidity and air pressure are already mapped to whether it rained or not.  This task can be formalized as follows. We observe nature, where a func7on f(humidity, pressure) maps the input to a discrete value, either Rain or No Rain. This func7on is hidden from us, and it is probably aﬀected by many other variables that we don’t have access to. Our goal is to create func7on h(humidity, pressure) that can approximate the behavior of func7on f. Such a task can be visualized by ploOng days on the dimensions of humidity and rain (the input), coloring each data point in blue if it rained that day and in red if it didn’t rain that day (the output). The white data point has only the input, and the computer needs to ﬁgure out the output.  3. Classiﬁca9on We will look at three primary ways: Nearest neighbour, perceptron/linear and support vector.  3.1",928,recursive
2f1c2aee-d287-4762-ab5f-4d784547ff70,Lecture_4.pdf,CSCI_80,0,".  3. Classiﬁca9on We will look at three primary ways: Nearest neighbour, perceptron/linear and support vector.  3.1. Nearest-Neighbor Classiﬁca5on One way of solving a task like the one described above is by assigning the variable in ques7on the value of the closest observa7on. So, for example, the white dot on the graph above would be colored blue, because the nearest observed dot is blue as well. This might work well some 7mes, but consider the graph below.  3.2. K Nearest Neighbor Classiﬁca5on  Following the same strategy, the white dot should be colored red, because the nearest observa7on to it is red as well. However, looking at the bigger picture, it looks like most of the",688,recursive
a5cb5b32-0b7f-4c32-9dd5-febe1ef4cef4,Lecture_4.pdf,CSCI_80,1,"other observa7ons around it are blue, which might give us the intui7on that blue is a be;er predic7on in this case, even though the closest observa7on is red.  One way to get around the limita7ons of nearest-neighbor classiﬁca7on is by using k-nearest-neighbors classiﬁca7on, where the dot is colored based on the most frequent color of the k nearest neighbors. It is up to the programmer to decide what k is. Using a 3-nearest neighbors classiﬁca7on, for example, the white dot above will be colored blue, which intui7vely seems like a be;er decision.  A drawback of the k-nearest-neighbors classiﬁca7on is that, using a naive approach, the algorithm will have to measure the distance of every single point to the point in ques7on, which is computa7onally expensive. This can be sped up by using data structures that enable ﬁnding neighbors more quickly or by pruning irrelevant observa7on.  3.3",896,recursive
3d4ff96a-8d42-4e8d-a179-09809261439f,Lecture_4.pdf,CSCI_80,1,". This can be sped up by using data structures that enable ﬁnding neighbors more quickly or by pruning irrelevant observa7on.  3.3. Perceptron Learning/Linear Regression Another way of going about a classiﬁca7on problem, as opposed to the nearest-neighbor strategy, is looking at the data as a whole and trying to create a decision boundary. In two-dimensional data, we can draw a line between the two types of observa7ons. Every addi7onal data point will be classiﬁed based on the side of the line on which it is plo;ed.  Decision Boundary  The drawback to this approach is that data are messy, and it is rare that one can draw a line and neatly divide the classes into two observa7ons without any mistakes. OHen, we will compromise, drawing a boundary that separates the observa7ons correctly more oHen than not, but s7ll occasionally misclassiﬁes them",854,recursive
8d09f62b-0b8d-4372-9b4f-2194b8608650,Lecture_4.pdf,CSCI_80,1,". OHen, we will compromise, drawing a boundary that separates the observa7ons correctly more oHen than not, but s7ll occasionally misclassiﬁes them.  In this case, the input of  x₁ = Humidity x₂ = Pressure will be given to a hypothesis func7on h(x₁, x₂), which will output its predic7on of whether it is going to rain that day or not. It will do so by checking on which side of the decision boundary the observa7on falls. Formally, the func7on will weight each of the inputs with an addi7on of a constant, ending in a linear equa7on of the following form:  h(x₁, x₂) = Rain if w₀ + w₁x₁ + w₂x₂ ≥ 0      No Rain otherwise  OHen, the output variable will be coded as 1 and 0, where if the equa7on yields more than 0, the output is 1 (Rain), and 0 otherwise (No Rain).  The weights and values are represented by vectors, which are sequences of numbers (which can be stored in lists or tuples in Python). We produce a Weight Vector w: (w₀, w₁, w₂), and geOng",954,recursive
59b47834-13f9-44a2-9d85-ff711fc439fc,Lecture_4.pdf,CSCI_80,2,"to the best weight vector is the goal of the machine learning algorithm. We also produce an Input Vector x: (1, x₁, x₂).  We take the dot product of the two vectors. That is, we mul7ply each value in one vector by the corresponding value in the second vector, arriving at the expression above: w₀ + w₁x₁ + w₂x₂. The ﬁrst value in the input vector is 1 because, when mul7plied by the weight vector w₀, we want to keep it a constant. The hypothesis is parameterized by weight as the hypothesis will change based on the weight.  Thus, we can represent our hypothesis function the following way: 
 Since the goal of the algorithm is to find the best weight vector, when the algorithm encounters new data it updates the current weights. It does so using the perceptron learning rule:",778,recursive
42973b7c-84a2-454f-adf7-da4dee8f9015,Lecture_4.pdf,CSCI_80,2,"Since the goal of the algorithm is to find the best weight vector, when the algorithm encounters new data it updates the current weights. It does so using the perceptron learning rule: 
   Dot Product Equa7on  Since the goal of the algorithm is to ﬁnd the best weight vector, when the algorithm encounters new data it updates the current weights. It does so using the perceptron learning rule:  3.4. Perceptron Learning Rule Given data point(x, y) update each weight according to: W(i) = w(i) + alpha(y – h(x)) * x(i)",517,recursive
48d57cf7-dbb1-47ab-b900-6498abb8222f,Lecture_4.pdf,CSCI_80,3,"W(i) = w(i) + alpha(actual value – es7mate) * x(i)    The important takeaway from this rule is that for each data point, we adjust the weights to make our func7on more accurate. The details, which are not as cri7cal to our point, are that each weight is set to be equal to itself plus some value value in parentheses. Here, y stands for the observed value while the hypothesis func7on stands for the es7mate. If they are iden7cal, this whole term is equal to zero, and thus the weight is not changed. If we underes7mated (calling No Rain while Rain was observed), then the value in the parentheses will be 1 and the weight will increase by the value of xᵢ scaled by α the learning coeﬃcient. If we overes7mated (calling Rain while No Rain was observed), then the value in the parentheses will be -1 and the weight will decrease by the value of x scaled by α. The higher α, the stronger the inﬂuence each new event has on the weight",931,recursive
3e73a3e3-5088-45ae-a0c6-f6ce8a8042f2,Lecture_4.pdf,CSCI_80,3,". The higher α, the stronger the inﬂuence each new event has on the weight.  The result of this process is a threshold func7on that switches from 0 to 1 once the es7mated value crosses some threshold.  3.5. SoB Threshold/Logis5c Regression  The problem with this type of func7on is that it is unable to express uncertainty, since it can only be equal to 0 or to 1. It employs a hard threshold. A way to go around this is by using a logis7c func7on, which employs a soH threshold. A logis7c func7on can yield a real number between 0 and 1, which will express conﬁdence in the es7mate. The closer the value to 1, the more likely it is to rain.",641,recursive
8f9e3f8a-decc-4ef2-a25f-22e8d5ea10f3,Lecture_4.pdf,CSCI_80,4,"The problem with this type of function is that it is unable to express uncertainty, since it can only be equal to 0 or to 1. It employs a hard threshold. A way to go around this is by using a logistic function, which employs a soft threshold. A logistic function can yield a real number between 0 and 1, which will express confidence in the estimate. The closer the value to 1, the more likely it is to rain.",408,recursive
27c5c4a0-ff4a-4aa8-8e09-43a2a8b9bad5,Lecture_4.pdf,CSCI_80,5,"3.6. Support Vector Machines In addi7on to nearest-neighbor and linear regression, another approach to classiﬁca7on is the Support Vector Machine. This approach uses an addi7onal vector (support vector) near the decision boundary to make the best decision when separa7ng the data. Consider the example below.  Support Vector Machine",332,recursive
be61ca0c-d080-479c-99e5-1a18dc24ac8d,Lecture_4.pdf,CSCI_80,5,"All the decision boundaries work in that they separate the data without any mistakes. However, are they equally as good? The two leHmost decision boundaries are very close to some of the observa7ons. This means that a new data point that diﬀers only slightly from one group can be wrongly classiﬁed as the other. As opposed to that, the rightmost decision boundary keeps the most distance from each of the groups, thus giving the most leeway for varia7on within it.   This type of boundary, which is as far as possible from the two groups it separates, is called the Maximum Margin Separator. It is the boundary that maximizes the distance between any of the data points.  Another beneﬁt of support vector machines is that they can represent decision boundaries with more than two dimensions, as well as non-linear decision boundaries, such as below.   3.7",856,recursive
6992190f-859c-479b-b03a-6ac03d90d598,Lecture_4.pdf,CSCI_80,5,".  Another beneﬁt of support vector machines is that they can represent decision boundaries with more than two dimensions, as well as non-linear decision boundaries, such as below.   3.7. Circle Decision Boundary  To summarize, there are mul7ple ways to go about classiﬁca7on problems, with no one being always be;er than the other. Each has their drawbacks and might prove more useful than others in speciﬁc situa7ons.",419,recursive
e191f40d-9c24-46fe-89cb-5ae23e771913,Lecture_4.pdf,CSCI_80,6,"4. Regression Regression is a supervised learning task of a func7on that maps an input point to a con7nuous value, some real number. This diﬀers from classiﬁca7on in that classiﬁca7on problems map an input to discrete values (Rain or No Rain).  For example, a company might use regression to answer the ques7on of how money spent adver7sing predicts money earned in sales. In this case, an observed func7on f(adver7sing) represents the observed income following some money that was spent in adver7sing (note that the func7on can take more than one input variable). These are the data that we start with. With this data, we want to come up with a hypothesis func7on h(adver7sing) that will try to approximate the behavior of func7on f. h will generate a line whose goal is not to separate between types of observa7ons, but to predict, based on the input, what will be the value of the output.",891,recursive
e35b1218-e88a-47c8-8eca-074a1089cead,Lecture_4.pdf,CSCI_80,7,"5. Loss Func9ons Loss func7ons are a way to quan7fy the u7lity lost by any of the decision rules above. The less accurate the predic7on, the larger the loss.  5.1. 0-1 Loss Func5on For classiﬁca7on problems, we can use a 0-1 Loss Func7on.  L(actual, predicted): 0 if actual = predicted 1 otherwise In words, this func7on gains value when the predic7on isn’t correct and doesn’t gain value when it is correct (i.e. when the observed and predicted values match).  In the example above, the days that are valued at 0 are the ones where we predicted the weather correctly (rainy days are below the line and not rainy days are above the line). However, days when it didn’t rain below the line and days when it did rain above it are the ones that we failed to predict. We give each one the value of 1 and sum them up to get an empirical es7mate of how lossy our decision boundary is.  L₁ and L₂ loss func7ons can be used when predic7ng a con7nuous value",947,recursive
8a67c74f-9fa6-4321-a029-b8490caf47e7,Lecture_4.pdf,CSCI_80,7,". We give each one the value of 1 and sum them up to get an empirical es7mate of how lossy our decision boundary is.  L₁ and L₂ loss func7ons can be used when predic7ng a con7nuous value. In this case, we are interested in quan7fying for each predic7on how much it diﬀered from the observed value. We do this by taking either the absolute value or the squared value of the observed value minus the predicted value (i.e. how far the predic7on was from the observed value).  L₁: L(actual, predicted) = |actual - predicted| L₂: L(actual, predicted) = (actual - predicted)² One can choose the loss func7on that serves their goals best. L₂ penalizes outliers more harshly than L₁ because it squares the the diﬀerence. L₁ can be visualized by summing the distances from each observed point to the predicted point on the regression line:",830,recursive
bdf72704-f3b6-4a56-b4d0-ca8ad778dd7e,Lecture_4.pdf,CSCI_80,8,"L₁ is be;er for overall ﬁt, when we don’t care about outliers. L2 is be;er for model where we care about modelling outliers as well.  5.2. OverﬁPng OverﬁOng is when a model ﬁts the training data so well that it fails to generalize to other data sets. In this sense, loss func7ons are a double edged sword. In the two examples below, the loss func7on is minimized such that the loss is equal to 0. However, it is unlikely that it will ﬁt new data well.   
 For example, in the leH graph, a dot next to the red one at the bo;om of the screen is likely to be Rain (blue). However, with the overﬁ;ed model, it will be classiﬁed as No Rain (red).  5.3. Regulariza5on Regulariza7on is the process of penalizing hypotheses that are more complex to favor simpler, more general hypotheses. We use regulariza7on to avoid overﬁOng.  In regulariza7on, we es7mate the cost of the hypothesis func7on h by adding up its loss and a measure of its complexity.",942,recursive
82724c1e-62df-4c67-914f-2cc9734a10e6,Lecture_4.pdf,CSCI_80,9,"cost(h) = loss(h) + λ complexity(h)  Lambda (λ) is a constant that we can use to modulate how strongly to penalize for complexity in our cost func7on. The higher λ is, the more costly complexity is.  One way to test whether we overﬁ;ed the model is with Holdout Cross Valida7on. In this technique, we split all the data in two: a training set and a test set. We run the learning algorithm on the training set, and then see how well it predicts the data in the test set. The idea here is that by tes7ng on data that were not used in training, we can a measure how well the learning generalizes.  The downside of holdout cross valida7on is that we don’t get to train the model on half the data, since it is used for evalua7on purposes. A way to deal with this is using k-Fold Cross-Valida7on. In this process, we divide the data into k sets. We run the training k 7mes, each 7me leaving out one dataset and using it as a test set",927,recursive
7670ac5f-b159-4e61-8fa2-42d7abf84c99,Lecture_4.pdf,CSCI_80,9,". A way to deal with this is using k-Fold Cross-Valida7on. In this process, we divide the data into k sets. We run the training k 7mes, each 7me leaving out one dataset and using it as a test set. We end up with k diﬀerent evalua7ons of our model, which we can average and get an es7mate of how our model generalizes without losing any data.  6. scikit-learn As oHen is the case with Python, there are mul7ple libraries that allow us to conveniently use machine learning algorithms. One of such libraries is scikit-learn.  As an example, we are going to use a CSV dataset of counterfeit banknotes.  Banknotes  The four leH columns are data that we can use to predict whether a note is genuine or counterfeit, which is external data provided by a human, coded as 0 and 1. Now we can train our model on this data set and see if we can predict whether new banknotes are genuine or not",881,recursive
7f7f4bde-683f-44fc-b9de-6a11e04b9c98,Lecture_4.pdf,CSCI_80,9,". Now we can train our model on this data set and see if we can predict whether new banknotes are genuine or not.  import csv import random  from sklearn import svm from sklearn.linear_model import Perceptron from sklearn.naive_bayes import GaussianNB from sklearn.neighbors import KNeighborsClassiﬁer  # model = KNeighborsClassiﬁer(n_neighbors=1) # model = svm.SVC() model = Perceptron() Note that aHer impor7ng the libraries, we can choose which model to use. The rest of the code will stay the same. SVC stands for Support Vector Classiﬁer (which we know as support vector",575,recursive
43294f2f-2825-4213-968c-91b16975d3fa,Lecture_4.pdf,CSCI_80,10,"machine). The KNeighborsClassiﬁer uses the k-neighbors strategy, and requires as input the number of neighbors it should consider",129,recursive
902d21f1-4a8a-4522-a5b0-b97c27c2dacf,Lecture_4.pdf,CSCI_80,10,".  # Read data in from ﬁle with open(""banknotes.csv"") as f:     reader = csv.reader(f)     next(reader)      data = []     for row in reader:         data.append({             ""evidence"": [ﬂoat(cell) for cell in row[:4]],             ""label"": ""Authen7c"" if row[4] == ""0"" else ""Counterfeit""         })  # Separate data into training and tes7ng groups holdout = int(0.40 * len(data)) random.shuﬄe(data) tes7ng = data[:holdout] training = data[holdout:]  # Train model on training set X_training = [row[""evidence""] for row in training] y_training = [row[""label""] for row in training] model.ﬁt(X_training, y_training)  # Make predic7ons on the tes7ng set X_tes7ng = [row[""evidence""] for row in tes7ng] y_tes7ng = [row[""label""] for row in tes7ng] predic7ons = model.predict(X_tes7ng)  # Compute how well we performed correct = 0 incorrect = 0 total = 0 for actual, predicted in zip(y_tes7ng, predic7ons):     total += 1     if actual == predicted:         correct += 1     else:         incorrect += 1  #",999,recursive
bb585817-bc34-4ce8-8810-04843ce15cf4,Lecture_4.pdf,CSCI_80,10,"performed correct = 0 incorrect = 0 total = 0 for actual, predicted in zip(y_tes7ng, predic7ons):     total += 1     if actual == predicted:         correct += 1     else:         incorrect += 1  # Print results print(f""Results for model {type(model).__name__}"")",262,recursive
bf7860c1-0443-4947-811c-208f479fc3dc,Lecture_4.pdf,CSCI_80,11,"print(f""Correct: {correct}"") print(f""Incorrect: {incorrect}"") print(f""Accuracy: {100 * correct / total:.2f}%"") This manual version of running the algorithm can be found in the source code for this lecture under banknotes0.py. Since the algorithm is used oHen in a similar way, scikit-learn contains addi7onal func7ons that make the code even more succinct and easy to use, and this version can be found under banknotes1.py.  7. Reinforcement Learning Reinforcement learning is another approach to machine learning, where aHer each ac7on, the agent gets feedback in the form of reward or punishment (a posi7ve or a nega7ve numerical value).  The learning process starts by the environment providing a state to the agent. Then, the agent performs an ac7on on the state. Based on this ac7on, the environment will return a state and a reward to the agent, where the reward can be posi7ve, making the behavior more likely in the future, or nega7ve (i.e",947,recursive
38d9463f-94c2-4c99-be30-5d9e56e241ba,Lecture_4.pdf,CSCI_80,11,". Based on this ac7on, the environment will return a state and a reward to the agent, where the reward can be posi7ve, making the behavior more likely in the future, or nega7ve (i.e. punishment), making the behavior less likely in the future.",242,recursive
870e1a04-82c6-4726-bc72-ec9b02e3dacd,Lecture_4.pdf,CSCI_80,11,"This type of algorithm can be used to train walking robots, for example, where each step returns a posi7ve number (reward) and each fall a nega7ve number (punishment).  7.1. Markov Decision Processes Reinforcement learning can be viewed as a Markov decision process, having the following proper7es:",298,recursive
c9ba0f6e-1a10-4653-b958-d75759bd5ea6,Lecture_4.pdf,CSCI_80,12,"Set of states S Set of ac7ons Ac7ons(S) Transi7on model P(s’ | s, a) Reward func7on R(s, a, s’) For example, consider the following task: 
  The agent is the yellow circle, and it needs to get to the green square while avoiding the red squares. Every single square in the task is a state. Moving up, down, or to the sides is an ac7on. The transi7on model gives us the new state aHer performing an ac7on, and the reward func7on is what kind of feedback the agent gets. For example, if the agent chooses to go right, it will step on a red square and get nega7ve feedback. This means that the agent will learn that, when in the state of being in the bo;om-leH square, it should avoid going right. This way, the agent will start exploring the space, learning which state-ac7on pairs it should avoid. The algorithm can be probabilis7c, choosing to take diﬀerent ac7ons in diﬀerent states based on some probability that’s being increased or decreased based on reward. When the agent reaches the green",994,recursive
1084c8ed-9a9c-4caa-9219-2e6cf8f22b44,Lecture_4.pdf,CSCI_80,13,"square, it will get a posi7ve reward, learning that it is favorable to take the ac7on it took in the previous state.  7.2. Q-Learning Q-Learning is one model of reinforcement learning, where a func7on Q(s, a) outputs an es7mate of the value of taking ac7on a in state s.  The model starts with all es7mated values equal to 0 (Q(s,a) = 0 for all s, a).  When an ac7on is taken and a reward is received, the func7on does two things: 1) it es7mates the value of Q(s, a) based on current reward and expected future rewards, and 2) updates Q(s, a) to take into account both the old es7mate and the new es7mate.  This gives us an algorithm that is capable of improving upon its past knowledge without star7ng from scratch",715,recursive
299f2483-3351-4134-93a1-faa0ed8e6e14,Lecture_4.pdf,CSCI_80,13,".  This gives us an algorithm that is capable of improving upon its past knowledge without star7ng from scratch. Start with QQ(s,a) = 0 for all s,a  Every 7me we take an ac7on a in state s and observed a reward r, we update:  Q(s, a) ⟵ Q(s, a) + α(new value es7mate – old es7mate) Q(s, a) ⟵ Q(s, a) + α(r + future reward es7mate – Q(s, a)) Q(s, a) ⟵ Q(s, a) + α(r + max(a’) Q(s’,a’) – Q(s, a))  The updated value of Q(s, a) is equal to the previous value of Q(s, a) in addi7on to some upda7ng value. This value is determined as the diﬀerence between the new value and the old value, mul7plied by α, a learning coeﬃcient. When α = 1 the new es7mate simply overwrites the old one. When α = 0, the es7mated value is never updated. By raising and lowering α, we can determine how fast previous knowledge is being updated by new es7mates.  The new value es7mate can be expressed as a sum of the reward (r) and the future reward es7mate",930,recursive
fc4f505b-1cf2-4e71-8128-3756174fac7d,Lecture_4.pdf,CSCI_80,13,".  The new value es7mate can be expressed as a sum of the reward (r) and the future reward es7mate. To get the future reward es7mate, we consider the new state that we got aHer taking the last ac7on, and add the es7mate of the ac7on in this new state that will bring to the highest reward. This way, we es7mate the u7lity of making ac7on a in state s not only by the reward it received, but also by the expected u7lity of the next step. The value of the future reward es7mate can some7mes appear with a coeﬃcient gamma that controls how much future rewards are valued. We end up with the following equa7on:",606,recursive
a39b5eae-a074-4b0b-ac76-e564c6d54127,Lecture_4.pdf,CSCI_80,13,"7.3. Greedy Decision-Making algorithm A Greedy Decision-Making algorithm completely discounts the future es7mated rewards, instead always choosing the ac7on a in current state s that has the highest Q(s, a). When in state s, choose ac7on a with highest Q(s,a)",259,recursive
a90394be-6314-456c-ab6e-7e58e63286c8,Lecture_4.pdf,CSCI_80,14,"This brings us to discuss the Explore vs. Exploit tradeoﬀ. A greedy algorithm always exploits, taking the ac7ons that are already established to bring to good outcomes. However, it will always follow the same path to the solu7on, never ﬁnding a be;er path. Explora7on, on the other hand, means that the algorithm may use a previously unexplored route on its way to the target, allowing it to discover more eﬃcient solu7ons along the way. For example, if you listen to the same songs every single 7me, you know you will enjoy them, but you will never get to know new songs that you might like even more!  7.4. ε (epsilon) Greedy Algorithm To implement the concept of explora7on and exploita7on, we can use the ε (epsilon) greedy algorithm. In this type of algorithm, we set ε equal to how oHen we want to move randomly. With probability 1-ε, the algorithm chooses the best move (exploita7on). With probability ε, the algorithm chooses a random move (explora7on)",960,recursive
becbf05f-40e8-4793-a47f-b64171cb8453,Lecture_4.pdf,CSCI_80,14,". With probability 1-ε, the algorithm chooses the best move (exploita7on). With probability ε, the algorithm chooses a random move (explora7on).  Another way to train a reinforcement learning model is to give feedback not upon every move, but upon the end of the whole process. For example, consider a game of Nim. In this game, diﬀerent numbers of objects are distributed between piles. Each player takes any number of objects from any one single pile, and the player who takes the last object looses. In such a game, an untrained AI will play randomly, and it will be easy to win against it. To train the AI, it will start from playing a game randomly, and in the end get a reward of 1 for winning and -1 for losing. When it is trained on 10,000 games, for example, it is already smart enough to be hard to win against it.  This approach becomes more computa7onally demanding when a game has mul7ple states and possible ac7ons, such as chess",943,recursive
2d45f4b5-cc49-448e-bc5c-521fa3663dfd,Lecture_4.pdf,CSCI_80,14,".  This approach becomes more computa7onally demanding when a game has mul7ple states and possible ac7ons, such as chess. It is infeasible to generate an es7mated value for every possible move in every possible state. In this case, we can use a func7on approxima7on, which allows us to approximate Q(s, a) using various other features, rather than storing one value for each state-ac7on pair. Thus, the algorithm becomes able to recognize which moves are similar enough so that their es7mated value should be similar as well, and use this heuris7c in its decision making.  8. Unsupervised Learning In all the cases we saw before, as in supervised learning, we had data with labels that the algorithm could learn from. For example, when we trained an algorithm to recognize counterfeit notes, each banknote had four variables with diﬀerent values (the input data) and whether it was counterfeit or not (the label)",912,recursive
dc9c5648-dc62-4a91-8288-e35630b6d441,Lecture_4.pdf,CSCI_80,14,". For example, when we trained an algorithm to recognize counterfeit notes, each banknote had four variables with diﬀerent values (the input data) and whether it was counterfeit or not (the label). In unsupervised learning, only the input data is present, and the AI learns pa;erns in these data.  8.1. Clustering  Clustering is an unsupervised learning task that takes the input data and organizes it into groups such that similar objects end up in the same group. This can be used, for example, in gene7cs research, when trying to ﬁnd similar genes, or in image segmenta7on, when deﬁning diﬀerent parts of the image based on similarity between pixels.",653,recursive
9bd45842-b57e-4f48-9f1d-c85fbd5e4fe3,Lecture_4.pdf,CSCI_80,15,"8.2. k-means Clustering k-means Clustering is an algorithm to perform a clustering task. It is an algorithm for clustering data based on repeatedly assigning points to clusters and upda7ng those cluster’s centers. It maps all data points in a space, and then randomly places k cluster centers in the space (it is up to the programmer to decide how many; this is the star7ng state we see on the leH). Each cluster center is simply a point in the space. Then, each cluster gets assigned all the points that are closest to its center than to any other center (this is the middle picture). Then, in an itera7ve process, the cluster center moves to the middle of all these points (the state on the right), and then points are reassigned again to the clusters whose centers are now closest to them. When, aHer repea7ng the process, each point remains in the same cluster it was before, we have reached an equilibrium and the algorithm is over, leaving us with points divided between clusters.",986,recursive
aac05809-5175-499b-8f2b-68ff561fcc38,Lecture_0.pdf,CSCI_80,0,"Week 1    Ar(ﬁcial Intelligence  Ar(ﬁcial Intelligence (AI) covers a range of techniques that appear as sen(ent behavior by the computer. For example, AI is used to recognize faces in photographs on your social media, beat the World’s Champion in chess, and process your speech when you speak to Siri or Alexa on your phone.  In this course, we will explore some of the ideas that make AI possible:  Search Finding a solu(on to a problem, like a navigator app that ﬁnds the best route from your origin to the des(na(on, or like playing a game and ﬁguring out the next move.  Knowledge Represen(ng informa(on and drawing inferences from it.  Uncertainty Dealing with uncertain events using probability.  Op(miza(on Finding not only a correct way to solve a problem, but a beOer—or the best—way to solve it.  Learning Improving performance based on access to data and experience. For example, your email is able to dis(nguish spam from non-spam mail based on past experience",972,recursive
9597a981-bb4a-4f06-bb8a-32650afc6db9,Lecture_0.pdf,CSCI_80,0,".  Learning Improving performance based on access to data and experience. For example, your email is able to dis(nguish spam from non-spam mail based on past experience.  Neural Networks A program structure inspired by the human brain that is able to perform tasks eﬀec(vely.  Language Processing natural language, which is produced and understood by humans.  Search Search problems involve an agent that is given an ini(al state and a goal state, and it returns a solu(on of how to get from the former to the laOer. A navigator app uses a typical search process, where the agent (the thinking part of the program) receives as input your current loca(on and your desired des(na(on, and, based on a search algorithm, returns a suggested path. However, there are many other forms of search problems, like puzzles or mazes.  15 puzzle",831,recursive
22705fff-8f39-4f5b-88e1-c8cecc6ca3a6,Lecture_0.pdf,CSCI_80,1,"Finding a solu(on to a 15 puzzle would require the use of a search algorithm.  1. Agent An en(ty that perceives its environment and acts upon that environment. In a navigator app, for example, the agent would be a representa(on of a car that needs to decide on which ac(ons to take to arrive at the des(na(on.  2. State A conﬁgura(on of an agent in its environment. For example, in a 15 puzzle, a state is any one way that all the numbers are arranged on the board.  3. Ini/al State The state from which the search algorithm starts. In a navigator app, that would be the current loca(on.  4. Ac/ons Choices that can be made in a state. More precisely, ac(ons can be deﬁned as a func(on. Upon receiving state s as input, Ac(ons(s) returns as output the set of ac(ons that can be executed in state s. For example, in a 15 puzzle, the ac(ons of a given state are the ways you can slide squares in the current conﬁgura(on (4 if the empty square is in the middle, 3 if next to a side, 2 if in the corner)",999,recursive
9df2ccc0-7193-4c24-9e5b-9db61bd8443c,Lecture_0.pdf,CSCI_80,1,".  5. Transi/on Model A descrip(on of what state results from performing any applicable ac(on in any state. More precisely, the transi(on model can be deﬁned as a func(on. Upon receiving state s and ac(on a as input, Results(s, a) returns the state resul(ng from performing ac(on a in state s. For example, given a certain conﬁgura(on of a 15 puzzle (state s), moving a square in any direc(on (ac(on a) will bring to a new conﬁgura(on of the puzzle (the new state).  6. State Space The set of all states reachable from the ini(al state by any sequence of ac(ons. For example, in a 15 puzzle, the state space consists of all the 16!/2 conﬁgura(ons on the board that can be reached from any ini(al state. The state space can be visualized as a directed graph with states, represented as nodes, and ac(ons, represented as arrows between nodes.  7. Goal Test The condi(on that determines whether a given state is a goal state",921,recursive
57d3a388-f7b9-4bfc-8419-8a56f8d0c2b9,Lecture_0.pdf,CSCI_80,1,".  7. Goal Test The condi(on that determines whether a given state is a goal state. For example, in a navigator app, the goal test would be whether the current loca(on of the agent (the representa(on of the car) is at the des(na(on. If it is — problem solved. If it’s not — we con(nue searching.",295,recursive
98f19661-34df-4744-8699-8f696e035081,Lecture_0.pdf,CSCI_80,2,"8. Path Cost A numerical cost associated with a given path. For example, a navigator app does not simply bring you to your goal; it does so while minimizing the path cost, ﬁnding the fastest way possible for you to get to your goal state.  9. Solu/on A sequence of ac(ons that leads from the ini(al state to the goal state.  10. Op/mal Solu/on A solu(on that has the lowest path cost among all solu(ons.  11. Node In a search process, data is oaen stored in a node, a data structure that contains the following data:  a. A state (current state) b. Its parent node, through which the current node was generated c. The ac(on that was applied to the state of the parent to get to the current node d. The path cost from the ini(al state to this node  Nodes contain informa(on that makes them very useful for the purposes of search algorithms. They contain a state, which can be checked using the goal test to see if it is the ﬁnal state",932,recursive
150a4f37-8f21-4ad8-86cf-20a4567ed6bb,Lecture_0.pdf,CSCI_80,2,". They contain a state, which can be checked using the goal test to see if it is the ﬁnal state. If it is, the node’s path cost can be compared to other nodes’ path costs, which allows choosing the op(mal solu(on. Once the node is chosen, by virtue of storing the parent node and the ac(on that led from the parent to the current node, it is possible to trace back every step of the way from the ini(al state to this node, and this sequence of ac(ons is the solu(on.  12. Fron/er However, nodes are simply a data structure — they don’t search, they hold informa(on. To actually search, we use the fron(er, the mechanism that “manages” the nodes. The fron(er starts by containing an ini(al state and an empty set of explored items, and then repeats the following ac(ons un(l a solu(on is reached:  a. Repeat: Loop  i. If the fron(er is empty, Stop. There is no solu(on to the problem.  ii. If the fron(er is not empty, remove a node from the fron(er. This is the node that will be considered. iii",995,recursive
655aac8b-b025-4aa3-80f7-c3ac53703f5b,Lecture_0.pdf,CSCI_80,2,". Repeat: Loop  i. If the fron(er is empty, Stop. There is no solu(on to the problem.  ii. If the fron(er is not empty, remove a node from the fron(er. This is the node that will be considered. iii. If the removed node contains the goal state, return the solu(on iv. If the removed node does not contain the goal state, expand the node. Expand the node (ﬁnd all the new nodes that could be reached from this node), and add resul(ng nodes to the fron(er.",453,recursive
349e98a1-5445-48a7-9c06-04087048b572,Lecture_0.pdf,CSCI_80,3,"* Add the current node to the explored set to avoid exploring them again and again.   Revised approach: a. Fron(er with an ini(al state b. Another data structure with an empty explored set c. Repeat: i. If the fron(er is empty, no solu(on ii. If the fron(er is not empty, then remove the node from the fron(er. - Check if the node has the goal state. If no, then add to the explored data structure. - If the node contains the goal state, return solu(on.  iii. Expand node, add resul(ng nodes to the fron(er if they aren’t already in the fron(er or the explored set.   Strategy to remove the node from the fron0er In the previous descrip(on of the fron(er, one thing went unmen(oned. At stage 1 in the pseudocode above, which node should be removed? This choice has implica(ons on the quality of the solu(on and how fast it is achieved",834,recursive
b4323da2-6b0d-40ba-8cad-12519d78a843,Lecture_0.pdf,CSCI_80,3,". At stage 1 in the pseudocode above, which node should be removed? This choice has implica(ons on the quality of the solu(on and how fast it is achieved. There are mul(ple ways to go about the ques(on of which nodes should be considered ﬁrst, two of which can be represented by the data structures of stack (in depth-ﬁrst search) and queue (in breadth-ﬁrst search; and here is a cute cartoon demonstra(on of the diﬀerence between the two).  a. Stack/ Depth First Search. Last in ﬁrst out data structure. That is, the last node added to the fron(er will be the ﬁrst one explored. This is depth-ﬁrst search.  A depth-ﬁrst search algorithm exhausts each one direc(on before trying another direc(on. In these cases, the fron(er is managed as a stack data structure. The catchphrase you need to remember here is “last-in ﬁrst-out.” Aaer nodes are being added to the fron(er, the ﬁrst node to remove and consider is the last one to be added",935,recursive
ad97ac3c-e7bb-4935-b61a-b0d42b818056,Lecture_0.pdf,CSCI_80,3,". The catchphrase you need to remember here is “last-in ﬁrst-out.” Aaer nodes are being added to the fron(er, the ﬁrst node to remove and consider is the last one to be added. This results in a search algorithm that goes as deep as possible in the ﬁrst direc(on that gets in its way while leaving all other direc(ons for later.  (An example from outside lecture: Take a situa(on where you are looking for your keys. In a depth-ﬁrst search approach, if you choose to start with searching in your pants, you’d ﬁrst go through every single pocket, emptying each pocket and going through the contents carefully. You will stop searching in your pants and start searching elsewhere only once you have completely exhausted the search in every single pocket of your pants.)  Pros: At best, this algorithm is the fastest. If it “lucks out” and always chooses the right path to the solu(on (by chance), then depth-ﬁrst search takes the least possible (me to get to a solu(on",964,recursive
ca40348d-f07c-4d98-882a-0f7222decf40,Lecture_0.pdf,CSCI_80,3,". If it “lucks out” and always chooses the right path to the solu(on (by chance), then depth-ﬁrst search takes the least possible (me to get to a solu(on.  Cons: It is possible that the found solu(on is not op(mal ( in case more than one solu(on exist). At worst, this algorithm will explore every possible path before ﬁnding the solu(on, thus taking",350,recursive
cfe70fa4-e698-4598-bbcb-0b6f7d3a6de3,Lecture_0.pdf,CSCI_80,4,"the longest possible (me before reaching the solu(on. Not good for inﬁnite space. Only good for ﬁnite space.   Code example:     # Deﬁne the func(on that removes a node from the fron(er and returns it.     def remove(self):        # Terminate the search if the fron(er is empty, because this means that there is no solu(on.         if self.empty():             raise Excep(on(""empty fron(er"")         else:            # Save the last item in the list (which is the newest node added)             node = self.fron(er[-1]             # Save all the items on the list besides the last node (i.e. removing the last node)             self.fron(er = self.fron(er[:-1]             return node   b. Queue/Breadth-First Search: The opposite of depth-ﬁrst search would be breadth-ﬁrst search (BFS). First in ﬁrst out, like a queue. Breadth ﬁrst search explores the shallowest node in the fron(er. It runs all scenarios in parallel. The algorithm to solve a shortest path problem is called BFS",982,recursive
c495b9f0-8153-4852-95db-5bb345ca502f,Lecture_0.pdf,CSCI_80,4,". First in ﬁrst out, like a queue. Breadth ﬁrst search explores the shallowest node in the fron(er. It runs all scenarios in parallel. The algorithm to solve a shortest path problem is called BFS.  A breadth-ﬁrst search algorithm will follow mul(ple direc(ons at the same (me, taking one step in each possible direc(on before taking the second step in each direc(on. In this case, the fron(er is managed as a queue data structure. The catchphrase you need to remember here is “ﬁrst-in ﬁrst-out.” In this case, all the new nodes add up in line, and nodes are being considered based on which one was added ﬁrst (ﬁrst come ﬁrst served!). This results in a search algorithm that takes one step in each possible direc(on before taking a second step in any one direc(on.  (An example from outside lecture: suppose you are in a situa(on where you are looking for your keys. In this case, if you start with your pants, you will look in your right pocket",945,recursive
a2a74bd8-87c3-413c-ac8b-1f7f9ba14f32,Lecture_0.pdf,CSCI_80,4,".  (An example from outside lecture: suppose you are in a situa(on where you are looking for your keys. In this case, if you start with your pants, you will look in your right pocket. Aaer this, instead of looking at your lea pocket, you will take a look in one drawer. Then on the table. And so on, in every loca(on you can think of. Only aaer you will have exhausted all the loca(ons will you go back to your pants and search in the next pocket.)  Pros: This algorithm is guaranteed to ﬁnd the op(mal solu(on. Cons: This algorithm is almost guaranteed to take longer than the minimal (me to run. At worst, this algorithm takes the longest possible (me to run. Performance: O(v+e)  V = number of ver(ces (nodes) E = number of edges  Code example:",747,recursive
610f295c-d20f-4e37-b630-d65894e8a974,Lecture_0.pdf,CSCI_80,5,"# Deﬁne the func(on that removes a node from the fron(er and returns it.     def remove(self):        # Terminate the search if the fron(er is empty, because this means that there is no solu(on.         if self.empty():             raise Excep(on(""empty fron(er"")         else:             # Save the oldest item on the list (which was the ﬁrst one to be added)             node = self.fron(er[0]             # Save all the items on the list besides the ﬁrst one (i.e. removing the ﬁrst node)             self.fron(er = self.fron(er[1:]             return node  c. Dijkstra’s algorithm (book): The algorthim is a modiﬁca(on of BFS. BFS ﬁnds the shortest path. But dijkstra’s ﬁnds the fastest path (in (me or cost). There are four steps to the algorithm: a. Find the cheapest node. This is the only node you can get to in the least amount of (me.  b. Check whether there’s a cheaper path to the neighbors of this node. If so, Update the costs of the neighbours of this node. c",975,recursive
1a251ad5-e194-4d4a-892d-aff9b4e8abd0,Lecture_0.pdf,CSCI_80,5,". This is the only node you can get to in the least amount of (me.  b. Check whether there’s a cheaper path to the neighbors of this node. If so, Update the costs of the neighbours of this node. c. Repeat un(l you have done this for every node in the graph. d. Calculate the ﬁnal path.  BFS ﬁnds the shortest path with the path segments. But in Dijkstra’s algorithm, you assign a number or weight to each segment. Then algorithm ﬁnds the path with the smallest total weight. To calculate the shortest path in an unweighted graph, use breadth ﬁrst search. To calculate the shortest path in a weighted graph, use Dijkstra’s algo.  Dijkstra’s algorithm doesn’t work for nega(ve weight.  d. Greedy Best-First Search Breadth-ﬁrst and depth-ﬁrst are both uninformed search algorithms. That is, these algorithms do not u(lize any knowledge about the problem that they did not acquire through their own explora(on. However, most oaen is the case that some knowledge about the problem is, in fact, available",998,recursive
1437a57c-de27-4714-a9d9-8a4a20552c36,Lecture_0.pdf,CSCI_80,5,". However, most oaen is the case that some knowledge about the problem is, in fact, available. For example, when a human maze-solver enters a junc(on, the human can see which way goes in the general direc(on of the solu(on and which way does not. AI can do the same. A type of algorithm that considers addi(onal knowledge to try to improve its performance is called an informed search algorithm.  Greedy best-ﬁrst search expands the node that is the closest to the goal, as determined by a heuris(c func(on h(n). As its name suggests, the func(on es(mates how close to the goal the next node is, but it can be mistaken. The eﬃciency of the greedy best-ﬁrst algorithm depends on how good the heuris(c func(on is.",711,recursive
70f11fb7-b9d0-4fd4-9ade-01a1b9f026b1,Lecture_0.pdf,CSCI_80,6,"Manha6an Distance For example, in a maze, an algorithm can use a heuris(c func(on that relies on the ManhaOan distance between the possible nodes and the end of the maze. The ManhaOan distance ignores walls and counts how many steps up, down, or to the sides it would take to get from one loca(on to the goal loca(on. This is an easy es(ma(on that can be derived based on the (x, y) coordinates of the current loca(on and the goal loca(on. However, it is important to emphasize that, as with any heuris(c, it can go wrong and lead the algorithm down a slower path than it would have gone otherwise. It is possible that an uninformed search algorithm will provide a beOer solu(on faster, but it is less likely to do so than an informed algorithm.  Pro: At best, ﬁnds the op(mal solu(on fastest. Con: At worst, equal to DFS.  e",825,recursive
2df0a06c-e2c7-44ca-ac86-36c855f0fae5,Lecture_0.pdf,CSCI_80,6,".  Pro: At best, ﬁnds the op(mal solu(on fastest. Con: At worst, equal to DFS.  e. A* Search A development of the greedy best-ﬁrst algorithm, A* search considers not only h(n), the es(mated cost from the current loca(on to the goal, but also g(n), the cost that was accrued un(l the current loca(on. By combining both these values, the algorithm has a more accurate way of determining the cost of the solu(on and op(mizing its choices on the go. The algorithm keeps track of (the cost of path un(l now + es(mated cost to the goal), and once it exceeds the es(mated cost of some previous op(on, the algorithm will ditch the current path and go back to the previous op(on, thus preven(ng itself from going down a long, ineﬃcient path that h(n) erroneously marked as best.  Yet again, since this algorithm, too, relies on a heuris(c, it is as good as the heuris(c that it employs",876,recursive
fa4b1dcf-40e1-4816-b6e5-7ca9f22fcbe4,Lecture_0.pdf,CSCI_80,6,".  Yet again, since this algorithm, too, relies on a heuris(c, it is as good as the heuris(c that it employs. It is possible that in some situa(ons, it will be less eﬃcient than greedy best-ﬁrst search or even the uninformed algorithms. For A* search to be op(mal, the heuris(c func(on, h(n), should be:  - Admissible, or never overes(ma(ng the true cost, and - Consistent, which means that the es(mated path cost to the goal of a new node in addi(on to the cost of transi(oning to it from the previous node is greater or equal to the es(mated path cost to the goal of the previous node. To put it in an equa(on form, h(n) is consistent if for every node n and successor node n’ with step cost c, h(n) ≤ h(n’) + c.  Con: uses a lot of memory  f. Adversarial Search Whereas, previously, we have discussed algorithms that need to ﬁnd an answer to a ques(on, in adversarial search the algorithm faces an opponent that tries to achieve the opposite goal",949,recursive
65def5eb-7661-403b-86a9-8a7af35188b3,Lecture_0.pdf,CSCI_80,6,". Oaen, AI that uses adversarial search is encountered in games, such as (c tac toe.",84,recursive
4c6bf6f4-7348-4de1-a3a7-6e29aed13678,Lecture_0.pdf,CSCI_80,7,"g. Minimax A type of algorithm in adversarial search, Minimax represents winning condi(ons as (-1) for one side and (+1) for the other side. Further ac(ons will be driven by these condi(ons, with the minimizing side trying to get the lowest score, and the maximizer trying to get the highest score.  MAX(X) aims to maximize the score. Min (x) aims to minimize the score.  Represen(ng a Tic-Tac-Toe AI:  O wins (-1) Draw (0) X wins (1)  X is a max player and O is a min player.  S₀: Ini(al state (in our case, an empty 3X3 board) Players(s): a func(on that, given a state s, returns which player’s turn it is (X or O). Ac(ons(s): a func(on that, given a state s, return all the legal moves in this state (what spots are free on the board). Result(s, a): a func(on that, given a state s and ac(on a, returns a new state. This is the board that resulted from performing the ac(on a on state s (making a move in the game)",917,recursive
0587227f-8bcb-4372-9fbf-ae588955f270,Lecture_0.pdf,CSCI_80,7,". Result(s, a): a func(on that, given a state s and ac(on a, returns a new state. This is the board that resulted from performing the ac(on a on state s (making a move in the game). Terminal(s): a func(on that, given a state s, checks whether this is the last step in the game, i.e. if someone won or there is a (e. Returns True if the game has ended, False otherwise. U(lity(s): a func(on that, given a terminal state s, returns the u(lity value of the state: -1, 0, or 1. How the algorithm works:  Recursively, the algorithm simulates all possible games that can take place beginning at the current state and un(l a terminal state is reached. Each terminal state is valued as either (-1), 0, or (+1).  Minimax in Tic Tac Toe  Minimax Algorithm in Tic Tac Toe  Knowing based on the state whose turn it is, the algorithm can know whether the current player, when playing op(mally, will pick the ac(on that leads to a state with a lower or a higher value",953,recursive
1eb11712-35e9-421e-99d7-a9cde100bd15,Lecture_0.pdf,CSCI_80,7,". This way, alterna(ng between minimizing and maximizing, the algorithm creates values for the state that would result from each possible ac(on. To give a more concrete example, we can imagine that the maximizing player asks at every turn: “if I take this ac(on, a new state will result. If the minimizing player plays op(mally, what ac(on can that player take to bring to the lowest value?” However, to answer this ques(on, the maximizing player has to ask: “To know what the minimizing player will do, I need to simulate the same process in the minimizer’s mind:",564,recursive
12751627-b4eb-485a-94e0-be38bddb3fcb,Lecture_0.pdf,CSCI_80,8,"the minimizing player will try to ask: ‘if I take this ac(on, what ac(on can the maximizing player take to bring to the highest value?’” This is a recursive process, and it could be hard to wrap your head around it; looking at the pseudo code below can help. Eventually, through this recursive reasoning process, the maximizing player generates values for each state that could result from all the possible ac(ons at the current state. Aaer having these values, the maximizing player chooses the highest one.  Minimax Algorithm  The Maximizer Considers the Possible Values of Future States. To put it in pseudocode, the Minimax algorithm works the following way:  Given a state s  The maximizing player picks ac(on a in Ac(ons(s) that produces the highest value of Min-Value(Result(s, a)). The minimizing player picks ac(on a in Ac(ons(s) that produces the lowest value of Max-Value(Result(s, a))",896,recursive
af492664-dff1-4429-a737-78790f275df7,Lecture_0.pdf,CSCI_80,8,". The minimizing player picks ac(on a in Ac(ons(s) that produces the lowest value of Max-Value(Result(s, a)). Func(on Max-Value(state)  v = -∞  # Check ﬁrst if the game is over if Terminal(state):   return U(lity(state)  # if the game isn’t over for ac(on in Ac(ons(state):   v = Max(v, Min-Value(Result(state, ac(on)))  return v  Func(on Min-Value(state):  v = ∞  if Terminal(state):   return U(lity(state)  for ac(on in Ac(ons(state):   v = Min(v, Max-Value(Result(state, ac(on)))  return v",492,recursive
c21d8ca1-b3b8-4c77-8bdc-6d293cd1f17a,Lecture_0.pdf,CSCI_80,9,"h. Alpha-Beta Pruning A way to op(mize Minimax, Alpha-Beta Pruning skips some of the recursive computa(ons that are decidedly unfavorable. Aaer establishing the value of one ac(on, if there is ini(al evidence that the following ac(on can bring the opponent to get to a beOer score than the already established ac(on, there is no need to further inves(gate this ac(on because it will decidedly be less favorable than the previously established one.  This is most easily shown with an example: a maximizing player knows that, at the next step, the minimizing player will try to achieve the lowest score. Suppose the maximizing player has three possible ac(ons, and the ﬁrst one is valued at 4. Then the player starts genera(ng the value for the next ac(on. To do this, the player generates the values of the minimizer’s ac(ons if the current player makes this ac(on, knowing that the minimizer will choose the lowest one",918,recursive
c721d64c-c287-4698-ae3f-04e296f34e08,Lecture_0.pdf,CSCI_80,9,". To do this, the player generates the values of the minimizer’s ac(ons if the current player makes this ac(on, knowing that the minimizer will choose the lowest one. However, before ﬁnishing the computa(on for all the possible ac(ons of the minimizer, the player sees that one of the op(ons has a value of three. This means that there is no reason to keep on exploring the other possible ac(ons for the minimizing player. The value of the not-yet-valued ac(on doesn’t maOer, be it 10 or (-10). If the value is 10, the minimizer will choose the lowest op(on, 3, which is already worse than the preestablished 4. If the not-yet-valued ac(on would turn out to be (-10), the minimizer will this op(on, (-10), which is even more unfavorable to the maximizer. Therefore, compu(ng addi(onal possible ac(ons for the minimizer at this point is irrelevant to the maximizer, because the maximizing player already has an unequivocally beOer choice whose value is 4.  Alpha Beta Pruning  i",977,recursive
d2989c12-221c-43ae-91b9-e024aa608c24,Lecture_0.pdf,CSCI_80,9,".  Alpha Beta Pruning  i. Depth-Limited Minimax There is a total of 255,168 possible Tic Tac Toe games, and 10²⁹⁰⁰⁰ possible games in Chess. The minimax algorithm, as presented so far, requires genera(ng all hypothe(cal games from a certain point to the terminal condi(on. While compu(ng all the Tic-Tac-Toe games doesn’t pose a challenge for a modern computer, doing so with chess is currently impossible.  Depth-limited Minimax considers only a pre-deﬁned number of moves before it stops, without ever ge}ng to a terminal state. However, this doesn’t allow for ge}ng a precise value for each ac(on, since the end of the hypothe(cal games has not been reached. To deal with this problem, Depth-limited Minimax relies on an evalua(on func(on that es(mates the expected u(lity of the game from a given state, or, in other words, assigns values to states",852,recursive
99a9fb93-017b-4b66-ae9a-a3168ab7b630,Lecture_0.pdf,CSCI_80,9,". To deal with this problem, Depth-limited Minimax relies on an evalua(on func(on that es(mates the expected u(lity of the game from a given state, or, in other words, assigns values to states. For example, in a chess game, a u(lity func(on would take as input a current conﬁgura(on of the board, try to assess its expected u(lity (based on what pieces each player has and their loca(ons on the board), and then return a posi(ve or a nega(ve value that represents how favorable the board is for one player versus the other. These values can be used to decide on the right ac(on, and the beOer the evalua(on func(on, the beOer the Minimax algorithm that relies on it.",666,recursive
